<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/">
    <channel>
        <title>Spencer Sharp</title>
        <link>undefined</link>
        <description>Your blog description</description>
        <lastBuildDate>Tue, 28 Feb 2023 21:15:40 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <image>
            <title>Spencer Sharp</title>
            <url>undefined/favicon.ico</url>
            <link>undefined</link>
        </image>
        <copyright>All rights reserved 2023</copyright>
        <item>
            <title><![CDATA[How can Open Source Help Reduce Software Emissions?]]></title>
            <link>undefined/articles/open-source-reduce-software-emissions-podcast</link>
            <guid>undefined/articles/open-source-reduce-software-emissions-podcast</guid>
            <pubDate>Tue, 31 May 2022 09:55:00 GMT</pubDate>
            <description><![CDATA[No description provided]]></description>
            <content:encoded><![CDATA[<p><p>The podcast Environmental Variables, hosted by Asim Hussain, invited me to
join as a guest! I joined as co-chair of the Open Source Working Group at the
Green Software Foundation, with Dan Lewis-Toakley; Green Cloud Lead at
ThoughtWorks, and also co-chair of the Open Source Working Group at the Green
Software Foundation.</p></p>
<p><p>We discussed the benefits of open source versus closed source, what tools are
already out there and how open source can help reduce software emissions.</p></p>
<figure class="kg-card kg-bookmark-card"><a class="kg-bookmark-container" href="https://podcasts.bcast.fm/e/r8kw7658-how-can-open-source-help-reduce-software-emissions"><div class="kg-bookmark-content"><div class="kg-bookmark-title"><p>How can Open Source Help Reduce Software Emissions?</p></div><div class="kg-bookmark-description"><p>In this episode Asim Hussain is joined by guest Chris Lloyd-Jones; Head
of Open Technologies at Avanade and co-chair of the Open Source Working
Group at the Green Software Foundation, and Dan Lewis-Toakley; Green
Cloud Lead at ThoughtWorks and co-chair of the Open Source Working Group
at the Green S…</p></div><div class="kg-bookmark-metadata"><img class="kg-bookmark-icon" src="https://content.bcastcdn.com/uploads/8l18vy21/3c4a1dd0-b687-11ec-883a-0dcfb88dc005/3c4a1fb0-b687-11ec-b27f-356e6aa0eee9.png" alt=""/><span class="kg-bookmark-author"><p>How can Open Source Help Reduce Software Emissions?</p></span><span class="kg-bookmark-publisher">Green Software Foundation</span></div></div><div class="kg-bookmark-thumbnail"><img src="https://content.bcastcdn.com/uploads/8l18vy21/70820890-b68e-11ec-b62d-3156696150b9/meta70820a20-b68e-11ec-a09d-e31d2b56ffb8.png" alt=""/></div></a></figure>]]></content:encoded>
            <author>spencer@planetaria.tech (Spencer Sharp)</author>
        </item>
        <item>
            <title><![CDATA[Green Software Engineering at Microsoft Build 2022]]></title>
            <link>undefined/articles/green-software-engineering-at-microsoft-build</link>
            <guid>undefined/articles/green-software-engineering-at-microsoft-build</guid>
            <pubDate>Mon, 30 May 2022 09:46:25 GMT</pubDate>
            <description><![CDATA[No description provided]]></description>
            <content:encoded><![CDATA[<p>I talked about using Green Software practices to develop applications in Azure, including optimal use of microservices, training of machine learning models, and carbon awareness at Microsoft Build 2022.</p>
<p>I was joined by the awesome  <a href="https://twitter.com/darsh262">Darshna Shah</a> of Elastacloud! Watch the session here:</p>
<figure class="kg-card kg-bookmark-card"><a class="kg-bookmark-container" href="https://mybuild.microsoft.com/en-US/sessions/bc226aa3-9d7a-4930-b916-3eb1b18863b4"><div class="kg-bookmark-content"><div class="kg-bookmark-title"><p>Microsoft Build – Join us May 24-26 2022</p></div><div class="kg-bookmark-description"><p>Come together and discover the latest innovations in code and
application development—and gain insights from peers and experts from
around the world.</p></div><div class="kg-bookmark-metadata"><img class="kg-bookmark-icon" src="https://mybuild.microsoft.com/favicon.ico" alt=""/><span class="kg-bookmark-author"><p>Microsoft Build – Join us May 24-26 2022</p></span><span class="kg-bookmark-publisher">Microsoft</span></div></div><div class="kg-bookmark-thumbnail"><img src="https://eventtools.event.microsoft.com/build2022/FY22_Build_Phase01_Homepage_Metadata_1200x630.jpg" alt=""/></div></a></figure>]]></content:encoded>
            <author>spencer@planetaria.tech (Spencer Sharp)</author>
        </item>
        <item>
            <title><![CDATA[Green Software Engineering - Tech Talk with Kazeem]]></title>
            <link>undefined/articles/green-software-tech-talk-kazeem</link>
            <guid>undefined/articles/green-software-tech-talk-kazeem</guid>
            <pubDate>Mon, 18 Apr 2022 09:46:00 GMT</pubDate>
            <description><![CDATA[No description provided]]></description>
            <content:encoded><![CDATA[<p>Green Software Engineering is an emerging discipline, defining the principles and competencies to define, develop, and run sustainable software applications.</p>
<p>In this episode, I was invited to talk about:</p>
<ul><li>What&#x27;s Green Software?</li><li>Who&#x27;s a Green Software Developer?</li><li>Reducing Software Carbon footprint</li><li>Advice on how to best consume electricity</li><li>Required skills for Green Software Engineering</li><li>Green Software Engineering Learning Resources</li></ul>
<figure class="kg-card kg-embed-card"><iframe width="200" height="113" src="https://www.youtube.com/embed/ufmm7SiAK6Q?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"></iframe></figure>]]></content:encoded>
            <author>spencer@planetaria.tech (Spencer Sharp)</author>
        </item>
        <item>
            <title><![CDATA[Is the Creative Sector embracing the use of AI?]]></title>
            <link>undefined/articles/creative-sector-embracing-the-use-of-ai</link>
            <guid>undefined/articles/creative-sector-embracing-the-use-of-ai</guid>
            <pubDate>Thu, 03 Mar 2022 17:18:28 GMT</pubDate>
            <description><![CDATA[No description provided]]></description>
            <content:encoded><![CDATA[<p>I&#x27;ve been watching the development of AI in the creative sector, and I thought it was time to talk about it. The creative sector seems to be embracing the use of AI to supplement creativity and content creation, rather than replacing any one task. Right now, AI in its broadest sense is referring to (in AI parlance) the second wave of &#x27;statistical learning&#x27; - solving problem domains, but not yet having the power to generate new ideas and understanding based on context, or the third wave of AI. This is then driving how the creative sector is able to use AI.</p>
<h3 id="creationsparking-new-ideas">Creation - Sparking new ideas</h3>
<p>Retail and marketing organisations are using AI to spark new ideas - for example, during workshops, transcribing the conversation, and searching for related concepts, which could allow people to make new connections. This is also improving rote tasks of content management - automatically captioning images which a human has selected to accompany a news article, or <a href="https://azure.microsoft.com/en-us/services/cognitive-services/bing-image-search-api/?WT.mc_id=AI-MVP-5004204">searching for new images that could be used</a> using tools like Bing Image Search; with the ability to filter by newness, and how &#x27;formal&#x27; the image is.</p>
<h3 id="increasing-touchpoints">Increasing touchpoints</h3>
<p>AI is allowing creative organisations to improve the touchpoints with their customers. For example, Avanade is working with a multinational entertainment company to create virtual agents - characters that can respond on-brand, in an engaging way. This is a new avenue, allowing two-way conversations, for new characters that respond to customers using the same phrasing, and evoking the same persona; and allowing customers to chat with their favourite brands in and around the media they watch.</p>
<h3 id="improving-sustaining-the-brand">Improving &amp; sustaining the brand</h3>
<p>The use of these new touchpoints also allows creative organisations new opportunities to improve their brand. For example, <a href="https://docs.microsoft.com/en-us/azure/cognitive-services/speech-service/how-to-custom-voice-create-voice?WT.mc_id=AI-MVP-5004204">I&#x27;ve worked in the past with Microsoft speech technology to create recognisable, on-brand “voice fonts”</a> – allowing for virtual agents to synthesise voice in a way that matches voice actors. These AI technologies are also allowing creative organisations to leverage the results of previous campaigns and promotional messages to recommend new messages, and predict the success of the next campaign.</p>
<h3 id="generationcreating-initial-designs">Generation - Creating initial designs</h3>
<p>Probably one of the most impactful use of AI right now is in generation - using AI to look at historic content, and generate designs combined in new and differing ways. This is really lowering the barrier for creatives to support startups and burgeoning companies - <a href="https://www.wix.com/">for example, Wix</a> is using AI to generate websites that match a certain colour scheme, and information architecture; <a href="https://logojoy.com/">and Logojoy</a> is using AI to generate custom logos, typography, and colour schemes. Key to this though, and going back to the idea of &#x27;statistical learning&#x27; in AI - for the premium experience, and that level of creativity, a human creative still needs to augment the AI created designs.</p>
<h2 id="what-are-the-challenges-to-the-use-of-ai-in-the-creative-industries">What are the challenges to the use of AI in the creative industries?</h2>
<p>The main challenge with AI right now is where it sits as a tool. The creative industry doesn&#x27;t seem to be adopting AI techniques to solve the problems they are best at, but rather seeing it as an &#x27;either-or.&#x27; For example, <a href="https://docs.microsoft.com/en-us/shows/ai-show/sketch2code?WT.mc_id=AI-MVP-5004204">tools like Sketch2code from Microsoft</a> can take wireframes and designs, to create a working prototype which designers and developers can collaborate on, and test.</p>
<p>This should be a net positive - these technologies don&#x27;t understand the vagaries of accessibility, they can&#x27;t support with a content strategy, and they aren&#x27;t able to add animation or logic - <a href="https://www.econotimes.com/if-ai-is-already-writing-code-will-programmers-lose-their-jobs-1426913">but most of the response to this seems to have a fear that developers will lose their jobs</a>. Developers wrote this, and ultimately need to accept where AI can add value and do things better so that the creative industry can focus on that spark of generating new ideas.</p>
<p>It’s clear that AI is not currently sophisticated enough to fully replace creatives in the industry, but is there a sense that these technologies could hamper creativity?Certainly with the current wave of AI and design, there&#x27;s certainly a sense that these technologies could hamper creativity. Most of the technologies currently available are simply using historic data to replicate styles we already have, or recombining those styles in new ways.</p>
<p>There may be a phrase &#x27;there is nothing new under the sun&#x27; but certainly if we are to prove that wrong, AI as it is won&#x27;t help.In 2016, <a href="https://www.thereforefilms.com/sunspring.html">an AI neural network called &#x27;Benjamin&#x27; wrote a screenplay</a>, including stage directions and dialog- this script then needed interpretation by a human, to be converted into a masterpiece.</p>
<p><a href="https://www.udemy.com/artificial-intelligence-music-creation-remixing-2018/">In 2018, online courses were trumpeting the ability of people to become music stars, using AI tools to compose and remix music</a>; <a href="https://aiva.ai/creations">similar to a startup, AIVA</a>, which composes emotional soundtracks that have already been used in the background to real videos. AI could hamper creativity if analytics are used to predict the future success of something new, based on what has gone before - modelling this type of impact could lead to companies becoming more risk-averse, rather than continuing to provoke new thought and discussion.</p>
<h2 id="how-will-ai-evolve-within-the-creative-industries">How will AI evolve within the creative industries?</h2>
<p>Ultimately I think AI in the creative industries will evolve in the same way as elsewhere - having the ability to self-generate &#x27;new&#x27; content, and different ideas, rather than recombining the past. I think the key is how well the creative industries embrace this.AI won&#x27;t start by creating the greatest screenplay, or the best art, and will still require humans to add that artistic flare for some time - but it might enable humans to realise creativity and art that we didn&#x27;t have the ability to produce before. <a href="https://odico.dk/">For example, Odico is a Danish startup which is using AI and robotics to produce unique architecture and realise complex shapes</a> that are out of reach of traditional construction techniques.</p>]]></content:encoded>
            <author>spencer@planetaria.tech (Spencer Sharp)</author>
        </item>
        <item>
            <title><![CDATA[Call to Action: Establishing a Centre of Excellence]]></title>
            <link>undefined/articles/call-to-action-on-green-software-establishing-a-centre-of-excellence</link>
            <guid>undefined/articles/call-to-action-on-green-software-establishing-a-centre-of-excellence</guid>
            <pubDate>Thu, 17 Feb 2022 17:24:00 GMT</pubDate>
            <description><![CDATA[No description provided]]></description>
            <content:encoded><![CDATA[<p>The <a href="https://greensoftware.foundation/articles/call-to-action-on-green-software-establishing-a-centre-of-excellence">Call to Action (CTA) series at the Green Software Foundation continues</a>, a recurring series on practical actions around Green Software.</p>
<blockquote>Green software is yet to reach the tipping point—that magic moment when an idea, trend, or social behaviour crosses a threshold, tips, and spreads like wildfire. Part of our role should be to make our own evangelism unnecessary and green software the default.</blockquote>
<blockquote>In my first article, I talked about <a href="https://greensoftware.foundation/articles/call-to-action-spreading-the-message-of-green-software"><u>spreading the message of green software</u></a> within organisations. I addressed grassroots change and the importance of organisational support for change. In the second article, I talked about <a href="https://greensoftware.foundation/articles/cta-success-factors-measurements-and-driving-the-right-behaviour"><u>success factors, measurements and metrics</u></a> to ensure your organisation is fully supportive of greening software.</blockquote>
<blockquote>After having identified the business benefits of adopting green software—as well as the broader societal reasons for this adoption!—and gained early buy-in for this change, you&#x27;ll eventually hit your next challenge: who drives this change?</blockquote>
<blockquote><strong>Green Software Engineering should be self-sustaining</strong></blockquote>
<blockquote>In 2002, in <em>The Tipping Point: How Little Things Can Make a Big Difference</em>, Malcolm Gladwell explored the science behind human behaviour and the adoption of practices. He defined a tipping point as &quot;that magic moment when an idea, trend, or social behaviour crosses a threshold, tips, and spreads like wildfire.&quot;</blockquote>
<blockquote>I believe that Green Software Engineering has the capacity to be self-sustaining, in the same way that organisations have previously adopted various methodologies and practices as a new default, from Agile and Test-Driven Development to the use of Microservices and Open-Source Software. Admittedly, organisations are at various points on this change journey. However, we aren&#x27;t yet at this tipping point for Green Software Engineering.</blockquote>
<blockquote>Part of our role should be to make our own evangelism unnecessary. We should build the structures, conduct training, and adopt ways of thinking to make green software the default.</blockquote>
<blockquote>I mentioned that grassroots adoption and evangelism can influence the behaviour of your peers. Gladwell goes further, talking about the need to create a community around people to drive a fundamental change in people&#x27;s beliefs and behaviour.</blockquote>
<blockquote>In that mindset, making green software ubiquitous, today I’ll focus on the capabilities an organisation should build. These new capabilities are people enablers, to <em>create </em>green software, and support the practice of new skills.</blockquote>
<blockquote>I’ll close by setting the scene for future articles on the actual nuts and bolts—the fundamental activities—that teams can adopt; for example, reporting and instrumentation, to write, improve, and use green software.</blockquote>
<blockquote><strong>A brief recap...</strong></blockquote>
<blockquote>We know the importance of a green mindset, and strong sponsorship and champions within your organisation.</blockquote>
<blockquote>We also understand why organisations might want to green their software, and how each organisation can identify and measure their unique benefit, within the technology or governance of your organisation.</blockquote>
<blockquote>The final leg of this stool is the doing function, the mechanism by which we train people, improve processes, and change the way we work.</blockquote>
<blockquote><strong>What do I mean by a “doing function”?</strong></blockquote>
<blockquote>Being deliberately vague here, a doing function is any team or group of people which is capable of helping your organisation to build capability, adopt new practices, and shift the status quo.</blockquote>
<blockquote>If we use the adoption of Open Source, or Inner Source as a model here, your Green Software function might already be well established. Larger enterprises may have several teams looking at various different aspects of Green Software.</blockquote>
<blockquote>Here are some approaches that might be suitable for your organisation to adopt as a doing function, as there is no one size that fits all. What works for an open-source project or small to medium business isn&#x27;t necessarily a good fit for a larger enterprise.</blockquote>
<blockquote>And your organisation may want to adopt multiple approaches to reach your end goal.</blockquote>
<blockquote><strong>Approaches you could adopt</strong></blockquote>
<blockquote><strong><strong>Centre of Excellence </strong></strong>- A Centre of Excellence (COE) is often the most formal organisational construct for sharing knowledge. This is usually a group of people or a team that can coordinate training, process improvement, and knowledge sharing.</blockquote>
<blockquote><strong><strong>Community of Practice</strong></strong> - The term Community of Practice refers to people that share a passion or interest. It provides a forum to share information and for peers to learn from one another. These communities of practice often form organically, but can be harder to sustain, as people can rotate in and out of the community based on need, and the amount of time they have available.</blockquote>
<blockquote><strong><strong>Project Team or Committee</strong></strong> - A project team is a good way to start sharing Green Software practices. For example, you can set up a project team or committee for creating a training plan for your organisation. This approach could also be suitable if your Green Software initiative is to be delivered by a corporate function, such as human resources, or learning and development. However, unless your organisation has such a deep interest in green software that the practices become self-sustaining, this is unlikely to lead to lasting change. This is because project teams are usually a temporary construct, and by their nature have an expiration date.</blockquote>
<blockquote><strong><strong>Network of Representatives</strong></strong> - In a highly federated engineering or manufacturing organisation, you might have a network of representatives or champions that come together to share best practices. These are similar to a community of practice, but are formally embedded within each product team to champion the adoption of the new change.</blockquote>
<blockquote>Your organisation may use different terms for some of these approaches, which perform a similar activity, but the overall ideas should be applicable anywhere.</blockquote>
<blockquote>For the rest of this article, I&#x27;m going to focus on a Centre of Excellence, the activities you could start with, and how you can sustain this, but the advice should be broadly applicable to every approach.</blockquote>
<blockquote><strong>Centres of Excellence: Getting started</strong></blockquote>
<blockquote>By this point, I&#x27;m assuming you have an understanding of who your business sponsor is for this initiative, and the success factors you&#x27;re driving towards. If not, you might want to refer back to articles one and two, <a href="https://greensoftware.foundation/articles/call-to-action-spreading-the-message-of-green-software"><u>spreading the message of Green Software</u></a>,<a href="https://greensoftware.foundation/articles/cta-success-factors-measurements-and-driving-the-right-behaviour"> <u>and measuring success</u></a>, respectively.</blockquote>
<blockquote><strong>First steps</strong></blockquote>
<blockquote>So, you&#x27;ve established a Centre of Excellence, or COE. Well done! Your journey is just beginning. As you spread the message, you may have identified supporters and those with a keen interest in green software.</blockquote>
<blockquote>Your COE will need to begin by creating a clear purpose for being, identifying the roles you require, how you will share knowledge, and why joining or working with your community is valuable for your peers.</blockquote>
<blockquote><strong>Framing the purpose</strong></blockquote>
<blockquote>The core group that establishes the COE will be the centre of your community and are responsible for building trust with the rest of the organisation, as well as setting a positive culture. You&#x27;ll want to spend time as a group ensuring that you all have the same common goals and purpose, as this will influence the activities you undertake.</blockquote>
<blockquote><strong>Identifying roles - and your community of practitioners</strong></blockquote>
<blockquote>As you set up your COE, you&#x27;ll be negotiating formal roles that might be set by your organisation, and the ad-hoc roles that you fall into through practice.</blockquote>
<blockquote>The role of your COE may initially aim to create a community of practitioners that care, deliberately seeding some elements that a Community of Practice would otherwise take on.</blockquote>
<blockquote>You may want to invite the supporters you have identified to join the COE, either formally if you are able to do so, or as part of a broader community. As the core of your community, you might want to adopt them formally into leadership roles or ask them to present and share their experience. By adopting supporters formally into your community, you can increase motivation, and keep engagement high.</blockquote>
<blockquote>COE members appointed to leadership positions could represent the interests of their community; for example, a technical community, such as frontend developers, or a geographical community, such as those located in a specific office.</blockquote>
<blockquote><strong>Sharing knowledge and maintaining engagement</strong></blockquote>
<blockquote>Your COE will need to identify how knowledge will be shared. First, synchronous sharing. Will you have a regular community call, or an in-person meeting? Is your organisation entirely remote, hybrid, or are you separated across different geographical locations?</blockquote>
<blockquote>Most organisations will also have formal channels for sharing tacit knowledge in an asynchronous fashion. Think manuals, standard operating procedures, code, newsletters, and instruction guides. Keep things simple and frictionless as you can, remembering you&#x27;re another place for people to spend their precious attention. Sending out polls in Slack, Teams, Yammer, Workplace, and other social networks can be a lightweight way to maintain engagement.</blockquote>
<blockquote><strong>Making adoption irresistible and irreversible</strong></blockquote>
<blockquote>Early activities of your COE should focus on what community members can gain by adopting Green Software principles, and by changing the context of Green Software. Ask how you can remove barriers to make it frictionless to create and learn about carbon-efficient software.</blockquote>
<blockquote><strong>What&#x27;s in it for me?</strong></blockquote>
<blockquote>We need to put ourselves in our colleagues&#x27; shoes. We&#x27;re probably yet another demand on their time. So we need to show the personal benefits that learning about green software can bring to each person.</blockquote>
<blockquote>For example, supporting your COE could support an individual&#x27;s career development, as they pick up and learn new skills. It could also be a chance for them to make a significant change for their team, such as improving a DevOps pipeline to make it more efficient or maintainable.</blockquote>
<blockquote>I recommend creating personas to represent the types of people within your organisation that you are looking to support. For example, consider a full-stack developer persona or a salesperson persona. You can then identify different needs, goals and motivations they might have and select or prioritise activities accordingly.</blockquote>
<blockquote><strong>Making it frictionless</strong></blockquote>
<blockquote>Just as I&#x27;ve been writing about how you can get started with Green Software, your peers will need pointers and support to get started.</blockquote>
<blockquote>One approach you can use is recipe cards or small activities that you can promote within your organisation. These could be posted on an intranet or emailed out regularly to interested people across your organisation. Each activity should have a time attached to it, from small activities that could take 5 minutes, such as reading an article, to hands-on activities that may take multiple hours, such as e-learning modules, or self-study software labs.</blockquote>
<blockquote><strong>Centres of Excellence: Continuing into the future</strong></blockquote>
<blockquote>This is the start of your journey by pulling together a like minded team. Whether that&#x27;s informally as a Community of Practice, a formal Centre of Excellence, or some other vehicle which works for your organisation, you now have a direction and the start of a plan.</blockquote>
<blockquote>In future articles, I&#x27;ll be focussing on more detailed activities and approaches that your teams can adopt, including observability, instrumentation, devops practices as well as incentives for change and the use of nudge theory. The team you pull together will be key to adopting these techniques.</blockquote>
<blockquote>As your community comes together, please remember that we, at the Green Software Foundation, need your help. Your community will be well placed to support our open-source projects including:</blockquote>
<blockquote><a href="https://greensoftware.foundation/projects/principles-of-green-software-engineering"><u>The Principles of Green Software Engineering</u></a> - Training on reducing the carbon emissions of a software system. Your community can contribute their thoughts.</blockquote>
<blockquote><a href="https://greensoftware.foundation/projects/awesome-green-software"><u>Awesome Green Software</u></a> - As your community contributes tools and ideas, promote them here.</blockquote>
<blockquote><a href="https://greensoftware.foundation/projects/writers"><u>Green Software Writers</u></a> - As I&#x27;ve done, ask your community members to write about their experience with green software.</blockquote>
<blockquote>And finally,<a href="https://greensoftware.foundation/projects/speakers"> <u>you could reach out to our Green Software Speakers community</u></a>, to speak at an event your community runs. Or you may want to speak about green software yourself. Either way, you can find a lot of resources and support from us.</blockquote>
<blockquote>Feel free to reach out on <a href="https://twitter.com/gsfcommunity">Twitter</a>, <a href="https://www.linkedin.com/company/green-software-foundation">LinkedIn</a> and other forums and share with me other topics you&#x27;d like me to cover regarding practical actions you can take to spread the message of green software.</blockquote>
<p>This article is licenced under <a href="https://creativecommons.org/licenses/by/4.0/" rel="noopener noreferrer">Creative Commons (CC BY 4.0)</a></p>]]></content:encoded>
            <author>spencer@planetaria.tech (Spencer Sharp)</author>
        </item>
        <item>
            <title><![CDATA[Call to Action: Success Factors, Measurements and Driving the Right Behaviour]]></title>
            <link>undefined/articles/call-to-action-success-factors</link>
            <guid>undefined/articles/call-to-action-success-factors</guid>
            <pubDate>Thu, 10 Feb 2022 13:11:41 GMT</pubDate>
            <description><![CDATA[No description provided]]></description>
            <content:encoded><![CDATA[<p>The Call to Action (CTA) series at the Green Software Foundation continues, a recurring series on practical actions around Green Software.</p>
<blockquote>There&#x27;s a growing understanding of the need for organisations to be green or consider sustainability. But what metrics can we use to measure success?</blockquote>
<blockquote>In the <a href="https://greensoftware.foundation/articles/call-to-action-spreading-the-message-of-green-software"><u>first article in the Call to Action on Green Software</u></a>, I talked about spreading the message of green software within organisations. Spreading this message will be the basis for change, and help us to drive the adoption of green software engineering practices. That said, how do we know if spreading this message is creating change and moving us closer to success? What is success in this context anyway?</blockquote>
<blockquote>To answer these questions, and to ensure we&#x27;re moving in the right direction, we need to define success and the measurements which demonstrate success.</blockquote>
<blockquote>Where measurements align with our personal values, or individual motivation—career success, drive, desire for a better world, or pay—then our behaviour can be influenced.</blockquote>
<p>See <a href="https://greensoftware.foundation/articles/cta-success-factors-measurements-and-driving-the-right-behaviour">the full article at the Green Software Foundation website</a>.</p>
<p>This article is licenced under <a href="https://creativecommons.org/licenses/by/4.0/" rel="noopener noreferrer">Creative Commons (CC BY 4.0)</a></p>]]></content:encoded>
            <author>spencer@planetaria.tech (Spencer Sharp)</author>
        </item>
        <item>
            <title><![CDATA[The Future of Edge – “demassification”]]></title>
            <link>undefined/articles/the-future-of-edge-demassification</link>
            <guid>undefined/articles/the-future-of-edge-demassification</guid>
            <pubDate>Thu, 03 Feb 2022 11:22:00 GMT</pubDate>
            <description><![CDATA[No description provided]]></description>
            <content:encoded><![CDATA[<p>Over the last year, it won&#x27;t have escaped anyone&#x27;s notice really that there have been massive and unprecedented changes to the health of the world, and by extension, how healthcare is delivered.a</p>
<p>Microsoft&#x27;s  <a href="https://cloudblogs.microsoft.com/quantum/2022/01/27/nasas-jpl-uses-microsofts-azure-quantum-to-manage-communication-with-space-missions/?WT.mc_id=AI-MVP-5004204">new blog on using Azure Quantum to manage communication with space missions</a>   had me thinking, about the Future of Edge, Space Networking, and the Internet of Things.</p>
<h2>First, let me set the scene with IoT...</h2>
<p>The Internet of Things - commonly known as IoT – describes the interconnection of everyday objects and spaces, using new and existing devices, leveraging improved connectivity and platforms, to enable brand new experiences. These experiences can be enterprise-focused to support optimized operations, such as predictive maintenance, or quality control – as well as consumer and employee focussed, e.g. tracking worker fatigue, or personalizing products for customers.</p>
<blockquote>
<p>The Internet of Things - commonly known as IoT – describes the interconnection of everyday objects and spaces.</p>
</blockquote>
<h2>What&#x27;s driving this increase in IoT?</h2>
<p>IoT is being driven by the massive opportunity to unlock new opportunities, which weren’t previously possible, and to make better use of the data that existing devices were generating.</p>
<p>The intersection of data platforms and the changing nature of network infrastructure has converged with the availability of cheap and easily deployable hardware modules.</p>
<h3>Connectivity</h3>
<p>These connectivity changes range from wide-area network standards such as LoRa, increasing speeds available with WiFi 5 onwards (as well as urban city-wide adoption schemes), and the rise of 5G cellular phone availability.</p>
<h3>Intelligence</h3>
<p>In addition to connectivity and data platforms, it’s easier than ever to deploy intelligence, from specialized algorithms to tiny machine learning models, to low power devices. This is both supporting the ability to process  <em>out of the cloud</em> and where events are happening, but it’s also enabling networking infrastructure to be better managed, for example, through software-defined networking; a truly virtuous circle.</p>
<h2>How does IoT relate to Edge?</h2>
<p>Edge means a lot of different things to a lot of different people. The truth is, the internet as-is wasn’t designed for the current demands placed upon it; it grew from a high-trust environment from military and academic collaboration to supporting global hyperconnectivity between parties that know nothing about each other.</p>
<p>Our hyperconnected planet is a patchwork of internet coverage, of varying latency and bandwidths; full of “dead zones” and network dead-ends. To that end, the Edge is no longer computing outside of the cloud or a datacenter – instead, the Edge is anywhere the internet isn’t.</p>
<blockquote>
<p>The Edge is anywhere the internet isn’t.</p>
</blockquote>
<h3>How is networking changing the game?</h3>
<p>Networking is increasing bandwidth, and expanding up to space, and down under the sea – but whilst bandwidth might increase, latency is a fundamental constraint, due to processing limitations, and the limitation of the speed of light as a transmission speed.</p>
<h1>The rise of new architectural patterns</h1>
<p>Software Engineers are building hyper-scale applications to serve the world – or at least many different locations; but the software engineering patterns and practices of the last five years coalesced in a period of co-located containers, burgeoning content delivery networks, and replicated databases [ <a href="https://docs.microsoft.com/en-us/azure/architecture/guide/design-principles/use-the-best-data-store?WT.mc_id=AI-MVP-5004204#recommendations">bounded by the CAP theorem of consistency, availability, and partition tolerance</a> .]</p>
<p>Our enterprise systems were often built upon synchronous assumptions, where availability was a given, common attitudes towards data usage and privacy were expected, and data transfers were outside the realm of nation-states.</p>
<p>To put it simply, those assumptions no longer hold true. From now, and for the next couple of years, we’re seeing devices proliferate to avoid the constraint of latency and networking speeds. We’re seeing companies figure out how they can update and recycle these. Bandwidth might increase, but latency will remain the hard limitation.</p>
<h2>Resolutions</h2>
<p>Engineers will begin designing for the “demassified era” – understanding how to handle processes with components that may be located across short or infinitesimal distances. Partition tolerance will become a guiding principle. Companies will be designing for the edge by default, and focus on how they make better sense of the data. For the purposes of Cognitive Search, or Machine Learning, this could likely involve bringing algorithms to the data, and returning indexed results. </p>
<blockquote>
<p>demassified (past tense) divide or break up (a social or political unit) into its component parts.</p>
</blockquote>
<h3>Optimizing bandwidth usage</h3>
<p>If the Edge is where the internet isn’t, the focus will be on optimizing bandwidth usage to avoid overage charges and the cost of shifting data from point to point. We’re shifting from this idea that data transmission is free, to pay for the fuel which shifts our data currency.</p>
<h3>Instant Gratification</h3>
<p>Systems will move away from &quot;instant gratification&quot; to reconciliation and retransmission – this means that they won’t expect a synchronous response, and that software will need to consider whether processes are “immediate”, “resolving”, or “long-running.”</p>
<p>Short bursts of data will happen on the edge, and data will be processed and used when needed, and when cheapest. Like charging an electric vehicle on your mains electricity, your autonomous systems, such as in-car devices, will drive and “report” when it returns to a “home” wifi station.</p>
<h3>Radical overhaul of the internet transport layer</h3>
<p>If we consider the fact that computing through the Cloud is what enables overage charges to become an everyday reality, then the internet transport layer itself will be radically overhauled for the future of networking systems. From Cloudflare here on Earth, computing at the Edge of the well-connected network, to OneWeb, and Starlink, we’re seeing the rise of new paradigms that our messaging systems need to contend with. A few years ago, who would have considered that commercial space telecommunication and standards could be in our near future?</p>
<h3>Second-order effects</h3>
<p>As the network solidifies up to space, and down under the sea, the rise of standards could see prices dropping. This isn’t the first time that mass infrastructure has required global adoption. Telegrams followed the model established by the International Telecommunication Union in 1865 – hard problems generate collaboration.</p>
<h1>From Space to Global Applications – further out on the Horizon</h1>
<h2>The Growth of Space Infrastructure</h2>
<p>In the long term, even Space needs standards. When space travel was limited to the capabilities of nation-states, one or two spaceships noisily hogging the analogue spectrum was fine. With interference in space, we’ll need to consider how communications take place over longer distances, from lensing of laser signals, physical throwing of data storage, to how we slice and use the available spectrum. It’s our current grappling with radio networking writ large.</p>
<h3>Shared Infrastructure?</h3>
<p>Will we see an establishment of solar-system wide backhaul of cooperative satellites to store, buffer, and forward messages? Will space ships have electromagnetically hardened and standardized black boxes, capable of locating, and contacting the backhaul? Be that Starlink, OneWeb, or another consortium yet to be built.</p>
<h2>The Sneakernet is still a competitor</h2>
<p>Andrew Tanenbaum said in 1981, &quot;Never underestimate the bandwidth of a station wagon full of tapes hurtling down the highway.&quot; The SneakerNet phenomenon - aka, putting on your sneakers and physically carrying your data – never really left us.  <a href="https://docs.microsoft.com/en-us/azure/databox/data-box-heavy-overview?WT.mc_id=AI-MVP-5004204">Microsoft has Azure Data Box Heavy </a> – a 500lb disk to transfer a petabyte of data into Azure, and AWS has their Amazon SnowBall.</p>
<p>And  <a href="https://what-if.xkcd.com/31/">as XKCD naturally took to its logical conclusion</a> , the Internet wouldn’t surpass the “bandwidth” of FedEx until 2040 – and that’s using today&#x27;s storage tools.</p>
<p>As we expand geographically, physically transferring data and then completing data reconciliation may remain an attractive option; particularly with those data ingress/egress fees…</p>
<h2>Just let it crumble</h2>
<p>One common problem with managing physical infrastructure is the requirement to update, secure, and track your IoT assets. Who is responsible when hardware needs to be upgraded?</p>
<p>One solution on the horizon could be taking a biological approach. Microchips may not always be silicon-based – nano-cellulose or other biodegradable alternatives are one way to avoid the burden of updates and replacement. Imagine growing your microchips with embedded software to avoid leaving an attack surface for your software to be attacked; and then simply letting them biodegrade.</p>
<h1>Some ponderings and possible futures...</h1>
<ul>
<li>To avoid the constraint of latency and networking speeds, devices are proliferating, to compute closer to where the activities are happening.</li>
<li>Engineers will begin designing for the “demassified era” – understanding how to deal with processes with components that may be located across short or infinitesimal distances.</li>
<li>Systems will move away from &quot;instant gratification&quot; to reconciliation and retransmission – this means that they won’t expect a synchronous response, and that software will need to consider whether processes are “immediate”, “resolving”, or “long-running.”</li>
<li>Microchips may not always be silicon-based – nano-cellulose or other biodegradable alternatives are one way to avoid the burden of updates and replacement.</li>
<li>A solar-system wide backhaul of cooperative satellites will be established to store, buffer, and forward messages.</li>
<li>Space ships will have hardened standardized black boxes, capable of contacting the backhaul – be that Starlink, OneWeb, or another consortium yet to be built.</li>
<li>Edge is only where the internet isn’t – and the internet could be everywhere, with the right commercial impetus</li>
<li>The internet transport layer is being radically overhauled - Edge will include space, and laser links could proliferate</li>
<li>Commercial space telecommunication will follow the model established by the International Telecommunication Union in 1865 – and nation-states will only regulate space.</li>
</ul>
<figure class="kg-card kg-bookmark-card"><a class="kg-bookmark-container" href="https://cloudblogs.microsoft.com/quantum/2022/01/27/nasas-jpl-uses-microsofts-azure-quantum-to-manage-communication-with-space-missions/"><div class="kg-bookmark-content"><div class="kg-bookmark-title"><p>NASA’s JPL uses Microsoft’s Azure Quantum to manage communication with
space missions - Microsoft Azure Quantum Blog</p></div><div class="kg-bookmark-description"><p>As NASA launches more frequent and complex missions into space, managing
communications with the growing number of spacecraft is becoming
increasingly challenging. NASA’s Jet Propulsion Laboratory (JPL) has
turned to Azure Quantum to explore ways to communicate more efficiently
with spacecraft explo…</p></div><div class="kg-bookmark-metadata"><img class="kg-bookmark-icon" src="https://cloudblogs.microsoft.com/uploads/prod/sites/7/2018/08/cropped-cropped-microsoft_logo_element-300x300.png" alt=""/><span class="kg-bookmark-author">Microsoft Azure Quantum Blog</span><span class="kg-bookmark-publisher">Anita Ramanan</span></div></div><div class="kg-bookmark-thumbnail"><img src="https://cloudblogs.microsoft.com/uploads/prod/sites/7/2022/01/MS_JPL_QuatComp_Thumbnail_02_.png" alt=""/></div></a></figure>]]></content:encoded>
            <author>spencer@planetaria.tech (Spencer Sharp)</author>
        </item>
        <item>
            <title><![CDATA[Call to Action: Spreading the Message of Green Software]]></title>
            <link>undefined/articles/call-to-action-spreading-the-message-of-green-software</link>
            <guid>undefined/articles/call-to-action-spreading-the-message-of-green-software</guid>
            <pubDate>Wed, 02 Feb 2022 14:21:06 GMT</pubDate>
            <description><![CDATA[No description provided]]></description>
            <content:encoded><![CDATA[<p>I wrote <a href="https://greensoftware.foundation/articles/call-to-action-spreading-the-message-of-green-software">a blog for the Green Software Foundation</a> - the start of a recurring series that I&#x27;m very excited about - Call to Action (CTA) -  practical steps for spreading the message of green software within organisations.</p>
<blockquote>I&#x27;ve been invited to regularly write and share my thoughts on spreading the message of green software; why this is important, and other trends I&#x27;m seeing in this space. I&#x27;ll start today by talking about top-down, and bottom-up change.</blockquote>
<blockquote>Geoffrey James, in the Tao of Programming, said &quot;Let the programmers be many and the managers few - then all will be productive.&quot;</blockquote>
<blockquote>This viewpoint has some validity. I&#x27;m incredibly aware of the drains on my productivity and creativity from context switching, but it fails to take into account the positive benefits that a strong support structure can provide, including supporting change, training, and the development of new skills.</blockquote>
<p>See <a href="https://greensoftware.foundation/articles/call-to-action-spreading-the-message-of-green-software">the full article at the Green Software Foundation website</a>.</p>]]></content:encoded>
            <author>spencer@planetaria.tech (Spencer Sharp)</author>
        </item>
        <item>
            <title><![CDATA[GitHub Copilot – GPT-3 powered coding]]></title>
            <link>undefined/articles/github-copilot-gpt-3-powered-coding</link>
            <guid>undefined/articles/github-copilot-gpt-3-powered-coding</guid>
            <pubDate>Wed, 12 Jan 2022 11:03:59 GMT</pubDate>
            <description><![CDATA[No description provided]]></description>
            <content:encoded><![CDATA[<p>I co-authored  <a href="https://www.avanade.com/en/blogs/techs-and-specs/software-development/github-copilot">a blog for Avanade Techs and Specs</a> , with a particular focus  <a href="https://docs.microsoft.com/en-us/shows/devops-lab/whats-new-in-devops-at-github-universe?WT.mc_id=AI-MVP-5004204">on GitHub Copilot</a> .</p>
<blockquote>
<p>Nearly a year ago, we  <a href="https://www.avanade.com/en/blogs/techs-and-specs/software-development/intelligent-code-creation">investigated several intelligent code creation tools, and discussed the ethical implications</a>   and investigated a few tools – and wow, a lot can change in a year!</p>
</blockquote>
<blockquote>
<p>GitHub  <a href="https://copilot.github.com/">Copilot</a>   is now in technical preview, and with our hands on it, we think it deserves a discussion of its own. Copilot is a new software tool in the Intelligent Code Creation (ICC) category, using powerful machine learning models from  <a href="https://openai.com/blog/openai-api/">OpenAI</a> , including GPT-3 and Codex, to develop significantly faster and more efficiently.</p>
</blockquote>
<blockquote>
<p>GitHub Copilot is supported for use on Visual Studio Code, JetBrains variants (including Rider and IntelliJ), and Neovim.</p>
</blockquote>
<blockquote>
<p><strong>Automatic suggestions</strong>
Copilot can autosuggest solutions for the context you’re working in, but it can also understand natural human language in comments and function names, to synthesize a solution for your current task.</p>
</blockquote>
<blockquote>
<p>Copilot is trained from software documents, and public code repositories, whilst also utilising your own code to improve its suggestions, in line with your coding style; supplying highly relevant suggestions based on what you are currently working on.</p>
</blockquote>
<blockquote>
<p><strong>Code generation from natural language</strong>
Thanks to OpenAI Codex, GitHub Copilot has the incredible ability to turn natural language into code. Write the logic you wish to achieve in a comment, and Copilot will try and create that functionality with code.</p>
</blockquote>
<blockquote>
<p>This can lead to one or more suggestions, including those spanning multiple lines of logic, making Copilot an excellent tool for existing developers to improve their productivity.</p>
</blockquote>
<blockquote>
<p><strong>Learning to code</strong>
Developers that are learning to code will find that Copilot is a useful learning tool, giving developers the ability to play with code, using natural language to synthesize well written and formatted code suggestions, rather than heavy reliance on copy/paste, documentation, code samples, and tutorials.</p>
</blockquote>
<blockquote>
<p>This should make it faster to implement working solutions quickly, instead of spending time unravelling the sample code to find out what has gone wrong from the version in your clipboard; although the human ability to discern and understand will remain important.</p>
</blockquote>
<blockquote>
<p><strong>Removing the bugbear of boilerplate... but what’s the cost?</strong>
Copilot can generate repetitive language in code, like quickly generating lists of sample data for testing.</p>
</blockquote>
<blockquote>
<p>Beyond the benefits of a system trained on large public code repositories, there are issues to be aware of. When code suggestions are based on popularity, or usage, you can’t guarantee that the code suggestions are using the most up to date implementations, libraries, and approaches.</p>
</blockquote>
<blockquote>
<p>If a new security flaw is found, Copilot may generate code without the correct fixes applied; and with such a vast training set, there is no sole source of truth or ‘correctness’ and other people’s bad coding habits may blindly end up in your code base. In one example we tested, we were even given someone else’s API key in a hard coded REST request. Oops!</p>
</blockquote>
<blockquote>
<p>One current pitfall is where new libraries or frameworks with significant breaking changes are released. Since the systems are trained on existing code repositories, it will take a significant amount of time for the available code to reflect the new versions. This may lead developers who aren’t in the know to continue developing for outdated versions instead of using the latest and greatest available to them.</p>
</blockquote>
<p>GitHub Copilot is an incredible update to the AI pair programming world - and it looks set to continue into the future,  <a href="https://github.com/github/feedback/discussions/8308">with another feature on the horizon including code explanation</a>   of highlighted code blocks. </p>
<p>There&#x27;s been some controversy on the internet around the use of public code - but with the rise of Tabnine, Kite, and others - the trend looks set to continue for now.</p>
<figure class="kg-card kg-bookmark-card kg-card-hascaption"><a class="kg-bookmark-container" href="https://copilot.github.com"><div class="kg-bookmark-content"><div class="kg-bookmark-title"><p>GitHub Copilot · Your AI pair programmer</p></div><div class="kg-bookmark-description"><p>GitHub Copilot works alongside you directly in your editor, suggesting
whole lines or entire functions for you.</p></div><div class="kg-bookmark-metadata"><img class="kg-bookmark-icon" src="https://github.com/fluidicon.png" alt=""/><span class="kg-bookmark-author">GitHub Copilot</span></div></div><div class="kg-bookmark-thumbnail"><img src="http://copilot.github.com/social.png" alt=""/></div></a><figcaption>Join the preview program!</figcaption></figure>
<p></p>]]></content:encoded>
            <author>spencer@planetaria.tech (Spencer Sharp)</author>
        </item>
        <item>
            <title><![CDATA[Industry group aims to tackle energy-efficient software development]]></title>
            <link>undefined/articles/industry-group-aims-to-tackle-energy-efficient-software-development</link>
            <guid>undefined/articles/industry-group-aims-to-tackle-energy-efficient-software-development</guid>
            <pubDate>Fri, 17 Dec 2021 16:48:07 GMT</pubDate>
            <description><![CDATA[No description provided]]></description>
            <content:encoded><![CDATA[<p><p>A number of media mentions around the launch of the newly published Green
Software Foundation Software Carbon Intensity specification.</p></p>
<figure class="kg-card kg-bookmark-card"><a class="kg-bookmark-container" href="https://www.computerweekly.com/news/252510873/Industry-group-aims-to-tackle-energy-efficient-software-development"><div class="kg-bookmark-content"><div class="kg-bookmark-title"><p>Industry group aims to tackle energy-efficient software development</p></div><div class="kg-bookmark-description"><p>How many processor cycles does an algorithm use? Can it use less and, if
so, how will this reduce overall energy usage and greenhouse emissions?</p></div><div class="kg-bookmark-metadata"><img class="kg-bookmark-icon" src="https://www.computerweekly.com/apple-touch-icon-144x144.png" alt=""/><span class="kg-bookmark-author">ComputerWeekly.com</span><span class="kg-bookmark-publisher">Cliff Saran,</span></div></div><div class="kg-bookmark-thumbnail"><img src="https://cdn.ttgtmedia.com/visuals/ComputerWeekly/Hero%20Images/eco-green-energy-electricity-wind-solar-fotolia.jpg" alt=""/></div></a></figure>
<blockquote><p>At a high level, said Lloyd-Jones, the specification is fundamentally based on
a set of core principles, such as measuring that the workload usage of a CPU
correlates roughly to how much electricity a piece of code uses.</p></blockquote>
<figure class="kg-card kg-bookmark-card"><a class="kg-bookmark-container" href="https://www.computing.co.uk/news/4041994/industry-initiative-aims-foster-green-software-development"><div class="kg-bookmark-content"><div class="kg-bookmark-title"><p>Industry initiative aims to foster green software development</p></div><div class="kg-bookmark-description"><p>The Green Software Foundation says its focus is ‘reduction, not
neutralisation’</p></div><div class="kg-bookmark-metadata"><img class="kg-bookmark-icon" src="https://assets.kreatio.net/computing_redesign/png/favicons/icon-hires.png" alt=""/><span class="kg-bookmark-author">computing_logo</span><span class="kg-bookmark-publisher">Dev Kundaliya</span></div></div><div class="kg-bookmark-thumbnail"><img src="https://image.chitra.live/api/v1/wps/617b168/c75e0106-c22c-4972-b12e-c85be1a533fe/8/software-370x229.jpg" alt=""/></div></a></figure>
<blockquote><p>Chris Lloyd-Jones, head of open technologies at Avanade, says the basic idea
behind SCI is to &quot;have a score to drive down your carbon footprint,&quot; rather
than measuring the total carbon footprint. This enables developers to look for
ways to make their code more energy-efficient and take steps to cut the carbon
footprint of the software they develop.</p></blockquote>
<figure class="kg-card kg-bookmark-card"><a class="kg-bookmark-container" href="https://texasnewstoday-com.cdn.ampproject.org/c/s/texasnewstoday.com/industry-initiatives-are-aimed-at-facilitating-green-software-development/572493/?amp"><div class="kg-bookmark-content"><div class="kg-bookmark-title"><p>Industry initiatives are aimed at facilitating green software
development - Texas News Today</p></div><div class="kg-bookmark-description"><p>Technology giants such as Microsoft, Accenture, GitHub, and Thoughtworks
are one of the founding members of new climate-friendly initiatives to
drive sustainable software development. Both companies are members of
the Green Software Foundation, which has announced initial
specifications for measurin…</p></div><div class="kg-bookmark-metadata"><img class="kg-bookmark-icon" src="https://texasnewstoday-com.cdn.ampproject.org/i/s/texasnewstoday.com/favicon.ico" alt=""/><span class="kg-bookmark-author">Texas News Today</span><span class="kg-bookmark-publisher">martinricker</span></div></div><div class="kg-bookmark-thumbnail"><img src="https://texasnewstoday.com/wp-content/uploads/https://image.chitra.live/api/v1/wps/617b168/c75e0106-c22c-4972-b12e-c85be1a533fe/8/software-370x229.jpg" alt=""/></div></a></figure>
<blockquote><p>Chris Lloyd-Jones, Head of Open Technology at Avanade, said the basic idea
behind SCI is not to measure total carbon emissions, but to “score to reduce
carbon emissions.” It states that. This allows developers to find ways to make
their code more energy efficient and take steps to reduce the carbon dioxide
emissions of the software they develop.</p></blockquote>
<p><a href="https://github.com/Green-Software-Foundation/software_carbon_intensity"><p>Read the specification here.</p></a></p>
<figure class="kg-card kg-bookmark-card"><a class="kg-bookmark-container" href="https://github.com/Green-Software-Foundation/software_carbon_intensity"><div class="kg-bookmark-content"><div class="kg-bookmark-title"><p>GitHub - Green-Software-Foundation/software_carbon_intensity: A
specification that describes how to calculate a carbon intensity for
software applications.</p></div><div class="kg-bookmark-description"><p>A specification that describes how to calculate a carbon intensity for
software applications. - GitHub -
Green-Software-Foundation/software_carbon_intensity: A specification
that describes how to c...</p></div><div class="kg-bookmark-metadata"><img class="kg-bookmark-icon" src="https://github.com/fluidicon.png" alt=""/><span class="kg-bookmark-author">GitHub</span><span class="kg-bookmark-publisher">Green-Software-Foundation</span></div></div><div class="kg-bookmark-thumbnail"><img src="https://opengraph.githubassets.com/d0ab84e10d8de541f18c06dff2f74e02b7743c552cd9d1438eb3b68c3e0a8b97/Green-Software-Foundation/software_carbon_intensity" alt=""/></div></a></figure>]]></content:encoded>
            <author>spencer@planetaria.tech (Spencer Sharp)</author>
        </item>
        <item>
            <title><![CDATA[Green Software - Making an impact]]></title>
            <link>undefined/articles/green-software-making-an-impact</link>
            <guid>undefined/articles/green-software-making-an-impact</guid>
            <pubDate>Mon, 13 Dec 2021 17:44:56 GMT</pubDate>
            <description><![CDATA[No description provided]]></description>
            <content:encoded><![CDATA[<p>I&#x27;ve been absolutely chuffed to be part of the Green Software Foundation, as one of the many members and contributors to  <a href="https://greensoftware.foundation/projects/software-carbon-intensity-sci-specification">the Software Carbon Intensity specification</a> .</p>
<p>From my perspective, the overall goal of the specification is to drive action to reduce the carbon impact of the software in the world around us. Many of us have taken a module on software profiling at university - using  <a href="https://ftp.gnu.org/old-gnu/Manuals/gprof-2.9.1/html_mono/gprof.html#SEC1">tools like gprof</a>   to track the performance of software, and identify areas for rewriting and refactoring, to improve software speed.</p>
<figure class="kg-card kg-image-card kg-card-hascaption"><img src="__GHOST_URL__/content/images/2021/12/image.png" class="kg-image" alt="A screenshot of columns of data showing the amount of milliseconds spent in each part of a software program execution" loading="lazy" width="522" height="420"/><figcaption><p>Screenshot from Linux For Engineers by <a href="http://linuxforengineers.blogspot.in/">Ajith P
Venugopal</a> , licensed under a
<a href="http://creativecommons.org/licenses/by-nc-sa/3.0/">Creative Commons Attribution-NonCommercial-ShareAlike 3.0 Unported
License</a> .</p></figcaption></figure>
<p><p>Until now though, how many of us actually go and do this? The glut of cheaply
available compute has made us somewhat spoilt - and I&#x27;d boldly say (or
whisper) lazy at times.</p></p>
<p><p>Carbon emissions of our software changes this imperative. It isn&#x27;t just
important to refactor software for speed and efficiency, but also to improve
the electrical performance, and thus potentially the carbon emissions
generated by running software.</p></p>
<figure class="kg-card kg-bookmark-card"><a class="kg-bookmark-container" href="https://www.computerweekly.com/news/252510873/Industry-group-aims-to-tackle-energy-efficient-software-development"><div class="kg-bookmark-content"><div class="kg-bookmark-title"><p>Industry group aims to tackle energy-efficient software development</p></div><div class="kg-bookmark-description"><p>How many processor cycles does an algorithm use? Can it use less and, if
so, how will this reduce overall energy usage and greenhouse emissions?</p></div><div class="kg-bookmark-metadata"><img class="kg-bookmark-icon" src="https://www.computerweekly.com/apple-touch-icon-144x144.png" alt=""/><span class="kg-bookmark-author">ComputerWeekly.com</span><span class="kg-bookmark-publisher">Cliff Saran,</span></div></div><div class="kg-bookmark-thumbnail"><img src="https://cdn.ttgtmedia.com/visuals/ComputerWeekly/Hero%20Images/eco-green-energy-electricity-wind-solar-fotolia.jpg" alt=""/></div></a></figure>
<p><p>Standing on the shoulders of many others in the foundation, the specification
itself describes three actions that should be taken to reduce the carbon
emissions of software:</p></p>
<blockquote><ol><li><p>Energy Efficiency: Actions taken to make software use less electricity to
perform the same function.</p></li><li><p>Hardware Efficiency: Actions taken to make software use less physical
resources to perform the same function.</p></li><li><p>Carbon Awareness: Actions taken to time or region-shift software
computation to take advantage of clean, renewable or low carbon sources of
electricity.</p></li></ol></blockquote>
<p><p>(</p><a href="https://github.com/Green-Software-Foundation/software_carbon_intensity/blob/main/Software_Carbon_Intensity/Software_Carbon_Intensity_Specification.md#software-sustainability-actions"><p>Original source</p></a><p>, <em>
Green Software Foundation, . (2021). Software Carbon Intensity Standard
(Version 1.0.0)
</em>)</p></p>
<p>These actions can come in many forms.</p>
<h3 id="energy-efficiency">Energy Efficiency</h3>
<p><p>For cloud aficionados, energy efficiency can be approached both by improving
the efficiency of the underlying software (or using </p><a href="https://docs.microsoft.com/en-us/azure/databricks/applications/machine-learning/preprocess-data/transfer-learning-tensorflow?WT.mc_id=AI-MVP-5004204"><p>techniques like transfer learning when training a machine learning model</p></a><p>), but also by rightsizing the cloud infrastructure being used. For example, Sara
Bergman <a href="https://devblogs.microsoft.com/sustainable-software/how-can-i-calculate-co2eq-emissions-for-my-azure-vm/?WT.mc_id=AI-MVP-5004204">
has written an excellent article
</a> on calculating the CO<sub>2</sub>eq of a virtual machine; using a similar
formula, we can roughly estimate the CO<sub>2</sub>eq of a container, <a href="https://docs.microsoft.com/en-us/azure/azure-functions/?WT.mc_id=AI-MVP-5004204">
or an Azure Function
</a>.</p></p>
<p><p>Whilst the target figures are likely some way off from the reality (presumably
only your cloud provider knows the true figures), we can be confident enough
to say that Containers and Serverless Computing are likely significantly more
energy &amp; carbon-efficient than running an application in a whole virtual
machine.</p></p>
<h3 id="hardware-efficiency">Hardware Efficiency</h3>
<p><p>Hardware efficiency in turn could mean moving to a cloud, with economies of
scale, and the ability of a cloud provider to be carbon neutral. </p><a href="https://docs.microsoft.com/en-us/compliance/assurance/assurance-datacenter-environmental-safeguards#energy-efficiency?WT.mc_id=AI-MVP-5004204"><p>Microsoft commits to be carbon negative by 2030 for example</p></a><p>, and to remove all historic carbon since it was founded in 1975, by 2050.</p></p>
<p><p>However, hardware efficiency could also include extending the life of your
existing hardware. For example, </p><a href="https://www.opencompute.org/blog/open-compute-open-sustainability-open-possibilities"><p>the Open Compute Project (OCP) has been looking at how to apply circular
economic principles to your IT infrastructure</p></a><p>.</p></p>
<h3 id="carbon-awareness">Carbon Awareness</h3>
<p><p>The final action that the specification describes, is Carbon Awareness. That
is, knowing the current fuel mix of your energy grid, and running applications
when the energy has been created through renewables, as opposed to fossil
fuels.</p></p>
<p><p>Some datacentres have private energy supplies; but others are connected to the
public and national grid, in whatever country they happen to be located.</p></p>
<p><p>For the UK, you can see the UK&#x27;s energy fuel mix in real time at <a href="https://electricityinfo.org/real-time-british-electricity-supply/">the
electricity
info</a> 
website. At the time of writing, 22.7% of the UK&#x27;s energy in the grid right
now, is from renewable sources. In the last 24 hours, 43% of the energy came
from renewable sources.</p></p>
<p><p>If you can embed this awareness into your software, you can enable your
software to lower its own emissions. </p></p>
<figure class="kg-card kg-bookmark-card"><a class="kg-bookmark-container" href="https://github.com/Green-Software-Foundation/software_carbon_intensity/blob/main/Software_Carbon_Intensity/Software_Carbon_Intensity_Specification.md#software-sustainability-actions"><div class="kg-bookmark-content"><div class="kg-bookmark-title"><p>software_carbon_intensity/Software_Carbon_Intensity_Specification.md at
main · Green-Software-Foundation/software_carbon_intensity</p></div><div class="kg-bookmark-description"><p>A specification that describes how to calculate a carbon intensity for
software applications. -
software_carbon_intensity/Software_Carbon_Intensity_Specification.md at
main · Green-Software-Foundat...</p></div><div class="kg-bookmark-metadata"><img class="kg-bookmark-icon" src="https://github.com/fluidicon.png" alt=""/><span class="kg-bookmark-author">GitHub</span><span class="kg-bookmark-publisher">Green-Software-Foundation</span></div></div><div class="kg-bookmark-thumbnail"><img src="https://opengraph.githubassets.com/af07ed5a4ee78ebe5b5369c72d5111bf37bea6ae0ad8bf1ddab2991fb142ca1b/Green-Software-Foundation/software_carbon_intensity" alt=""/></div></a></figure>
<h3 id="the-future">The future</h3>
<p><p>It&#x27;s exciting. This specification enables everyone to take an action to reduce
the carbon emissions of the software we use, day-to-day. </p></p>
<p><p>Are you ready for a return to software profiling? Be prepared to dust off
those skills.</p></p>]]></content:encoded>
            <author>spencer@planetaria.tech (Spencer Sharp)</author>
        </item>
        <item>
            <title><![CDATA[The Wonderful World of GitHub Actions]]></title>
            <link>undefined/articles/the-wonderful-world-of-github-actions</link>
            <guid>undefined/articles/the-wonderful-world-of-github-actions</guid>
            <pubDate>Tue, 21 Sep 2021 14:46:35 GMT</pubDate>
            <description><![CDATA[No description provided]]></description>
            <content:encoded><![CDATA[<p>I&#x27;ve been open sourcing projects at Avanade for some time. I&#x27;ve recently needed a ton of automation - from code scans for security vulnerabilities and licensing compliance to automatically merging pull requests after a certain amount of time. </p>
<p>I&#x27;ve just started a new role as Head of Open Technologies for Avanade - bringing together Open Innovation, Open Source, and supporting a broader community. I&#x27;ll share some of the information I&#x27;ve learnt whilst using GitHub Actions to help my work.</p>
<h3>So, what are GitHub Actions?</h3>
<p><a href="https://docs.microsoft.com/en-us/learn/paths/automate-workflow-github-actions/?WT.mc_id=AI-MVP-5004204">GitHub Actions provide automation for your code repositories</a> . Each action is described in a YAML defined workflow file that let you execute logic based upon events like Pull Requests, Pushes to branches, issue creation etc.</p>
<p>Many projects need specific workflows and requirements, such as a restriction on the approved open-source licences, a desire to create issues based on &#x27;#TODO:&#x27; notes buried in code comments, or to make life easier.</p>
<h3>How do you set up a GitHub action?</h3>
<p>GitHub Actions YAML files are stored within a code repository, in a dot folder called <code>.github/workflows/</code>. You can define one or more  <em>workflows</em> which developers can use to group together different related jobs and actions.</p>
<p>Each <em>workflow</em> defines a series of <em>jobs</em>. A <em>job</em> is made up of multiple <em>steps</em>. A <em>step</em> combines multiple  <em>actions</em>. Finally, all of this runs on a <em>runner</em> somewhere - a machine or a container spun up to run and execute your workflow.</p>
<p>Finally, you define which <em>event</em> triggers which <em>workflows</em>. Got that?! This diagram might show better how everything fits together.</p>
<figure class="kg-card kg-image-card kg-card-hascaption"><img src="__GHOST_URL__/content/images/2021/09/GHA-Blog.png" class="kg-image" alt="A diagram showing an event triggering a workflow. The next step shows a workflow running on a runner, a machine. This ends with outputs emitting from the runner. There is a box under the runner, showing a multiple steps in a job - the job example is a called a compliance scan. There are multiple steps, each step has an action. The first step is download a code repo, with the actions/checkout@v2 action. The second step is save cache, with the actions/cache@v2 repo. The final step is run licence scan, with any action you choose." loading="lazy" width="624" height="617" srcset="__GHOST_URL__/content/images/size/w600/2021/09/GHA-Blog.png 600w, __GHOST_URL__/content/images/2021/09/GHA-Blog.png 624w"/><figcaption>An example of the process running end to end</figcaption></figure>
<p><p>I&#x27;ll talk about some of the Actions I used on my last project (working with
Brain Control Devices, a robotics platform, and a robot) and some I&#x27;m trying
out now. I will assume some familiarity with 
<a href="https://guides.github.com/introduction/flow/">the GitHub flow</a>,
mainly pull requests, pushes, and branching. </p><a href="https://guides.github.com/introduction/flow/"><p>If not, I recommend a read</p></a><p>!</p></p>
<figure class="kg-card kg-bookmark-card"><a class="kg-bookmark-container" href="https://github.com/Avanade/emtech-stretch-labs"><div class="kg-bookmark-content"><div class="kg-bookmark-title">Avanade/emtech-stretch-labs</div><div class="kg-bookmark-description"><p>Repositories related to Avanade’s exploration with Rocos, NextMind and
Hello Robot. - Avanade/emtech-stretch-labs</p></div><div class="kg-bookmark-metadata"><img class="kg-bookmark-icon" src="https://github.githubassets.com/favicons/favicon.svg" alt=""/><span class="kg-bookmark-author">GitHub</span><span class="kg-bookmark-publisher">Avanade</span></div></div><div class="kg-bookmark-thumbnail"><img src="https://opengraph.githubassets.com/8edec2b56f7ea704dba22d06272ce6b8aebda6d1603e9bf8f081ddddbd5bce14/Avanade/emtech-stretch-labs" alt=""/></div></a></figure>
<h2 id="finding-a-github-action">Finding a GitHub Action</h2>
<p><p>There are many different GitHub Actions available on the GitHub Marketplace.</p></p>
<figure class="kg-card kg-bookmark-card"><a class="kg-bookmark-container" href="https://github.com/marketplace?type=actions"><div class="kg-bookmark-content"><div class="kg-bookmark-title"><p>GitHub Marketplace: actions to improve your workflow</p></div><div class="kg-bookmark-description"><p>Find the actions that help your team build better, together.</p></div><div class="kg-bookmark-metadata"><img class="kg-bookmark-icon" src="https://github.com/fluidicon.png" alt=""/><span class="kg-bookmark-author">GitHub</span></div></div><div class="kg-bookmark-thumbnail"><img src="https://github.githubassets.com/images/modules/site/social-cards/marketplace.png" alt=""/></div></a></figure>
<h3>GitHub Actions for Azure - great for ML</h3>
<p>Microsoft also maintains a  <a href="https://docs.microsoft.com/en-us/azure/developer/github/github-actions?WT.mc_id=AI-MVP-5004204#where-can-i-see-all-the-available-actions">specific list of GitHub Actions for Azure</a>   - and some of these are particularly useful for integrating MLOps, or  <a href="https://docs.microsoft.com/en-us/azure/machine-learning/concept-model-management-and-deployment?WT.mc_id=AI-MVP-5004204">the practices you need to deploy Machine Learning models in production alongside your code</a> . GitHub Actions are helpful to improve collaboration between developers and data scientists to increase reproducibility and your machine learning development consistency.</p>
<h3>Licence Compliance</h3>
<p>I&#x27;ve tried some of the Open Source licence compliance tools, and I&#x27;m now looking at some of the commercial options - I don&#x27;t have an opinion on those yet, but I can show you some of the OSS tools in use.</p>
<p>I&#x27;m still using  <a href="https://github.com/ShiftLeftSecurity/scan-action"><code>ShiftLeftSecurity/scan-action</code></a>   from <a href="http://slscan.io/">http://slscan.io/</a> and that tool supports many different programming languages.</p>
<p>For Python repositories, I particularly like  <a href="https://github.com/andersy005/gh-action-py-liccheck"><code>andersy005/gh-action-py-liccheck</code></a>   which uses a <code>pyproject.toml</code> file format.</p>
<p>Here&#x27;s an example of these actions in use:</p>
<script src="https://gist.github.com/Sealjay/cb59f8aaf25de08a830b59358d560571.js"></script>
<h3>Issues and Work Tracking</h3>
<p>I like to use two actions for my issues and my work -  <a href="https://github.com/ribtoks/tdg-github-action">one to create issues for Todos in code</a>   called <code>ribtoks/tdg-github-action</code> and another to  <a href="https://github.com/AdityaGovardhan/ga-pull-requests-projects">make sure new pull requests are assigned to a GitHub project board related to the project</a>   called <code>AdityaGovardhan/ga-pull-requests-projects</code>.</p>
<p>Here&#x27;s an example of these actions in use:</p>
<script src="https://gist.github.com/Sealjay/a3b3848342fef7d279bb85d63e033927.js"></script>
<h2>Where to learn more?</h2>
<p>GitHub Actions make your life so much easier.   <a href="https://docs.microsoft.com/en-us/learn/paths/automate-workflow-github-actions/?WT.mc_id=AI-MVP-5004204">I recommend the Microsoft Learn path</a>   to get hands-on and try out some examples.</p>
<figure class="kg-card kg-bookmark-card"><a class="kg-bookmark-container" href="https://docs.microsoft.com/en-us/learn/paths/automate-workflow-github-actions/?WT.mc_id=AI-MVP-5004204"><div class="kg-bookmark-content"><div class="kg-bookmark-title"><p>Automate your workflow with GitHub Actions - Learn</p></div><div class="kg-bookmark-description"><p>Learn how GitHub Actions enables you to automate your software
development cycle and deploy applications to Azure.</p></div><div class="kg-bookmark-metadata"><span class="kg-bookmark-author">Microsoft Docs</span><span class="kg-bookmark-publisher">tpetchel</span></div></div><div class="kg-bookmark-thumbnail"><img src="https://docs.microsoft.com/learn/achievements/github/automate-workflow-github-actions-social.png" alt=""/></div></a></figure>]]></content:encoded>
            <author>spencer@planetaria.tech (Spencer Sharp)</author>
        </item>
        <item>
            <title><![CDATA[The Metaverse - finally here?]]></title>
            <link>undefined/articles/the-metaverse-is-it-finally-here</link>
            <guid>undefined/articles/the-metaverse-is-it-finally-here</guid>
            <pubDate>Thu, 02 Sep 2021 14:04:06 GMT</pubDate>
            <description><![CDATA[No description provided]]></description>
            <content:encoded><![CDATA[<p><p>Aside from (quite a few!) talks recently, around </p><a href="https://sealjay.com/querying-azure-digital-twins-with-powerbi/"><p>querying Azure Digital Twins with PowerBI</p></a><p>, I&#x27;ve been pretty quiet. Why is that? Well, I&#x27;m finishing up my masters
degree at the University of Edinburgh, focussed in the areas of AI, human
interaction, and... how do we make human connections?</p></p>
<p><p>So, why am I talking about this? Well as I&#x27;ve been working on my research,
I&#x27;ve found that real life events are rapidly providing fodder, and almost too
many topics and avenues to look at.</p></p>
<h3 id="some-of-the-topics-ive-been-exploring-include"><p>Some of the topics I&#x27;ve been exploring include...</p></h3>
<ul><li>Procedurally generating virtual spaces from a 3D map</li><li>Using AI and ML to make virtual spaces seem real</li><li><p>Connecting two physical spaces to make them feel seamlessly connected, like
a window</p></li></ul>
<p><p>And almost every single time, I find an open source project, or commercial
research springing up to look in the same field. And that&#x27;s amazing! I take it
to mean I&#x27;m on the right track.</p></p>
<p><p>From </p><a href="https://docs.microsoft.com/en-us/mesh/overview?WT.mc_id=AI-MVP-5004204"><p>HoloPortation from Microsoft Mesh</p></a><p>, <a href="https://hubs.mozilla.com/">Mozilla Hubs</a>,  and the </p><a href="https://www.microsoft.com/en-us/research/project/confidential-consortium-framework/"><p>Confidential Consortium Framework</p></a><p>, to devices from Google, Amazon and Facebook which connect two places... the
main thread that seems to link these together, is that we&#x27;re seeing an
increase in services and design to provide security, trust, connection, and
infrastructure to connect multiple parties across space.</p></p>
<h2 id="the-metaverse">The Metaverse!</h2>
<p><p>This brings me to the Metaverse. The term Metaverse was coined by William
Gibson, and in my opinion, is broadly used to refer to the totality of the
world, connected and underpinned by the internet. For example, using augmented
reality to navigate around a store, using virtual reality to host conferences,
and <em>generally melding the physical and digital world into one</em>.</p></p>
<p><p>I think we&#x27;re now at the tipping point. We have competing standards to
consider, competing technologies, but societal trends such as white-collar
home working, digital driving licences, and the rise of interest communities
as the main connector of people, rather than work, friends, or family seem to
be bringing some version of the Metaverse to life.</p></p>
<p><p>This brings problems - how do we include everyone? In the same way that
Clubhouse, and similar audio tools can enfranchise and inadvertently
disenfranchise groups... who is this excluding? But the future rushes towards
us (whether or not we like it) - let&#x27;s all keep an eye on progress, so we can
share in a better future for all.</p></p>
<figure class="kg-card kg-bookmark-card"><a class="kg-bookmark-container" href="https://sealjay.com/oral-culture-and-the-rise-of-literacy/"><div class="kg-bookmark-content"><div class="kg-bookmark-title">Oral culture and the rise of literacy</div><div class="kg-bookmark-description"><p>The rise of clubhouse - and a return to oral culture. Literacy
enfranchises some previously excluded elements of society, and this is a
trend to watch.</p></div><div class="kg-bookmark-metadata"><img class="kg-bookmark-icon" src="https://sealjay.com/favicon.png" alt=""/><span class="kg-bookmark-author">Sealjay</span><span class="kg-bookmark-publisher">Chris Lloyd-Jones</span></div></div><div class="kg-bookmark-thumbnail"><img src="https://static.ghost.org/v3.0.0/images/publication-cover.png" alt=""/></div></a></figure>
<h3 id="footnote">Footnote - </h3>
<p><p>This topic has intersected nicely with my professional life too, having
recently (shameless plug) co-ordinated a new project around Digital Twins for
Smart Buildings and Virtual Spaces, which won </p><a href="https://stevieawards.com/iba/new-product-awards-category-winners-0"><p>Gold for IoT Analytics solution 2021 at the International Business Awards</p></a><p>, and was shortlisted for IoT project of the year &amp; VR project of the year </p><a href="https://nationaltechnologyawards.co.uk/shortlist21.php"><p>at the National Tech Awards</p></a><p>. </p></p>
<figure class="kg-card kg-embed-card kg-card-hascaption"><iframe width="200" height="113" src="https://www.youtube.com/embed/ilYaBASU5XQ?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"></iframe><figcaption><p>My professional work with AltSpace, creating a VR Space and Digital Twin for
Avanade&#x27;s London Office</p></figcaption></figure>]]></content:encoded>
            <author>spencer@planetaria.tech (Spencer Sharp)</author>
        </item>
        <item>
            <title><![CDATA[Azure Confidential Ledger – attestability for the masses]]></title>
            <link>undefined/articles/azure-confidential-ledger-attestability-for-the-masses</link>
            <guid>undefined/articles/azure-confidential-ledger-attestability-for-the-masses</guid>
            <pubDate>Wed, 14 Jul 2021 14:15:00 GMT</pubDate>
            <description><![CDATA[No description provided]]></description>
            <content:encoded><![CDATA[<p>I co-authored <a href="https://www.avanade.com/en/blogs/techs-and-specs/azure/confidential-ledger">a blog for Avanade Techs and Specs</a>, with a particular focus on <a href="https://docs.microsoft.com/en-us/azure/confidential-ledger/overview?WT.mc_id=AI-MVP-5004204">Azure Confidential Ledger</a>, or &#x27;ACL&#x27;.</p>
<blockquote>
<p>Azure Confidential Ledger or ‘ACL’ is a lightweight and flexible managed decentralized data platform, <a href="https://docs.microsoft.com/en-us/azure/confidential-computing/overview?WT.mc_id=AI-MVP-5004204">built on top of Azure Confidential Computing and Intel SGX</a>. Backed by blockchain technology, multiple parties can add data entries in a secure and tamperproof way to ensure data integrity whilst allowing flexibility in the data and approach.</p>
<p>Azure&#x27;s confidential computing technology and hardware can secure data during processing, to ensure confidentiality of data end-to-end rather than just when at rest or in transit. This allows for processing of sensitive and regulated data in the cloud, to enable specific use cases such as cross-organizational data sharing, data combination, and processing of large datasets to train AI models without exposing the data to others.</p>
<p>Azure Confidential Ledger runs on similar principles to those used in <a href="https://www.avanade.com/en/blogs/techs-and-specs/azure/blockchain-sql-server-ledger-tables">Azure SQL ledger tables, which we explored previously</a> for Microsoft Build 2021. Azure Confidential Ledger gives us the same level of trust and integrity, without the need for a managed SQL database or dedicated SQL server. Entries can be quickly added to the ledger as and when they occur, with receipts for each transaction to validate each entry. Entries can also be read from the ledger, so a full history can be established, without the ability of any party to tamper with the historical content.</p>
<p>Entries can vary, from the short and simple, to verbose or unstructured data formats. This provides great flexibility in what can be logged to the ledger, making Azure Confidential Ledger suitable for many use cases. Data formats can be changed or adapted over time, and entries don’t have to conform to a single standard from the point of creation, so confidential ledger can evolve with the problem space it has been implemented in, while retaining the history of data.</p>
</blockquote>
<p>Using Azure Confidential Ledger is <a href="https://docs.microsoft.com/en-us/archive/msdn-magazine/2019/april/azure-confidential-computing-secure-multi-party-machine-learning-with-azure-confidential-computing?WT.mc_id=AI-MVP-5004204">one way to support secure multi-party machine learning</a>. For more information about attestability for the masses, or to add comments, the blog post is available in full at <a href="https://www.avanade.com/en/blogs/techs-and-specs/azure/confidential-ledger">Azure Confidential Ledger – attestability for the masses (avanade.com)</a> - for Azure Confidential Ledger itself, Microsoft&#x27;s documentation is <em>the place</em> to start reading up.</p>
<figure class="kg-card kg-bookmark-card"><a class="kg-bookmark-container" href="https://docs.microsoft.com/en-us/azure/confidential-ledger/overview?WT.mc_id=AI-MVP-5004204"><div class="kg-bookmark-content"><div class="kg-bookmark-title"><p>Microsoft Azure Confidential Ledger overview</p></div><div class="kg-bookmark-description"><p>An overview of Azure Confidential Ledger, a highly secure service for
managing sensitive data records</p></div><div class="kg-bookmark-metadata"><span class="kg-bookmark-author">Microsoft Docs</span><span class="kg-bookmark-publisher">msmbaldwin</span></div></div><div class="kg-bookmark-thumbnail"><img src="https://docs.microsoft.com/en-us/media/logos/logo-ms-social.png" alt=""/></div></a></figure>]]></content:encoded>
            <author>spencer@planetaria.tech (Spencer Sharp)</author>
        </item>
        <item>
            <title><![CDATA[Microsoft Inspire 2021: Protecting your Ledger with Azure Confidential Computing]]></title>
            <link>undefined/articles/microsoft-inspire-2021-protecting-your-ledger-with-azure-confidential-computing</link>
            <guid>undefined/articles/microsoft-inspire-2021-protecting-your-ledger-with-azure-confidential-computing</guid>
            <pubDate>Wed, 14 Jul 2021 00:00:00 GMT</pubDate>
            <description><![CDATA[No description provided]]></description>
            <content:encoded><![CDATA[<p><p>I spoke with Vikas Bhatia of Microsoft, and Paul O&#x27;Neill of intel to discuss a
number of industry examples around Azure Confidential Computing.</p></p>
<embed type="video/mp4" src="https://mediusdownload.event.microsoft.com/asset-2e7bb820-f588-4c2b-baed-427f5b803f02/OD201_1920x1080_AACAudio_4953.mp4?sv=2015-02-21&amp;sr=c&amp;sig=LM%2FTZOwnnlCnxgf%2FecPHi71FCd4elgGcA8jwlqkJXrI%3D&amp;se=2026-10-21T07%3A06%3A47Z&amp;sp=r"/>
<p><p>Source: </p><a href="https://myinspire.microsoft.com/sessions/c623bbc5-d32a-43f6-862b-d81fd4175f53?source=sessions"><p>Protecting your Ledger with Azure Confidential Computing (microsoft.com)</p></a></p>
<blockquote><p>Discover how Avanade, the leading provider of innovative digital and cloud
services, took advantage of Azure Confidential Computing powered by Intel SGX
to offer a tamper-protected ledger to their customers. Hear from experts to
learn how you can use Azure Confidential Computing in different industry
examples in this panel discussion.</p></blockquote>]]></content:encoded>
            <author>spencer@planetaria.tech (Spencer Sharp)</author>
        </item>
        <item>
            <title><![CDATA[Understand medical information in text]]></title>
            <link>undefined/articles/text-analytics-for-health</link>
            <guid>undefined/articles/text-analytics-for-health</guid>
            <pubDate>Tue, 25 May 2021 16:00:00 GMT</pubDate>
            <description><![CDATA[No description provided]]></description>
            <content:encoded><![CDATA[<p>Over the last year, it won&#x27;t have escaped anyone&#x27;s notice really that there have been massive and unprecedented changes to the health of the world, and by extension, how healthcare is delivered.</p>
<p>From mobile applications, like  <a href="https://covid19.nhs.uk/">the COVID-19 app in England</a>, to  <a href="https://news.microsoft.com/en-gb/features/driving-force-the-inside-story-of-how-a-group-of-rival-companies-came-together-to-make-ventilators-for-the-nhs-during-the-covid-19-pandemic/">using augmented reality to ramp up the production of ventilators</a>   (a project I was lucky enough to help with!), some changes have been radical, and we won&#x27;t go back to the way things were before.</p>
<h3>New technologies releasing at speed</h3>
<p>Building on this, new technologies continue to be released at pace. Semantic Search was one technology launched in March 2021,  <a href="https://sealjay.com/intelligent-search-at-your-fingertips/">allowing users to ask questions of a Cognitive Search index, and receive an answer</a>   – you can imagine how this could allow people to self-solve for basic healthcare needs like nutrition, and fitness.</p>
<h3>Launch of Text Analytics for Health</h3>
<p>Well,  <a href="https://news.microsoft.com/build2021">at Microsoft Build today</a>, another awesome service has been launched to add to the set!  <a href="https://docs.microsoft.com/en-gb/azure/cognitive-services/text-analytics/how-tos/text-analytics-for-health?WT.mc_id=AI-MVP-5004204">Text Analytics for health</a>   allows developers to pull out healthcare related insights and named entities, from unstructured text, like medical records or journals.</p>
<p>In Microsoft’s example, they use this to link medication, diagnoses, and treatments together – helping to rapidly understand links in medical notes and research information.</p>
<figure class="kg-card kg-image-card kg-card-hascaption"><img src="__GHOST_URL__/content/images/2021/05/image-5.png" class="kg-image" loading="lazy" width="839" height="289" srcset="__GHOST_URL__/content/images/size/w600/2021/05/image-5.png 600w, __GHOST_URL__/content/images/2021/05/image-5.png 839w" sizes="(min-width: 720px) 720px"/><figcaption><p>Image copyright Microsoft Inc. Displays correlations and meaningful links.</p></figcaption></figure>
<p>More broadly, this can be used to analyse data at scale – for example, ingesting
the latest pre-print medical journals to identify impactful treatments, monitoring
social media to look for the spread of flu or colds through symptom mention, and
improving all of the many virtual agents and chatbots that are propagating into the
healthcare system! (Incidentally, Microsoft <a href="https://aka.ms/AAcf1i7">also launched a new visual WYSIWYG editor
for chatbots in the Azure Bot Service</a> …!)</p>
<figure class="kg-card kg-image-card kg-card-hascaption"><img src="__GHOST_URL__/content/images/2021/05/image-4.png" class="kg-image" loading="lazy" width="964" height="331" srcset="__GHOST_URL__/content/images/size/w600/2021/05/image-4.png 600w, __GHOST_URL__/content/images/2021/05/image-4.png 964w" sizes="(min-width: 720px) 720px"/><figcaption><p>Image copyright Microsoft Inc. Displays medical assertions.</p></figcaption></figure>
<p>I&#x27;m hopeful and excited that we&#x27;ll see a real uptake of this service, to improve
how healthcare is delivered and evolves for everyone.a</p>
<figure class="kg-card kg-bookmark-card"><a class="kg-bookmark-container" href="https://docs.microsoft.com/en-gb/azure/cognitive-services/text-analytics/how-tos/text-analytics-for-health?tabs=ner&amp;WT.mc_id=AI-MVP-5004204"><div class="kg-bookmark-content"><div class="kg-bookmark-title"><p>How to use Text Analytics for health - Azure Cognitive Services</p></div><div class="kg-bookmark-description"><p>Learn how to extract and label medical information from unstructured
clinical text with Text Analytics for health.</p></div><div class="kg-bookmark-metadata"><span class="kg-bookmark-author">Microsoft Docs</span><span class="kg-bookmark-publisher">aahill</span></div></div><div class="kg-bookmark-thumbnail"><img src="https://docs.microsoft.com/en-us/media/logos/logo-ms-social.png"/></div></a></figure>]]></content:encoded>
            <author>spencer@planetaria.tech (Spencer Sharp)</author>
        </item>
        <item>
            <title><![CDATA[Querying Azure Digital Twins with PowerBI]]></title>
            <link>undefined/articles/querying-azure-digital-twins-with-powerbi</link>
            <guid>undefined/articles/querying-azure-digital-twins-with-powerbi</guid>
            <pubDate>Mon, 24 May 2021 23:12:17 GMT</pubDate>
            <description><![CDATA[No description provided]]></description>
            <content:encoded><![CDATA[<p><p>A Digital Twin is a digital replica of a physical object, space, or abstract
process. It allows us to model the state of these things virtually, and then
respond to events as they happen in real time.</p></p>
<p><p>Microsoft provide an Azure Digital Twin service, which allows us to create
pre-defined models (such as thermostats for example) and then create twins
based on these models, mapping the relationships between a whole series of
different things.</p></p>
<figure class="kg-card kg-bookmark-card"><a class="kg-bookmark-container" href="https://docs.microsoft.com/en-gb/azure/digital-twins/overview?WT.mc_id=AI-MVP-5004204"><div class="kg-bookmark-content"><div class="kg-bookmark-title"><p>What is Azure Digital Twins? - Azure Digital Twins</p></div><div class="kg-bookmark-description"><p>Overview of what can be done with Azure Digital Twins.</p></div><div class="kg-bookmark-metadata"><span class="kg-bookmark-author">Microsoft Docs</span><span class="kg-bookmark-publisher">baanders</span></div></div><div class="kg-bookmark-thumbnail"><img src="https://docs.microsoft.com/en-us/media/logos/logo-ms-social.png" alt=""/></div></a></figure>
<p>As well as SDKs across a variety of languages from .NET to Python, Microsoft have
created a number of tools and code samples - <a href="https://github.com/Azure-Samples/digital-twins-explorer/">the Azure Digital Twins explorer</a>
is a web based application that allows you to visually see the connections between
these twins.</p>
<figure class="kg-card kg-image-card kg-card-hascaption"><img src="__GHOST_URL__/content/images/2021/05/image-1.png" class="kg-image" loading="lazy" width="2000" height="1248" srcset="__GHOST_URL__/content/images/size/w600/2021/05/image-1.png 600w, __GHOST_URL__/content/images/size/w1000/2021/05/image-1.png 1000w, __GHOST_URL__/content/images/size/w1600/2021/05/image-1.png 1600w, __GHOST_URL__/content/images/size/w2400/2021/05/image-1.png 2400w" sizes="(min-width: 720px) 720px"/><figcaption><p>A screenshot of the graph database within the Azure Digital Twins explorer</p></figcaption></figure>
<h3 id="sharing-data-with-end-users">Sharing data with end users</h3>
<p><p>Sharing these views with end users can be difficult however - you probably
don&#x27;t want to be sharing the explorer with end users! And what if you want to
share an overview of the current situation with your business users? Well,
this sounds like a perfect use case for PowerBI and Azure Digital Twins.</p></p>
<h3 id="powerbi-to-the-rescue">PowerBI to the rescue</h3>
<p><p>PowerBI is the visualisation tool from Microsoft that allows you to create and
share pre-built reports and data visualisations - niftily, you can use the
output of Python scripts as a data source, allowing us to use the Azure
Digital Twins SDK to create a PowerBI data source.</p></p>
<figure class="kg-card kg-bookmark-card"><a class="kg-bookmark-container" href="https://github.com/Sealjay-clj/powerbi-adt"><div class="kg-bookmark-content"><div class="kg-bookmark-title">Sealjay-clj/powerbi-adt</div><div class="kg-bookmark-description"><p>Querying Azure Digital Twins with PowerBI. Contribute to
Sealjay-clj/powerbi-adt development by creating an account on GitHub.</p></div><div class="kg-bookmark-metadata"><img class="kg-bookmark-icon" src="https://github.githubassets.com/favicons/favicon.svg" alt=""/><span class="kg-bookmark-author">GitHub</span><span class="kg-bookmark-publisher">Sealjay-clj</span></div></div><div class="kg-bookmark-thumbnail"><img src="https://opengraph.githubassets.com/9642f68c9fffaf41f7353e8263423950fa92f07d6101da79bcb0d37bb2bd9eea/Sealjay-clj/powerbi-adt" alt=""/></div></a></figure>
<h3>How do I pull my twins into PowerBI?</h3>
<p>Using the <code>azure-digitaltwins-core</code> python package, this can be done in eight steps!</p>
<ol>
<li>Create an Azure Digital Twin, or use one you already have.</li>
<li>Give yourself access to the data plane - adding some example data - the  <a href="https://github.com/Azure-Samples/digital-twins-explorer/">Azure Digital Twins explorer</a>   example data is a good start.</li>
<li>Create a virtual environment for your Python setup, e.g.  <code>python3 -m venv .venv</code>.</li>
<li>Install the requirements <code>pip install -r requirements-dev.txt</code>.</li>
<li>Copy the path to your virtual environment.</li>
<li><a href="https://docs.microsoft.com/en-us/power-bi/connect-data/desktop-python-scripts#enable-python-scripting?WT.mc_id=AI-MVP-5004204">Enable python scripting</a>   in PowerBI.</li>
<li>Log in to Azure on the CLI with <code>az login</code>.</li>
<li>Import the <strong>powerbi-query.py</strong> file in the  <a href="https://github.com/Sealjay-clj/powerbi-adt">GitHub repository</a>  as a  <a href="https://docs.microsoft.com/en-us/power-bi/connect-data/desktop-python-scripts?WT.mc_id=AI-MVP-5004204#run-your-python-script-and-import-data">PowerBI datasource</a> .</li>
</ol>
<pre><code class="language-python"><p>query_expression = &quot;SELECT * FROM digitaltwins&quot; query_result =
service_client.query_twins(query_expression) twin_list =
pd.DataFrame(query_result)</p></code></pre>
<p>And there you have it. The example query I provide will allow you to query the twin graph - and you can use  <a href="https://docs.microsoft.com/en-us/azure/digital-twins/how-to-query-graph?WT.mc_id=AI-MVP-5004204">the Azure Digital Twins query language</a>   to build on this. Each individual pandas dataframe will appear as a data set.</p>
<h3>How could you extend this?</h3>
<p>So, next time you want to share data from Azure Digital Twins - consider PowerBI! You could use the  <a href="https://docs.microsoft.com/en-gb/azure/cognitive-services/anomaly-detector/?WT.mc_id=AI-MVP-5004204">Anomaly Detector Cognitive service</a>   for example, in combination with PowerBI, to look for buildings that are too hot, too humid, or too cold, and colour code this accordingly.</p>
<p>For a full example,  <a href="https://github.com/Sealjay-clj/powerbi-adt">you can see the repository on GitHub</a> .</p>
<figure class="kg-card kg-image-card kg-card-hascaption"><img src="__GHOST_URL__/content/images/2021/05/image-2.png" class="kg-image" loading="lazy" width="586" height="296"/><figcaption>The list of twins displayed in PowerBI</figcaption></figure>]]></content:encoded>
            <author>spencer@planetaria.tech (Spencer Sharp)</author>
        </item>
        <item>
            <title><![CDATA[Deploying a nextjs application to Azure]]></title>
            <link>undefined/articles/deploying-a-nextjs-application-to-azure</link>
            <guid>undefined/articles/deploying-a-nextjs-application-to-azure</guid>
            <pubDate>Mon, 03 May 2021 22:36:38 GMT</pubDate>
            <description><![CDATA[No description provided]]></description>
            <author>spencer@planetaria.tech (Spencer Sharp)</author>
        </item>
        <item>
            <title><![CDATA[Thinking machines: Azure Digital Twins]]></title>
            <link>undefined/articles/thinking-machines-azure-digital-twins</link>
            <guid>undefined/articles/thinking-machines-azure-digital-twins</guid>
            <pubDate>Wed, 28 Apr 2021 22:07:00 GMT</pubDate>
            <description><![CDATA[No description provided]]></description>
            <content:encoded><![CDATA[<p>I co-authored  <a href="https://www.avanade.com/en/blogs/techs-and-specs/data-and-analytics/thinking-machines-azure-digital-twins">a blog for Avanade Techs and Specs</a> , with a particular focus on Azure Digital Twins for AI and Machine Learning.</p>
<blockquote>
<p>We used  <a href="https://azure.microsoft.com/en-us/services/digital-twins?WT.mc_id=AI-MVP-5004204">Azure Digital Twins (ADT)</a>   to provide memory for our thinking machines, to add context. ADT is an Intelligent Cloud platform provided by Microsoft that allows you to represent real-world things digitally. Every detail can be recorded, tracked, and inspected digitally to give an overview of the state of, places, devises, business processes, and people. At the heart of ADT is the spatial intelligence graphs used to model relationships and interactions between twins.</p>
</blockquote>
<blockquote>
<p>Innovative AI solutions require innovative data storage solutions. In a multi agent world where lots of individual ‘thoughts’ are processing, sometimes simultaneously, it is easy to imagine that it gets difficult to keep track of data. ADT allows us to treat the agent system in an easy to visualise way which mimics the structure of biological brains. Events and actions taken by agents, result in ‘memories’ of data. This data may be useful, or it may be junk, but in order to ‘learn’ it is important for us to assess mistakes as well as successes. Events can be linked to one another, creating a logical pathway of events that occurred, and the data that was produced.</p>
</blockquote>
<p>For more information about Digital Twins for Thinking Machines, the blog post is available in full at  <a href="https://www.avanade.com/en/blogs/techs-and-specs/data-and-analytics/thinking-machines-azure-digital-twins">https://www.avanade.com/en/blogs/techs-and-specs/data-and-analytics/thinking-machines-azure-digital-twins</a>   - for ADT itself, Microsoft&#x27;s documentation is <em>the place</em> to start reading up.</p>
<figure class="kg-card kg-bookmark-card"><a class="kg-bookmark-container" href="https://docs.microsoft.com/en-us/azure/digital-twins/overview?WT.mc_id=AI-MVP-5004204"><div class="kg-bookmark-content"><div class="kg-bookmark-title"><p>What is Azure Digital Twins? - Azure Digital Twins</p></div><div class="kg-bookmark-description"><p>Overview of what can be done with Azure Digital Twins.</p></div><div class="kg-bookmark-metadata"><span class="kg-bookmark-author">Microsoft Docs</span><span class="kg-bookmark-publisher">baanders</span></div></div><div class="kg-bookmark-thumbnail"><img src="https://docs.microsoft.com/en-us/media/logos/logo-ms-social.png" alt=""/></div></a></figure>]]></content:encoded>
            <author>spencer@planetaria.tech (Spencer Sharp)</author>
        </item>
        <item>
            <title><![CDATA[Open Source Models]]></title>
            <link>undefined/articles/oss-open-source-models</link>
            <guid>undefined/articles/oss-open-source-models</guid>
            <pubDate>Tue, 27 Apr 2021 17:53:13 GMT</pubDate>
            <description><![CDATA[No description provided]]></description>
            <content:encoded><![CDATA[<p><p>I&#x27;ve spent a lot of time recently, trying to understand open source models,
and how they cover their costs. I personally <strong>love </strong>open
source, and the community around it.</p></p>
<p><p>But - I think many of us have a tacit understanding of Open Source, and how it
works, and I thought I&#x27;d try and put that down in writing. Without
understanding how it works now, I think it&#x27;s hard to consider how it should
work in the future.</p></p>
<p><p>I&#x27;m interested in your thoughts, please feel free to reach out on twitter!</p></p>
<h3 id="open-source-models">Open Source Models</h3>
<figure class="kg-card kg-image-card"><img src="__GHOST_URL__/content/images/2021/04/image.png" class="kg-image" loading="lazy" width="639" height="648" srcset="__GHOST_URL__/content/images/size/w600/2021/04/image.png 600w, __GHOST_URL__/content/images/2021/04/image.png 639w"/></figure>
<p><em><p>High Corporate Heritage / Low Corporate Ownership - Created as Exhaust
- </p></em><p>A byproduct of the work an organisation needs to do, to get their job done.
For example, Spinnaker was created by Netflix to deliver software, and was
later adopted by Google. Bootstrap is one of the most used web frameworks, and
was called “Twitter Blueprint” before being open sourced externally.</p></p>
<p><em><p>Low Corporate Heritage / Low Corporate Ownership - Left to run free - </p></em><p>Intentionally created by individuals or foundations with an eye to open
sourcing from the-get go. This tends to lead to a collegiate development
process, with heavy not-for-profit links. For example, the Apache Software
foundation maintains Kafka, and the Linux Foundation grows Linux.</p></p>
<p><em><p>High Corporate Heritage / High Corporate Ownership - Pushed from the front
- </p></em><p>Sponsored and supported by a corporation or enterprise with a vested interest
in the success of a technology. For example, Docker and Elastic search promote
an open source community, but broadly speaking, they own the roadmap and the
development of the software.</p></p>
<p><em><p>Low Corporate Heritage / High Corporate Ownership - Pushed to the side
- </p></em><p>A corporation that has a vested interest in the success of a technology, but
wants the open source community to buy-in to it. For example, the .NET
foundation was created by Microsoft to contribute and own the .NET framework,
including related projects like C# .NET core.</p></p>
<h3 id="how-do-they-cover-their-costs">How do they cover their costs?</h3>
<figure class="kg-card kg-image-card"><img src="__GHOST_URL__/content/images/2021/04/image-1.png" class="kg-image" loading="lazy" width="624" height="643" srcset="__GHOST_URL__/content/images/size/w600/2021/04/image-1.png 600w, __GHOST_URL__/content/images/2021/04/image-1.png 624w"/></figure>
<p><em><p>High Corporate Heritage / Low Corporate Ownership - Created as Exhaust
- </p></em><p>Generally initial corporate coverage, then when the product no longer has
corporate usage, it either gets adopted by an open source community, or it
dies.</p></p>
<p><em><p>Low Corporate Heritage / Low Corporate Ownership - Left to run free - </p></em><p>These projects are generally not-for-profits, relying on donations, academic
grants, and sponsorship from enterprises that use the software.</p></p>
<p><em><p>High Corporate Heritage / High Corporate Ownership - Pushed from the front
- </p></em><p>Funds from the corporation producing the software - commonly the corporation
provides a SaaS cloud hosting option, or requests donations for paid features.</p></p>
<p><em><p>Low Corporate Heritage / High Corporate Ownership - Pushed to the side
- </p></em><p>Generally the corporation is trying to use the software to promote another aim</p><ul>
<li>such as Azure Cloud Revenue, or the use of AWS. The corporation funds the
project to indirectly support the aim.</li>
</ul></p>]]></content:encoded>
            <author>spencer@planetaria.tech (Spencer Sharp)</author>
        </item>
        <item>
            <title><![CDATA[MIT Future Compute: A round-up]]></title>
            <link>undefined/articles/mit-future-compute-a-round-up</link>
            <guid>undefined/articles/mit-future-compute-a-round-up</guid>
            <pubDate>Fri, 26 Mar 2021 22:15:00 GMT</pubDate>
            <description><![CDATA[No description provided]]></description>
            <content:encoded><![CDATA[<p><p>Following my blog post about MIT Future Compute, I co-authored a more in depth
article about cloud tech trends and connectivity </p><a href="https://www.avanade.com/en/blogs/techs-and-specs/quantum-computing/mit-future-compute"><p>for Avanade Techs and Specs.</p></a></p>
<figure class="kg-card kg-bookmark-card"><a class="kg-bookmark-container" href="https://sealjay.com/whats-on-the-horizon-2021-mit-future-compute/"><div class="kg-bookmark-content"><div class="kg-bookmark-title"><p>What’s on the horizon? 2021 and beyond</p></div><div class="kg-bookmark-description"><p>I was lucky enough to attend MIT Future Compute 2021, to understand
theconvergence of various technologies, from the Internet of Things to
new(-ish)connectivity options, like 5G and LoRaWAN. Future Compute
2021An examination of the computing landscape, hosted online byMIT
Technology Review Febru…</p></div><div class="kg-bookmark-metadata"><img class="kg-bookmark-icon" src="https://sealjay.com/favicon.png"/><span class="kg-bookmark-author">Sealjay</span><span class="kg-bookmark-publisher">Chris Lloyd-Jones</span></div></div><div class="kg-bookmark-thumbnail"><img src="https://static.ghost.org/v3.0.0/images/publication-cover.png"/></div></a></figure>
<p>The blog covers cloud, 5G, sustainability, quantum, classical compute.</p>
<blockquote><p>If you read nothing else – then know this: everything is converging. AI and
Machine Learning infused the picture from every commentator – and this
demonstrates to us that now is an inflection point, where great things will be
created through the combination, re-combination and experimentation of these
technologies.</p></blockquote>
<blockquote><p>We don’t know where everything will land, but the impact of connectivity, and
sovereign internet, led us to posit four scenarios:</p><br/><ol>
<li>Collaborative Outputs – Knowledge workers leave the city, and work in a
globalized highly connected world</li>
</ol><br/><ol start="2">
<li>Global villages – Cities remain collaborative hubs for new ventures and
technologies, with digital third spaces focusing on messaging</li>
</ol><br/><ol start="3">
<li>Fragmented tribes – Travel becomes limited, and data fragments with the
imposition of internal walls to accommodate data sovereignty within
corporations, leading to competing standards for data sharing</li>
</ol><br/><ol start="4">
<li>Urban foxes – Travel resurges, and corporations re-adapt to cross-border
working, with connectivity focusing on the last mile, supporting the
Intelligent Edge.</li>
</ol></blockquote>
<p><p>For more information about the convergence of everything, the blog post is
available in full at</p><a href="https://www.avanade.com/en/blogs/techs-and-specs/quantum-computing/mit-future-compute"> <p><a href="https://www.avanade.com/en/blogs/techs-and-specs/quantum-computing/mit-future-compute">https://www.avanade.com/en/blogs/techs-and-specs/quantum-computing/mit-future-compute</a></p></a></p>]]></content:encoded>
            <author>spencer@planetaria.tech (Spencer Sharp)</author>
        </item>
        <item>
            <title><![CDATA[Power Automate for individual group notifications]]></title>
            <link>undefined/articles/power-automate-for-individual-group-notifications</link>
            <guid>undefined/articles/power-automate-for-individual-group-notifications</guid>
            <pubDate>Sat, 06 Mar 2021 02:26:59 GMT</pubDate>
            <description><![CDATA[No description provided]]></description>
            <content:encoded><![CDATA[<p>If you&#x27;re like me, you probably wish you got less email! But, equally, you don&#x27;t want to tag a whole group of people in Teams either - starting a whole discussion.</p>
<p>Sometimes I find myself needing to send an urgent message to a group of people, but I want to make sure each individual gets it as a message.</p>
<p>So, I thought I&#x27;d share a handy approach to this using Power Automate, in case this comes in handy for you!</p>
<p><strong>Caveat:</strong> make sure you don&#x27;t overuse this, or send notifications to an overly broad set of users. Over communication can switch your users off from your messages!</p>
<h2>Context</h2>
<p>At my organisation, we&#x27;re currently having an internal competition - right now, we&#x27;re competing for the most steps! This has really brought out that team spirit, but some people are pretty busy.</p>
<p>Sending a notification to people that haven&#x27;t had the time to log their steps is the perfect type of notification to send via Teams - short, sharp, targeted, and actionable.</p>
<h2>What does this use?</h2>
<p>I&#x27;ll be using the <a href="https://docs.microsoft.com/en-us/connectors/teams/?WT.mc_id=AI-MVP-5004204">Microsoft Teams</a> connector for Power Automate. I&#x27;ll send an Adaptive Card to a user from the Flow Bot, with an actionable link - falling back to an email if the Flow Bot is blocked. (One reason not to spam your users!)</p>
<p><a href="https://adaptivecards.io/">Adaptive Cards</a> allows us to write JSON snippets, which are then translated into the native UI of the platform that your message is being received in.</p>
<figure class="kg-card kg-image-card kg-card-hascaption"><img src="__GHOST_URL__/content/images/2021/03/image-18.png" class="kg-image" loading="lazy" width="1086" height="382" srcset="__GHOST_URL__/content/images/size/w600/2021/03/image-18.png 600w, __GHOST_URL__/content/images/size/w1000/2021/03/image-18.png 1000w, __GHOST_URL__/content/images/2021/03/image-18.png 1086w" sizes="(min-width: 720px) 720px"/><figcaption><p>An example of a very basic Adaptive Card, just saying hi!</p></figcaption></figure>
<p>How do we do it? ----------------</p>
<p>I&#x27;ll assume you have some basic familiarity with Power Automate - and if not, Microsoft has just released a &#x27;<a href="https://developer.microsoft.com/en-us/offers/30-days-to-learn-it">30 days to learn it</a>&#x27; learning path for the Power Platform, which covers just these topics!</p>
<p>At a high level, the process is this:</p>
<ul>
<li>Get the users in a group.</li>
<li>Set a template for the adaptive card, the email fallback, and choose the title.</li>
<li>Loop through the users, and try to send the adaptive card.</li>
<li>If the user has the bot blocked, send the email.</li>
</ul>
<p>I&#x27;ll be using a recurring trigger, so I can send this on a weekly basis. In the real-life scenario, I&#x27;m also checking to see if the user has posted steps - I&#x27;ve omitted that here for clarity.</p>
<h2>Setting up the automation</h2>
<p>I&#x27;ve gone to <a href="https://flow.microsoft.com/">flow.microsoft.com</a> and logged into my account.</p>
<p>I&#x27;ll click &#x27;Create&#x27; on the left-hand side and choose &#x27;Scheduled cloud flow.&#x27;</p>
<figure class="kg-card kg-image-card kg-card-hascaption"><img src="__GHOST_URL__/content/images/2021/03/image-19.png" class="kg-image" loading="lazy" width="542" height="416"/><figcaption><p>This scheduled cloud flow option lets you select a recurring frequency</p></figcaption></figure>
<p>Complete the form and select how often you&#x27;d like the flow to run.</p>
<h2>Defining your messages</h2>
<p>Before we go any further, it&#x27;s worth figuring out what messages you&#x27;ll send.</p>
<h3>Adaptive Card</h3>
<p>My adaptive card has a title, a short description, and a button for the user to take action.</p>
<figure class="kg-card kg-image-card"><img src="__GHOST_URL__/content/images/2021/03/image-20.png" class="kg-image" loading="lazy" width="950" height="648" srcset="__GHOST_URL__/content/images/size/w600/2021/03/image-20.png 600w, __GHOST_URL__/content/images/2021/03/image-20.png 950w" sizes="(min-width: 720px) 720px"/></figure>
<p>There are <a href="https://adaptivecards.io/samples/Restaurant.html">tons of samples</a> to
choose from on the adaptive cards site - and you can click &#x27;Try it yourself&#x27; to edit
a card in a WYSIWYG editor.</p>
<p>You can see the code for my card here:</p>
<pre><code>{
  &quot;type&quot;: &quot;AdaptiveCard&quot;,
  &quot;body&quot;: [
    {
      &quot;type&quot;: &quot;TextBlock&quot;,
      &quot;size&quot;: &quot;ExtraLarge&quot;,
      &quot;weight&quot;: &quot;Bolder&quot;,
      &quot;text&quot;: &quot;Your steps are needed!&quot;
    },
    {
      &quot;type&quot;: &quot;ColumnSet&quot;,
      &quot;columns&quot;: [
        {
          &quot;type&quot;: &quot;Column&quot;,
          &quot;items&quot;: [
            {
              &quot;type&quot;: &quot;Image&quot;,
              &quot;style&quot;: &quot;Person&quot;,
              &quot;url&quot;: &quot;https://demeliou.files.wordpress.com/2012/11/marie-curie.jpg&quot;,
              &quot;size&quot;: &quot;Large&quot;
            }
          ],
          &quot;width&quot;: &quot;auto&quot;
        },
        {
          &quot;type&quot;: &quot;Column&quot;,
          &quot;items&quot;: [
            {
              &quot;type&quot;: &quot;TextBlock&quot;,
              &quot;weight&quot;: &quot;Bolder&quot;,
              &quot;text&quot;: &quot;Logging just one step matters!&quot;,
              &quot;wrap&quot;: true
            },
            {
              &quot;type&quot;: &quot;TextBlock&quot;,
              &quot;text&quot;: &quot;We have the highest average steps per day... in it to WIN it! If everyone in the team logged, we&#x27;d be top of the leaderboard.&quot;,
              &quot;wrap&quot;: true
            },
            {
              &quot;type&quot;: &quot;TextBlock&quot;,
              &quot;text&quot;: &quot;Don&#x27;t let the rest of House Curie down, any step logged is a step forward!&quot;,
              &quot;wrap&quot;: true
            }
          ],
          &quot;width&quot;: &quot;stretch&quot;
        }
      ]
    }
  ],
  &quot;actions&quot;: [
    {
      &quot;type&quot;: &quot;Action.OpenUrl&quot;,
      &quot;title&quot;: &quot;Log your steps!&quot;,
      &quot;url&quot;: &quot;https://www.google.com&quot;
    }
  ],
  &quot;$schema&quot;: &quot;http://adaptivecards.io/schemas/adaptive-card.json&quot;,
  &quot;version&quot;: &quot;1.2&quot;
}
</code></pre>
<p>The key point here is the button - created right at the bottom, as an <code>Action.OpenUrl</code> type. You&#x27;ll also notice that my adaptive card doesn&#x27;t separate the data from the template, as the Flow Bot currently doesn&#x27;t support this.</p>
<h3>Email</h3>
<p>I used an <a href="https://html-online.com/editor/">online HTML editor</a> to create a very basic email template, with the same call to action - as well as a short explanatory note as to why the user is receiving the email.</p>
<p>You can see the HTML I used here:</p>
<pre><code>&lt;h1&gt;Your team need you!&lt;/h1&gt;
&lt;table style=&quot;border-collapse: collapse; width: 100%;&quot; border=&quot;1&quot;&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&quot;width: 60.634%;&quot;&gt;
&lt;p&gt;We have the highest average steps per day... in it to WIN it! If everyone in the team logged, we&#x27;d be top of the leaderboard&lt;/p&gt;
&lt;p&gt;Don&#x27;t let the rest of the team downdown, any step logged is a step forward!&lt;/p&gt;
&lt;p&gt;Logging just one step matters!&lt;/p&gt;
&lt;/td&gt;
&lt;td style=&quot;width: 39.366%;&quot;&gt;&lt;img src=&quot;https://demeliou.files.wordpress.com/2012/11/marie-curie.jpg&quot; alt=&quot;&quot; width=&quot;180&quot; height=&quot;200&quot; /&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;&lt;a href=&quot;dummylink&quot;&gt;Click Here to log your Steps&lt;/a&gt;&lt;/p&gt;
&lt;hr /&gt;
&lt;p&gt;&lt;em&gt;We know you&#x27;re busy, and would rather not bother you. We&#x27;ve semt this email because you have &lt;a href=&quot;https://flow.microsoft.com/en-us/blog/microsoft-flow-in-microsoft-teams/&quot;&gt;the Flow Bot&lt;/a&gt; blocked in Microsoft Teams.&amp;nbsp;&lt;/em&gt;&lt;/p&gt;
</code></pre>
<p>Here&#x27;s what the user would receive:</p>
<figure class="kg-card kg-image-card kg-card-hascaption"><img src="__GHOST_URL__/content/images/2021/03/image-21.png" class="kg-image" loading="lazy" width="1276" height="812" srcset="__GHOST_URL__/content/images/size/w600/2021/03/image-21.png 600w, __GHOST_URL__/content/images/size/w1000/2021/03/image-21.png 1000w, __GHOST_URL__/content/images/2021/03/image-21.png 1276w" sizes="(min-width: 720px) 720px"/><figcaption>An email from the automation</figcaption></figure>
<p>Assuming the title is pretty explanatory, I&#x27;ll create three compose actions, and
add in my adaptive card, my email, and my title.</p>
<figure class="kg-card kg-image-card kg-card-hascaption"><img src="__GHOST_URL__/content/images/2021/03/image-22.png" class="kg-image" loading="lazy" width="1250" height="650" srcset="__GHOST_URL__/content/images/size/w600/2021/03/image-22.png 600w, __GHOST_URL__/content/images/size/w1000/2021/03/image-22.png 1000w, __GHOST_URL__/content/images/2021/03/image-22.png 1250w" sizes="(min-width: 720px) 720px"/><figcaption><p>You can see the recurrence trigger, the adaptive card, the email content,
and the title.</p></figcaption></figure>
<p>Looping over the users ----------------------</p>
<p>Now we need to get all of the users in the group I want to message, and then iterate over them!</p>
<p>I use the &#x27;List group members&#x27; connector to get the users in the group.</p>
<figure class="kg-card kg-image-card"><img src="__GHOST_URL__/content/images/2021/03/image-23.png" class="kg-image" loading="lazy" width="1248" height="334" srcset="__GHOST_URL__/content/images/size/w600/2021/03/image-23.png 600w, __GHOST_URL__/content/images/size/w1000/2021/03/image-23.png 1000w, __GHOST_URL__/content/images/2021/03/image-23.png 1248w" sizes="(min-width: 720px) 720px"/></figure>
<p>I then create an &#x27;Apply to each&#x27; action, and add the &#x27;value&#x27; of the &#x27;List group members&#x27;
action to the selected output.</p>
<figure class="kg-card kg-image-card"><img src="__GHOST_URL__/content/images/2021/03/image-24.png" class="kg-image" loading="lazy" width="610" height="290" srcset="__GHOST_URL__/content/images/size/w600/2021/03/image-24.png 600w, __GHOST_URL__/content/images/2021/03/image-24.png 610w"/></figure>
<h2 id="sending-the-messages-and-the-fallback"><p>Sending the messages - and the fallback</p></h2>
<h3 id="the-adaptive-card">The Adaptive Card</h3>
<p><p>To send the Adaptive card, I search for the &#x27;Post your own adaptive card as
the Flow bot to a user&#x27; action, under the Teams connector.</p></p>
<figure class="kg-card kg-image-card"><img src="__GHOST_URL__/content/images/2021/03/image-30.png" class="kg-image" loading="lazy" width="844" height="104" srcset="__GHOST_URL__/content/images/size/w600/2021/03/image-30.png 600w, __GHOST_URL__/content/images/2021/03/image-30.png 844w" sizes="(min-width: 720px) 720px"/></figure>
<p>Once this is created, I insert the Mail variable, for the users email - and I then
insert the data I pre-prepared, with the advanced options expanded.</p>
<ul>
<li>Recipient - Place the Mail output, with the users email</li>
<li>Message - Place the Adapative Cards output</li>
<li>Headline - I use the Title output</li>
<li>Summary - I tend to use the Title output again</li>
<li>IsAlert - I select &#x27;Yes&#x27;</li>
</ul>
<figure class="kg-card kg-image-card"><img src="__GHOST_URL__/content/images/2021/03/image-25.png" class="kg-image" loading="lazy" width="1264" height="660" srcset="__GHOST_URL__/content/images/size/w600/2021/03/image-25.png 600w, __GHOST_URL__/content/images/size/w1000/2021/03/image-25.png 1000w, __GHOST_URL__/content/images/2021/03/image-25.png 1264w" sizes="(min-width: 720px) 720px"/></figure>
<h3 id="and-the-email-fallback">And... the email fallback</h3>
<p>This is probably the trickiest bit, to be honest.</p>
<p><p>Create a &#x27;condition&#x27; action, and in the left hand side of the condition, &#x27;Add
dynamic content&#x27;, select &#x27;Expression&#x27; and then enter
<code>outputs(&#x27;Post_your_own_adaptive_card_as_the_Flow_bot_to_a_user&#x27;)?[&#x27;statusCode&#x27;]</code>
in the box. If you renamed the action after making it, you&#x27;ll need to update
here too.</p></p>
<figure class="kg-card kg-image-card"><img src="__GHOST_URL__/content/images/2021/03/image-26.png" class="kg-image" loading="lazy" width="1242" height="676" srcset="__GHOST_URL__/content/images/size/w600/2021/03/image-26.png 600w, __GHOST_URL__/content/images/size/w1000/2021/03/image-26.png 1000w, __GHOST_URL__/content/images/2021/03/image-26.png 1242w" sizes="(min-width: 720px) 720px"/></figure>
<p><p>Once that&#x27;s complete, enter 403 in the right hand side - so your condition
should be checking whether the status code from posting via the Flow bot, is
equal to 403.</p></p>
<figure class="kg-card kg-image-card"><img src="__GHOST_URL__/content/images/2021/03/image-27.png" class="kg-image" loading="lazy" width="1222" height="408" srcset="__GHOST_URL__/content/images/size/w600/2021/03/image-27.png 600w, __GHOST_URL__/content/images/size/w1000/2021/03/image-27.png 1000w, __GHOST_URL__/content/images/2021/03/image-27.png 1222w" sizes="(min-width: 720px) 720px"/></figure>
<p><p>Hit the ellipses &#x27;...&#x27; in the condition, and select &#x27;Configure run after.&#x27;</p></p>
<figure class="kg-card kg-image-card"><img src="__GHOST_URL__/content/images/2021/03/image-28.png" class="kg-image" loading="lazy" width="578" height="456"/></figure>
<p>Ensure the condition runs if the bot is successful, fails, or is skipped.</p>
<figure class="kg-card kg-image-card"><img src="__GHOST_URL__/content/images/2021/03/image-29.png" class="kg-image" loading="lazy" width="1236" height="456" srcset="__GHOST_URL__/content/images/size/w600/2021/03/image-29.png 600w, __GHOST_URL__/content/images/size/w1000/2021/03/image-29.png 1000w, __GHOST_URL__/content/images/2021/03/image-29.png 1236w" sizes="(min-width: 720px) 720px"/></figure>
<p><p>Now, if the bot fails to send a message - because the user has blocked it - we
should catch that error.</p></p>
<h3 id="sending-the-backup-email">Sending the backup email</h3>
<p><p>For this demo, I&#x27;ll use the &#x27;Send an email&#x27; connector - but you may prefer to
use the &#x27;Send an email from a shared mailbox&#x27; connector.</p></p>
<figure class="kg-card kg-image-card"><img src="__GHOST_URL__/content/images/2021/03/image-31.png" class="kg-image" loading="lazy" width="348" height="114"/></figure>
<p><p>Complete the connector, entering the &#x27;Mail&#x27; output in the &#x27;To&#x27; box, and the
&#x27;Title&#x27; output in the &#x27;Subject&#x27; box.</p></p>
<p><p>Once complete, select the code icon, on the furthest right hand side of the
WYSIWYG editor, to enter HTML entry mode.</p></p>
<figure class="kg-card kg-image-card"><img src="__GHOST_URL__/content/images/2021/03/image-33.png" class="kg-image" loading="lazy" width="1188" height="446" srcset="__GHOST_URL__/content/images/size/w600/2021/03/image-33.png 600w, __GHOST_URL__/content/images/size/w1000/2021/03/image-33.png 1000w, __GHOST_URL__/content/images/2021/03/image-33.png 1188w" sizes="(min-width: 720px) 720px"/></figure>
<p><p>Once you&#x27;re in the HTML editor mode, hit &#x27;Add dynamic content&#x27;, and then
select the HTML email we created earlier.</p></p>
<figure class="kg-card kg-image-card"><img src="__GHOST_URL__/content/images/2021/03/image-36.png" class="kg-image" loading="lazy" width="324" height="68"/></figure>
<figure class="kg-card kg-image-card"><img src="__GHOST_URL__/content/images/2021/03/image-32.png" class="kg-image" loading="lazy" width="1248" height="578" srcset="__GHOST_URL__/content/images/size/w600/2021/03/image-32.png 600w, __GHOST_URL__/content/images/size/w1000/2021/03/image-32.png 1000w, __GHOST_URL__/content/images/2021/03/image-32.png 1248w" sizes="(min-width: 720px) 720px"/></figure>
<h2 id="time-to-run-">Time to run!</h2>
<p><p>Now that you&#x27;ve pulled this all together, it&#x27;s time to try it out! I recommend
testing this with a specially created Team just for this purpose, in case you
want to tweak the formatting.</p></p>
<p><p>Make sure your flow is enabled, and then hit the Test button. Once the flow
has finished running, you should see messages posted in the Run History.</p></p>
<figure class="kg-card kg-image-card"><img src="__GHOST_URL__/content/images/2021/03/image-38.png" class="kg-image" loading="lazy" width="1308" height="136" srcset="__GHOST_URL__/content/images/size/w600/2021/03/image-38.png 600w, __GHOST_URL__/content/images/size/w1000/2021/03/image-38.png 1000w, __GHOST_URL__/content/images/2021/03/image-38.png 1308w" sizes="(min-width: 720px) 720px"/></figure>
<p><p>For users that have blocked the bot, you&#x27;ll see the condition evaluate as
true, and the fallback email will have been sent.</p></p>
<figure class="kg-card kg-image-card"><img src="__GHOST_URL__/content/images/2021/03/image-37.png" class="kg-image" loading="lazy" width="1952" height="1108" srcset="__GHOST_URL__/content/images/size/w600/2021/03/image-37.png 600w, __GHOST_URL__/content/images/size/w1000/2021/03/image-37.png 1000w, __GHOST_URL__/content/images/size/w1600/2021/03/image-37.png 1600w, __GHOST_URL__/content/images/2021/03/image-37.png 1952w" sizes="(min-width: 720px) 720px"/></figure>
<p><p>Thanks for reading - and I hope you find this useful. Remember not to spam
your users!</p></p>
<p><p>If you&#x27;d like something more involved, consider trying out Azure Cognitive
Search!</p></p>
<figure class="kg-card kg-bookmark-card"><a class="kg-bookmark-container" href="https://sealjay.com/cognitive-search-law-part1-indexer/"><div class="kg-bookmark-content"><div class="kg-bookmark-title"><p>Using Cognitive Search to make the law more accessible: Part 1</p></div><div class="kg-bookmark-description"><p>Using Azure Cognitive Search to index UK Law going back to the 1800s, to
make it accessible and comprehensible</p></div><div class="kg-bookmark-metadata"><img class="kg-bookmark-icon" src="https://sealjay.com/favicon.png"/><span class="kg-bookmark-author">Sealjay</span><span class="kg-bookmark-publisher">Chris Lloyd-Jones</span></div></div><div class="kg-bookmark-thumbnail"><img src="https://images.unsplash.com/photo-1521587760476-6c12a4b040da?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=MXwxMTc3M3wwfDF8c2VhcmNofDE3fHxsYXd8ZW58MHx8fA&amp;ixlib=rb-1.2.1&amp;q=80&amp;w=2000"/></div></a></figure>]]></content:encoded>
            <author>spencer@planetaria.tech (Spencer Sharp)</author>
        </item>
        <item>
            <title><![CDATA[3 ways to turn your supply chain into a growth engine]]></title>
            <link>undefined/articles/3-ways-to-turn-your-supply-chain-into-a-growth-engine</link>
            <guid>undefined/articles/3-ways-to-turn-your-supply-chain-into-a-growth-engine</guid>
            <pubDate>Thu, 04 Mar 2021 20:35:00 GMT</pubDate>
            <description><![CDATA[No description provided]]></description>
            <content:encoded><![CDATA[<p><p>I co-authored </p><a href="https://www.avanade.com/en/blogs/avanade-insights/manufacturing/supply-chain-growth-engine"><p>a blog for Avanade Insights</p></a><p>, with a particular focus on responsible business, sustainability, open data,
and service design.</p></p>
<blockquote><p>To shift from recovery to growth in 2021, differentiate your organization by
transforming to a customer-centric supply chain faster than your competitors.
That may seem a daunting prospect; however, you can simplify the process by
focusing on three actions.</p></blockquote>
<p><p>For more information about democratising your data, defining your core
business, or creating a resilient and responsible supply chain, the blog post
is available in full at </p><a href="https://www.avanade.com/en/blogs/avanade-insights/manufacturing/supply-chain-growth-engine"><p><a href="https://www.avanade.com/en/blogs/avanade-insights/manufacturing/supply-chain-growth-engine">https://www.avanade.com/en/blogs/avanade-insights/manufacturing/supply-chain-growth-engine</a></p></a></p>]]></content:encoded>
            <author>spencer@planetaria.tech (Spencer Sharp)</author>
        </item>
        <item>
            <title><![CDATA[Intelligent search at your fingertips: Semantic Search]]></title>
            <link>undefined/articles/intelligent-search-at-your-fingertips</link>
            <guid>undefined/articles/intelligent-search-at-your-fingertips</guid>
            <pubDate>Wed, 03 Mar 2021 10:10:00 GMT</pubDate>
            <description><![CDATA[No description provided]]></description>
            <content:encoded><![CDATA[<p>This week at at Microsoft Ignite,  <a href="https://myignite.microsoft.com/sessions/cb258175-2e65-49fe-919c-23c88dca54c7?source=sessions">Pablo Castro and Jeremy Chapman</a>   covered some  <a href="https://techcommunity.microsoft.com/t5/azure-ai/introducing-semantic-search-bringing-more-meaningful-results-to/ba-p/2175636">amazing new additions to Azure Cognitive Search</a>   - including semantic search, semantic answers, and semantic questions! Everything is semantic!</p>
<p>Semantic Search allows you to offer better answers to search queries, really blowing pure keyword based ranking out of the water. The ranking algorithm tries to rank articles, based on how well they actually answer a query.</p>
<p>The idea behind semantic search is try to understand  <em>what the user wants to</em> achieve - this leverages investments from Bing, and Microsoft Research, to bring the best of other solutions together. </p>
<p>I previously posted about unlocking content using Azure Cognitive Search - and Semantic Search puts these ideas on steroids!</p>
<figure class="kg-card kg-bookmark-card"><a class="kg-bookmark-container" href="https://sealjay.com/unlocking-content-with-summaries-and-insight/"><div class="kg-bookmark-content"><div class="kg-bookmark-title"><p>Unlocking content using Azure Cognitive Search, and Agolo</p></div><div class="kg-bookmark-description"><p>Using Azure Cognitive Search to index information within a document
store, and make it more easily comprehensible &amp; accessible</p></div><div class="kg-bookmark-metadata"><img class="kg-bookmark-icon" src="https://sealjay.com/favicon.png"/><span class="kg-bookmark-author">Sealjay</span><span class="kg-bookmark-publisher">Chris Lloyd-Jones</span></div></div><div class="kg-bookmark-thumbnail"><img src="__GHOST_URL__/content/images/2021/02/cogsearchmain-1.png"/></div></a></figure>
<p><p>The problem with a pure keyword search, is that computers don&#x27;t understand the
context they&#x27;re operating in. If you search for an orange, you&#x27;ll get results
for the fruit, mixed in with the colour.</p></p>
<p><p>For a single keyword, that&#x27;s fine - but semantic search really helps with
areas that get much more difficult.</p></p>
<p><p>Semantic Search makes it possible to understand links across text in a
document, adding Semantic Answers -  allowing you to identify answers in a
passage, or maybe figure out the questions that a document is posing, and
therefore what a person might search for.</p></p>
<p><p>This means we can actually show relevant passages from documents in context,
and hopefully answer a user right in the search results.</p></p>
<p><p>This is a really important extension to Azure Cognitive Search, and </p><a href="https://docs.microsoft.com/en-gb/azure/search/semantic-search-overview"><p>now this is in public preview</p></a><p>, I&#x27;m looking forward to getting my hands on this, so I can show you how to use
this yourself!</p></p>
<h2 id="want-to-know-more">Want to know more?</h2>
<p><p>I&#x27;ll be demonstrating Semantic Search as part of a six-part series on rolling
your own Azure Cognitive Search application!</p></p>
<figure class="kg-card kg-bookmark-card"><a class="kg-bookmark-container" href="https://sealjay.com/cognitive-search-law-part1-indexer/"><div class="kg-bookmark-content"><div class="kg-bookmark-title"><p>Using Cognitive Search to make the law more accessible: Part 1</p></div><div class="kg-bookmark-description"><p>Using Azure Cognitive Search to index UK Law going back to the 1800s, to
make it accessible and comprehensible</p></div><div class="kg-bookmark-metadata"><img class="kg-bookmark-icon" src="https://sealjay.com/favicon.png"/><span class="kg-bookmark-author">Sealjay</span><span class="kg-bookmark-publisher">Chris Lloyd-Jones</span></div></div><div class="kg-bookmark-thumbnail"><img src="https://images.unsplash.com/photo-1521587760476-6c12a4b040da?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=MXwxMTc3M3wwfDF8c2VhcmNofDE3fHxsYXd8ZW58MHx8fA&amp;ixlib=rb-1.2.1&amp;q=80&amp;w=2000"/></div></a></figure>
<p><p>The science behind this investment is pretty amazing too, and Microsoft
Research have published a brilliant write-up of how they actually achieved
these new features.</p></p>
<figure class="kg-card kg-bookmark-card"><a class="kg-bookmark-container" href="https://www.microsoft.com/en-us/research/blog/the-science-behind-semantic-search-how-ai-from-bing-is-powering-azure-cognitive-search/"><div class="kg-bookmark-content"><div class="kg-bookmark-title"><p>The science behind semantic search: How AI from Bing is powering Azure
Cognitive Search - Microsoft Research</p></div><div class="kg-bookmark-description"><p>Azure Cognitive Search is a cloud search service that gives developers
APIs and tools to build rich search experiences over private,
heterogeneous content in web, mobile, and enterprise applications. It
has multiple components, including an API for indexing and querying,
seamless integration through…</p></div><div class="kg-bookmark-metadata"><img class="kg-bookmark-icon" src="https://img-prod-cms-rt-microsoft-com.akamaized.net/cms/api/am/imageFileData/RE1Mu3b?ver=5c31"/><span class="kg-bookmark-author">Microsoft Research</span><span class="kg-bookmark-publisher">Rangan Majumder</span></div></div><div class="kg-bookmark-thumbnail"><img src="https://www.microsoft.com/en-us/research/uploads/prod/2021/03/1400x788_semantic_search_still_no_logo-scaled.jpg"/></div></a></figure>]]></content:encoded>
            <author>spencer@planetaria.tech (Spencer Sharp)</author>
        </item>
        <item>
            <title><![CDATA[Using Cognitive Search to make the law more accessible: Part 1]]></title>
            <link>undefined/articles/cognitive-search-law-part1-indexer</link>
            <guid>undefined/articles/cognitive-search-law-part1-indexer</guid>
            <pubDate>Wed, 03 Mar 2021 02:01:00 GMT</pubDate>
            <description><![CDATA[No description provided]]></description>
            <content:encoded><![CDATA[<p>In a previous blog post,  <a href="https://sealjay.com/unlocking-content-with-summaries-and-insight/">I talked about the endless possibilities that Cognitive Search</a>   gives you, making various datasets more easily accessible.</p>
<p>Now, I&#x27;m going to show you how you can do this yourself, in a six-part blog series, covering Azure Cognitive Search, through to implementing a web application to display your results.</p>
<p>This is following the awesome work  <a href="https://techcommunity.microsoft.com/t5/azure-ai/introducing-semantic-search-bringing-more-meaningful-results-to/ba-p/2175636">Microsoft has done to launch semantic search... and semantic answers</a> !</p>
<p>I&#x27;ll be covering:</p>
<ol>
<li><em>(this blog post)</em> Search - Creating an indexer for Azure Cognitive Search through the Azure portal</li>
<li>Integration - Integrating Azure Cognitive Search with a Python Web Application, using  <a href="https://azuresdkdocs.blob.core.windows.net/$web/python/azure-search-documents/11.1.0/index.html">the Azure SDK for Python</a></li>
<li>Getting a Dataset - How the UK Legislation dataset was crawled and downloaded</li>
<li>User Interface - Creating a layout for your web application using Tailwind CSS, making the most of Azure Cognitive Search features</li>
<li>Infrastructure as Code - Deploying the entire solution using Pulumi and GitHub Actions</li>
<li>Answers - How can we use Azure Cognitive Search to answer questions about the law  <a href="https://docs.microsoft.com/en-gb/azure/search/semantic-search-overview">using Semantic Search</a></li>
</ol>
<p>If you want to skip to the end, the accompanying code repository is already freely  <a href="https://github.com/Sealjay-clj/py-cognitive-search">available on GitHub</a> .</p>
<h2>Background</h2>
<p>Azure Cognitive Search takes your data, wherever it may be - from SQL Server Data, through to Blob Storage, and <a href="__GHOST_URL__/cognitive-search-law-part1-indexer/o-index-sharepoint-online">SharePoint Online</a>.</p>
<p>The power behind Azure Cognitive Search is in the &quot;Document Cracking&quot; - applying logic and AI enrichment to make information usable.</p>
<p>I selected <a href="https://www.legislation.gov.uk/">UK Legislation</a> for this demo, because it meets a few excellent criteria:</p>
<ol>
<li>It&#x27;s freely available for use under licence.</li>
<li>It has a variety of document formats, including modern data (in PDF, XML, RDF, etc), through to scanned in images, embedded within PDF.</li>
<li>It demonstrates the power of Cognitive Search - allowing us to ask questions about the law and figure out the answer.</li>
</ol>
<figure class="kg-card kg-gallery-card kg-width-wide kg-card-hascaption"><div class="kg-gallery-container"><div class="kg-gallery-row"><div class="kg-gallery-image"><img src="__GHOST_URL__/content/images/2021/03/Screenshot-2021-03-03-at-01.06.02.png" width="655" height="911" loading="lazy" srcset="__GHOST_URL__/content/images/size/w600/2021/03/Screenshot-2021-03-03-at-01.06.02.png 600w, __GHOST_URL__/content/images/2021/03/Screenshot-2021-03-03-at-01.06.02.png 655w"/></div><div class="kg-gallery-image"><img src="__GHOST_URL__/content/images/2021/03/Screenshot-2021-03-03-at-01.06.34.png" width="1081" height="908" loading="lazy" srcset="__GHOST_URL__/content/images/size/w600/2021/03/Screenshot-2021-03-03-at-01.06.34.png 600w, __GHOST_URL__/content/images/size/w1000/2021/03/Screenshot-2021-03-03-at-01.06.34.png 1000w, __GHOST_URL__/content/images/2021/03/Screenshot-2021-03-03-at-01.06.34.png 1081w" sizes="(min-width: 720px) 720px"/></div></div></div><figcaption><p>The ancient legislation from legislation.gov.uk, next to the application
we&#x27;ll be building in this series. Image contains public sector information
licensed under the Open Government Licence v3.0.</p></figcaption></figure>
<h2 id="let-s-get-started-">Let&#x27;s get started!</h2>
<p><p>To follow along, I assume you have access to a Microsoft Azure subscription 
<a href="https://azure.microsoft.com/en-gb/free/">or free trial</a>; I also
assume you have access to a dataset with some PDFs (in part 3, I&#x27;ll show you
how to download my dataset.)</p></p>
<h4>Create your Storage Account to be Indexed</h4>
<p>As I mentioned, Azure Cognitive Search supports a variety of data sources. As we have PDFs, I&#x27;ll be creating an Azure Storage Account, and a Blob Storage container.</p>
<p>Azure Storage Accounts <a href="https://portal.azure.com/#create/Microsoft.StorageAccount-ARM">can be found within the Azure Marketplace</a>. Choose your preferred options, then &#x27;Review + create&#x27; your resource.</p>
<figure class="kg-card kg-image-card kg-card-hascaption"><img src="__GHOST_URL__/content/images/2021/03/image-8.png" class="kg-image" loading="lazy" width="776" height="518" srcset="__GHOST_URL__/content/images/size/w600/2021/03/image-8.png 600w, __GHOST_URL__/content/images/2021/03/image-8.png 776w" sizes="(min-width: 720px) 720px"/><figcaption>I went with pretty standard defaults</figcaption></figure>
<p><p>It will take a bit of time for your storage account to be provisioned - and
once it is, you&#x27;ll need to create a Blob Storage container, to hold all of the
files you intend to crack open!</p></p>
<p><p>I prefer to do this </p><a href="https://azure.microsoft.com/en-gb/features/storage-explorer/"><p>using the Azure Storage Explorer</p></a><p>, a free application to manage Azure cloud storage resources, but you can also
open up your new account in the portal. Click on &#x27;Containers&#x27; under Blob service,
and then click &#x27;Container&#x27; and answer the questions which appear.</p></p>
<figure class="kg-card kg-image-card"><img src="__GHOST_URL__/content/images/2021/03/image-9.png" class="kg-image" loading="lazy" width="261" height="72"/></figure>
<figure class="kg-card kg-image-card"><img src="__GHOST_URL__/content/images/2021/03/image-11.png" class="kg-image" loading="lazy" width="87" height="30"/></figure>
<p><strong><em>Don&#x27;t forget to upload some PDFs into the container for indexing!</em></strong></p>
<p>In part 3, I&#x27;ll show you how to download the dataset I&#x27;ve used - or you can skip ahead to the GitHub repo to copy the process.</p>
<h4>Create your Azure Search Resource</h4>
<p>You can  <a href="https://portal.azure.com/#create/Microsoft.Search">find Azure Cognitive Search in the Azure Marketplace</a> .</p>
<p>For the purpose of this demo, I&#x27;ll be creating a &#x27;Basic&#x27; search resource. Be aware that your search tier limits the maximum number of indexes you can create, the size and speed of your physical storage, as well as the cost implication.   <a href="https://docs.microsoft.com/en-us/azure/search/search-sku-tier">Microsoft have a great guide on their portal.</a></p>
<figure class="kg-card kg-image-card"><img src="__GHOST_URL__/content/images/2021/03/image-7.png" class="kg-image" loading="lazy" width="780" height="374" srcset="__GHOST_URL__/content/images/size/w600/2021/03/image-7.png 600w, __GHOST_URL__/content/images/2021/03/image-7.png 780w" sizes="(min-width: 720px) 720px"/></figure>
<p>When we come to part six of the series, <a href="https://docs.microsoft.com/en-us/azure/search/semantic-search-overview">Semantic Search</a> (which
will help us answer questions about the law) is only available for search services
configured on a Standard pricing tier.</p>
<p>Pick your preferred location, tier, and choose a resource group - then &#x27;Review + create&#x27; your resource.</p>
<h4>Create your Data Source</h4>
<p>Now that your search resource is up and running, we need to connect to the Blob Storage container which we created. Click on &#x27;Data sources&#x27; and then &#x27;New Data Source.&#x27;</p>
<figure class="kg-card kg-image-card kg-card-hascaption"><img src="__GHOST_URL__/content/images/2021/03/image-13.png" class="kg-image" loading="lazy" width="475" height="78"/><figcaption>Click on the &#x27;Data sources&#x27; tab</figcaption></figure>
<p>A form will pop up, asking for more information about your data source.</p>
<figure class="kg-card kg-image-card"><img src="__GHOST_URL__/content/images/2021/03/image-16.png" class="kg-image" loading="lazy" width="1057" height="494" srcset="__GHOST_URL__/content/images/size/w600/2021/03/image-16.png 600w, __GHOST_URL__/content/images/size/w1000/2021/03/image-16.png 1000w, __GHOST_URL__/content/images/2021/03/image-16.png 1057w" sizes="(min-width: 720px) 720px"/></figure>
<p><p>See the &#x27;Choose an existing&#x27; connection option? Choose this option, to pick
from other storage accounts you have access to. Then select the relevant
container and confirm your choices.</p></p>
<p>You&#x27;ll need to name the data source - and then click Save.</p>
<h4 id="createyoursearchindex">Create your Search Index</h4>
<p><p>Indexes are the main landing ground for all of the content that you&#x27;ll be
ingesting. This is a critical point - and once you add a field to an index, or
set certain settings, you&#x27;ll need to delete the whole index if you make a
mistake. This isn&#x27;t an issue if you have a few documents indexed but is quite
painful if you have thousands or more.</p></p>
<p><p>In a later blog post, I&#x27;ll show you how to use Pulumi and API calls to set
this up.</p></p>
<p>To create an index, click on the &#x27;Indexes&#x27; tab and then &#x27;New Index.&#x27;</p>
<figure class="kg-card kg-image-card kg-card-hascaption"><img src="__GHOST_URL__/content/images/2021/03/image-4.png" class="kg-image" loading="lazy" width="245" height="85"/><figcaption>Click on &#x27;New Index&#x27;</figcaption></figure>
<p><p>This will take you to a screen where you can add the various fields - that is,
the column names, data types, and settings for your searchable content. This
is the physical structure of your index.</p></p>
<figure class="kg-card kg-image-card kg-card-hascaption"><img src="__GHOST_URL__/content/images/2021/03/image-5.png" class="kg-image" loading="lazy" width="1089" height="399" srcset="__GHOST_URL__/content/images/size/w600/2021/03/image-5.png 600w, __GHOST_URL__/content/images/size/w1000/2021/03/image-5.png 1000w, __GHOST_URL__/content/images/2021/03/image-5.png 1089w" sizes="(min-width: 720px) 720px"/><figcaption>Your Add Index page</figcaption></figure>
<p>Some of <a href="https://docs.microsoft.com/en-us/azure/search/search-what-is-an-index#attributes">these field attributes have important
implications</a></p>
<ul>
<li>the most interesting one that I&#x27;ll point out, is the &quot;suggester.&quot; This allows
you to easily add auto-complete, and auto-suggested terms to your application.</li>
</ul>
<p>For now, in my indexer, I&#x27;ve added fields to store the content, the legislation title, and the original file name.</p>
<figure class="kg-card kg-image-card kg-card-hascaption"><img src="__GHOST_URL__/content/images/2021/03/image-6.png" class="kg-image" loading="lazy" width="1074" height="314" srcset="__GHOST_URL__/content/images/size/w600/2021/03/image-6.png 600w, __GHOST_URL__/content/images/size/w1000/2021/03/image-6.png 1000w, __GHOST_URL__/content/images/2021/03/image-6.png 1074w" sizes="(min-width: 720px) 720px"/><figcaption>The indexer I&#x27;ve used</figcaption></figure>
<p><p>In future, I can imagine wanting to store a summary of the file, maybe even
index individual legislation paragraphs, or allow users to search legislation
over time.</p></p>
<p><strong>All of these scenarios are supported!</strong></p>
<h4 id="createyouraienrichmentskillset">Create your AI Enrichment Skillset</h4>
<p><p>The PDFs I&#x27;ve used are very image-heavy up until the start of the late 20th
century laws. This is likely because legal texts pre-digitisation were scanned
in from paper copies.</p></p>
<p><p>Because of this, we need to handle older PDF documents - pulling out the
images - whilst indexing the text in new documents.</p></p>
<p><p>Cognitive Skills allow us to achieve this. We can use built-in skills from
Microsoft, including Cognitive Services like Computer Vision, or key phrase
extraction; as well as <em>custom skills</em> - like the use of Agolo for text
summaries </p><a href="https://sealjay.com/unlocking-content-with-summaries-and-insight/"><p>that I demonstrated previously</p></a><p>.</p></p>
<p><p>The skillset I&#x27;ve created has two parts - part one will extract text (plain
and structured) from images, and part two will merge all text into one field.</p></p>
<p>The skillset can be found in full below.</p>
<script src="https://gist.github.com/Sealjay-clj/f640c01e6b374cd37dd8e87581c8f895.js"></script>
<h4>Start Indexing</h4>
<p>There are a few different elements  <a href="https://docs.microsoft.com/en-gb/azure/search/search-howto-create-indexers">to creating an indexer.</a>   Microsoft&#x27;s guide is great for this, so I&#x27;ve listed the indexer JSON definition I used in full below, and explained some key sections.</p>
<p>To create your indexer, click on &#x27;Indexers&#x27; and then &#x27;New Indexer&#x27;.</p>
<p>This will take you to a screen where you can fill in a form, or you can paste in the definition for an existing definition from JSON. </p>
<figure class="kg-card kg-image-card kg-card-hascaption"><img src="__GHOST_URL__/content/images/2021/03/image-3.png" class="kg-image" loading="lazy" width="395" height="437"/><figcaption>I assume you&#x27;ll open up the JSON tab too!</figcaption></figure>
<p><p>By default, the existing definition is pretty plain, and it won&#x27;t use the AI
skill we&#x27;ve already defined.</p></p>
<p>The most important parts that you might need to add, are:</p>
<ul><li><p><code>skillsetName</code> - this references the AI Enrichment Skillset we
created before</p></li><li><p><code>imageAction</code> - by default, this is set to None. In our case,
it&#x27;s <code>generateNormalizedImages</code>, which ensures we get back images
for any PDFs that require this.</p></li><li><p><code>outputFieldMappings</code> - we need to make sure that the 
<code>merged_content</code> from our AI Skillset is stored in index field I
made earlier.</p></li></ul>
<p>And here&#x27;s my definition in full.</p>
<script src="https://gist.github.com/Sealjay-clj/00f2ca6238975c712248a7c5d08b2b6a.js"></script>
<p><p>When your indexer is set up in the way you&#x27;d like it, you&#x27;ll need to hit &#x27;Run&#x27;</p><ul>
<li>unless you&#x27;ve chosen to regularly schedule it, and this will populate your
index.</li>
</ul></p>
<figure class="kg-card kg-image-card kg-card-hascaption"><img src="__GHOST_URL__/content/images/2021/03/image-17.png" class="kg-image" loading="lazy" width="60" height="33"/><figcaption>The magic button!</figcaption></figure>
<p><p>This will take a bit of time, influenced by the amount of data you have - and
the user interface is pretty intuitive.</p></p>
<p><strong><em><p>Make sure that you have uploaded some PDFs into the container for
indexing!</p></em></strong></p>
<h4 id="tryitout">Try it out!</h4>
<figure class="kg-card kg-image-card kg-card-hascaption"><img src="__GHOST_URL__/content/images/2021/03/image-2.png" class="kg-image" loading="lazy" width="745" height="184" srcset="__GHOST_URL__/content/images/size/w600/2021/03/image-2.png 600w, __GHOST_URL__/content/images/2021/03/image-2.png 745w" sizes="(min-width: 720px) 720px"/><figcaption>Click on your index, whatever you named it</figcaption></figure>
<p><p>After you leave your index to run, you should be able to return to the pane
for your Search resource, and click on the &#x27;Index&#x27; tab, and then the name of
your index.</p></p>
<p><p>This will open a search explorer - feel free to search for terms and see what
you get back! I got back some information about one of the finance bills I&#x27;d
uploaded.</p></p>
<figure class="kg-card kg-image-card kg-card-hascaption"><img src="__GHOST_URL__/content/images/2021/03/image-1.png" class="kg-image" loading="lazy" width="1058" height="391" srcset="__GHOST_URL__/content/images/size/w600/2021/03/image-1.png 600w, __GHOST_URL__/content/images/size/w1000/2021/03/image-1.png 1000w, __GHOST_URL__/content/images/2021/03/image-1.png 1058w" sizes="(min-width: 720px) 720px"/><figcaption><p>A result for &#x27;Weights&#x27; returning a (slightly uninteresting) result on a
finance act from the UK</p></figcaption></figure>
<p><p>Feel proud of yourself! You&#x27;ve set up and indexed some content, and you&#x27;re
well on the way to making your information usable and accessible.</p></p>
<h2 id="next-time">Next time</h2>
<p><p>And there we have it! We have an index with some (hopefully useful) content,
ready to be integrated into an application!</p></p>
<p><p>In the next post, I&#x27;ll be covering how to integrate Azure Cognitive Search
with the screenshot of the Python Web Application you see above.</p></p>
<figure class="kg-card kg-bookmark-card"><a class="kg-bookmark-container" href="https://github.com/Sealjay-clj/py-cognitive-search/"><div class="kg-bookmark-content"><div class="kg-bookmark-title">Sealjay-clj/py-cognitive-search</div><div class="kg-bookmark-description"><p>A demonstrator of the latest and greatest in Cognitive Search, deployed
in Azure with Python. - Sealjay-clj/py-cognitive-search</p></div><div class="kg-bookmark-metadata"><img class="kg-bookmark-icon" src="https://github.githubassets.com/favicons/favicon.svg"/><span class="kg-bookmark-author">GitHub</span><span class="kg-bookmark-publisher">Sealjay-clj</span></div></div><div class="kg-bookmark-thumbnail"><img src="https://avatars.githubusercontent.com/u/19361656?s=400&amp;v=4"/></div></a></figure>]]></content:encoded>
            <author>spencer@planetaria.tech (Spencer Sharp)</author>
        </item>
        <item>
            <title><![CDATA[Cognitive Search Series]]></title>
            <link>undefined/articles/cognitive-search-series</link>
            <guid>undefined/articles/cognitive-search-series</guid>
            <pubDate>Wed, 03 Mar 2021 00:37:07 GMT</pubDate>
            <description><![CDATA[No description provided]]></description>
            <content:encoded><![CDATA[<p>Dataset:</p>
<ol><li>How to set up an indexer on a blob store - <a href="https://docs.microsoft.com/en-us/azure/search/search-howto-create-indexers">Create an indexer - Azure Cognitive Search | Microsoft Docs</a></li><li>How to integrate with a Python website - <a href="https://azuresdkdocs.blob.core.windows.net/$web/python/azure-search-documents/11.1.0/index.html">Azure Cognitive Search client library for Python — Azure SDK for Python 2.0.0 documentation (windows.net)</a></li></ol>
<p>Appendix</p>
<p>3. How the dataset was created &amp; kept up to date -  How we might use the knowledge store to update this - <a href="https://docs.microsoft.com/en-us/azure/search/cognitive-search-concept-intro">https://docs.microsoft.com/en-us/azure/search/cognitive-search-concept-intro</a> - <a href="https://docs.microsoft.com/en-us/azure/search/search-indexer-overview">https://docs.microsoft.com/en-us/azure/search/search-indexer-overview</a> <a href="https://www.legislation.gov.uk/new/data.feed">https://www.legislation.gov.uk/new/data.feed</a>  <a href="https://likegeeks.com/python-web-crawler-scrapy/#:~:text=Scrapy%20is%20a%20Python%20web%20framework%20that%20you,data%20in%20spreadsheets%20or%20any%20other%20business%20need.">Create your first Python web crawler using Scrapy - Like Geeks</a> </p>
<p>4. Creating a layout with tailwind - <a href="https://tailwindui.com/components?utm_source=tailwindcss&amp;utm_medium=navigation">Tailwind UI - Official Tailwind CSS Components</a> <a href="https://tailwindcss.com/docs/installation#install-tailwind-via-npm"><a href="https://tailwindcss.com/docs/installation">Installation - Tailwind CSS</a> </a> <a href="https://tailwindcss.com/docs/optimizing-for-production#writing-purgeable-html">Optimizing for Production - Tailwind CSS</a></p>
<p>5. Bringing it all together with Pulumi and GitHub Actions - <a href="https://www.pulumi.com/docs/guides/continuous-delivery/github-actions/"><a href="https://www.pulumi.com/docs/guides/continuous-delivery/github-actions/">https://www.pulumi.com/docs/guides/continuous-delivery/github-actions/</a></a></p>
<p>If you want to skip to the end, the accompanying GitHub repository is already freely available.</p>]]></content:encoded>
            <author>spencer@planetaria.tech (Spencer Sharp)</author>
        </item>
        <item>
            <title><![CDATA[Ethical and productivity implications of Intelligent Code Creation]]></title>
            <link>undefined/articles/ethical-and-productivity-implications-of-intelligent-code-creation</link>
            <guid>undefined/articles/ethical-and-productivity-implications-of-intelligent-code-creation</guid>
            <pubDate>Tue, 02 Mar 2021 21:59:00 GMT</pubDate>
            <description><![CDATA[No description provided]]></description>
            <content:encoded><![CDATA[<p><p>I co-authored </p><a href="https://www.avanade.com/en/blogs/techs-and-specs/software-development/intelligent-code-creation"><p>a blog for Avanade Techs and Specs</p></a><p>, focussing on Intelligent Code Creation tools, like Kite and Tabnine.</p></p>
<blockquote><p>Intelligent code creation (ICC) uses machine learning models and embedded
intelligence to provide developer support for writing secure best in class
code. This can involve a developer co-pilot or an ‘AI pair programming’
approach that flags poor development practices or proposes alternative ways to
solve a problem.</p></blockquote>
<blockquote><strong>What is it?</strong><br/><p>This approach provides additional support for existing developers, providing
answers to write complex algorithms, trained on other “best of breed”
codebases. It also enables new developers to become productive on domain
specific code, or closed enterprise owned codebases. Long story short, this is
not an update to automatic code generation, but it is about providing support
in what and how to develop next. AI becomes your assistant, rather than
replacing human ingenuity.</p></blockquote>
<p><p>For more information about Intelligent Code Creation tools, the blog post is
available in full at </p><a href="https://www.avanade.com/en/blogs/techs-and-specs/software-development/intelligent-code-creation"><p><a href="https://www.avanade.com/en/blogs/techs-and-specs/software-development/intelligent-code-creation">https://www.avanade.com/en/blogs/techs-and-specs/software-development/intelligent-code-creation</a></p></a></p>]]></content:encoded>
            <author>spencer@planetaria.tech (Spencer Sharp)</author>
        </item>
        <item>
            <title><![CDATA[Oral culture and the rise of literacy]]></title>
            <link>undefined/articles/oral-culture-and-the-rise-of-literacy</link>
            <guid>undefined/articles/oral-culture-and-the-rise-of-literacy</guid>
            <pubDate>Fri, 26 Feb 2021 15:48:46 GMT</pubDate>
            <description><![CDATA[No description provided]]></description>
            <content:encoded><![CDATA[<p><p>A colleague recently shared an interesting blog post about the historical
anomaly of written culture - and it gave me a lot to think about. I liked many
of the conclusions, but some elements need continued observation.</p></p>
<figure class="kg-card kg-bookmark-card"><a class="kg-bookmark-container" href="https://zeynep.substack.com/p/the-clubhouse-app-and-the-rise-of"><div class="kg-bookmark-content"><div class="kg-bookmark-title"><p>The Clubhouse App and the Rise of Oral Psychodynamics</p></div><div class="kg-bookmark-description"><p>It’s written/print culture that’s the recent historical anomaly, and
still a minority of the world</p></div><div class="kg-bookmark-metadata"><img class="kg-bookmark-icon" src="https://bucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com/public/images/5b8e6eea-e41f-44ce-b6bc-3efb15007258/apple-touch-icon-1024x1024.png"/><span class="kg-bookmark-author">Insight</span><span class="kg-bookmark-publisher">zeynep</span></div></div><div class="kg-bookmark-thumbnail"><img src="https://cdn.substack.com/image/fetch/w_1200,c_limit,f_jpg,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F48c346c7-e51b-4961-b7b3-47f88a8abba8_1096x1536.jpeg"/></div></a></figure>
<h3 id="inclusion-in-the-workforce">Inclusion in the workforce</h3>
<p><p>I&#x27;ve sometimes wondered if the recent inclusion of different neurodiversities
in the workforce &amp; society is down to acceptance, or if societal
conditions were fertile by happenstance, rather than design.</p></p>
<p><p>I posit that a rise in literate culture, while exclusionary to some with
dyslexia (although this has improved over time with education and
accessibility tools), allows people with non-traditional emotional &amp;
communication norms to participate in discussions, eduction, activities, and
events - without being seen as &quot;slow&quot; or &quot;weird.&quot;</p></p>
<p><p>Some communities with lower rates of diagnosis for autism and other
communication differences, have higher rates of current oral tradition and
usage.</p></p>
<p><p>If I look at the rise of television culture, and the rise of radio - history
shows that this affected popular perception of politicians, leading to an
increase in photogenic politicians, and particularly the rise of people with
the abilities to lead in public debate.</p></p>
<p><p>I personally linked this to the idea that the medium began to matter as much
as the message - and a return to Twitter and Email has added an element of
healthy debate.</p></p>
<h3 id="oral-traditions">Oral traditions</h3>
<p><p>Oral traditions are, exactly as the article intuits, a code of conduct in use
across time and society. These are passed on through word of mouth, from
generation to generation.</p></p>
<p><p>This means that societies create customs and social norms, but they are only
known by those people who are taught the norms. These can&#x27;t be found - they
need to be taught. This is a slow process, and contrary to the way mass media
works today.</p></p>
<p><p>The rise of literacy has led to stability - it&#x27;s given us the written word,
and accountability. Literacy allows for us to see what our leaders get up to,
how we follow ethical standards, how we make sure the law is applied equally
to all, in a non-arbitrary fashion.</p></p>
<p><p>Mass media allows for broader society to be engaged and react, as opposed to
tools like clubhouse, which are very &quot;in the moment&quot; tools, and close off the
pool of activities and cultural processes like innovation.</p></p>
<p><p>If we take the very shaky premise that all progress is good progress - or even
say <em>some </em>progress is better than none - I think society benefits from
an open pool of innovation, and literacy allows us to include more groups than
those we exclude.</p></p>
<h3 id="conclusion">Conclusion</h3>
<p><p>My main conclusion is - Clubhouse is a good thing. It&#x27;s another medium for
debate.</p></p>
<p><p>I worry that too much of a shift to oral culture, with limited recording and
transmission, or participation via text, will limit societal revolution and
changes.</p></p>
<p><p>Zeynep talks about a tension between literate classes that hold power - I&#x27;d
also say that literacy enfranchises some previously excluded elements of
society, and it&#x27;s one to watch.</p></p>]]></content:encoded>
            <author>spencer@planetaria.tech (Spencer Sharp)</author>
        </item>
        <item>
            <title><![CDATA[What's on the horizon? 2021 and beyond]]></title>
            <link>undefined/articles/whats-on-the-horizon-2021-mit-future-compute</link>
            <guid>undefined/articles/whats-on-the-horizon-2021-mit-future-compute</guid>
            <pubDate>Thu, 25 Feb 2021 19:56:21 GMT</pubDate>
            <description><![CDATA[No description provided]]></description>
            <content:encoded><![CDATA[<p>I was lucky enough to attend MIT Future Compute 2021, to understand the convergence of various technologies, from the Internet of Things to new(-ish) connectivity options, like 5G and LoRaWAN.</p>
<figure class="kg-card kg-bookmark-card"><a class="kg-bookmark-container" href="https://event.technologyreview.com/future-compute-2021/home"><div class="kg-bookmark-content"><div class="kg-bookmark-title">Future Compute 2021</div><div class="kg-bookmark-description"><p>An examination of the computing landscape, hosted online by MIT
Technology Review February 10-11, 2021</p></div><div class="kg-bookmark-metadata"><img class="kg-bookmark-icon" src="https://assets.swoogo.com/uploads/tiny/842456-600074017c29b.png"/><span class="kg-bookmark-author">Future Compute</span></div></div><div class="kg-bookmark-thumbnail"><img src="https://assets.swoogo.com/uploads/full/685594-5f7bb54135215.jpg"/></div></a></figure>
<p>Particularly as Microsoft Ignite 2021 kicks off (I&#x27;m particularly excited about  <a href="https://myignite.microsoft.com/sessions/cb258175-2e65-49fe-919c-23c88dca54c7?source=sessions">the session on Semantic Search</a>   - the power of understanding at your fingertips!), I thought it would be useful to explore some of the takeaways from Future Compute.</p>
<h2>Everything is converging</h2>
<p>I&#x27;m sure this gets said every year - and like every other year, it continues to be ever more true.</p>
<p>Surprisingly, AI and Machine Learning don&#x27;t get a look in - partly because to my mind, they infuse every aspect of the diagram.</p>
<p>We can see the continued rise of cloud providers, who are continuously onboarding and updating their Quantum and High-Performance Compute services. On the flipside, you can see the emergence of an open internet coalition - with organisations like DFINITY and SOLID attempting to swing the pendulum towards decentralisation.</p>
<figure class="kg-card kg-image-card kg-card-hascaption"><img src="__GHOST_URL__/content/images/2021/02/diagram.png" class="kg-image" alt="A venn diagram showing: energy consumption, processing - then open internet with ledger inside; then Cloud with thinking achines inside; then quantum intersecting with cloud. Then Intelligent edge with IoT inside, and intersecting with Icloud and open internet." loading="lazy" width="1101" height="955" srcset="__GHOST_URL__/content/images/size/w600/2021/02/diagram.png 600w, __GHOST_URL__/content/images/size/w1000/2021/02/diagram.png 1000w, __GHOST_URL__/content/images/2021/02/diagram.png 1101w" sizes="(min-width: 720px) 720px"/><figcaption>Credit: Fergus Kidd &amp; Chris Lloyd-Jones</figcaption></figure>
<p>This was an early draft from a related piece I&#x27;m working on for Avanade - with inputs
from Fergus Kidd.</p>
<h2>We&#x27;re waiting for the pieces to land</h2>
<p>  With speakers from Microsoft, IBM, AWS, and Google on the one hand - and consultancies, academia, start-ups and new players on the other, I felt like there was an excellent overview of points of view.</p>
<p>The commonality was - no one had a clear answer. To my mind, we&#x27;re looking to see what happens around sovereign internet, and connectivity.</p>
<p>Sovereign internet - whether it results in global collaboration, or global fragmentation - can be demonstrated through moves like Facebook v Australia, or the various different Azure Cloud deployments (Azure Public, Azure China, and previously, German Azure.)</p>
<p>Connectivity - seems to driven by whether a post-COVID world will end up in a return to the rural areas, or centralisation in cities; and continued globalisation. If people jump at the chance to work remotely, and live in the countryside, then we&#x27;ll see an outflux of knowledge workers from the city, leading to increased dominance of virtual spaces.</p>
<p>I posit four potential scenarios - we&#x27;ll likely end up with a combination of these four, but really interesting to see the trends in the market.</p>
<figure class="kg-card kg-image-card kg-card-hascaption"><img src="__GHOST_URL__/content/images/2021/02/image-25.png" class="kg-image" loading="lazy" width="661" height="651" srcset="__GHOST_URL__/content/images/size/w600/2021/02/image-25.png 600w, __GHOST_URL__/content/images/2021/02/image-25.png 661w"/><figcaption>Credit: Chris Lloyd-Jones</figcaption></figure>
<p>Oh well! This is my attempt to see where things are going - catch you at ignite!</p>]]></content:encoded>
            <author>spencer@planetaria.tech (Spencer Sharp)</author>
        </item>
        <item>
            <title><![CDATA[Tech Talent 2021]]></title>
            <link>undefined/articles/tech-talent-2021</link>
            <guid>undefined/articles/tech-talent-2021</guid>
            <pubDate>Wed, 24 Feb 2021 17:00:00 GMT</pubDate>
            <description><![CDATA[No description provided]]></description>
            <content:encoded><![CDATA[<p><p>I was lucky enough to present at Tech Talent 2021- speaking about
CognitiveSearch, XR, VR and the Future of Work!</p></p>
<figure class="kg-card kg-embed-card"><blockquote class="twitter-tweet"><p>The wait is over -  <a href="https://twitter.com/hashtag/TechTalent2021?src=hash&amp;ref_src=twsrc%5Etfw">#TechTalent2021</a>   takes place TODAY! 🎉</p><p>We’re so excited to welcome all of these companies to Tech Talent 2021.</p><p>Looking forward to seeing you between 1pm and 7pm on Hopin! 👩‍💻 <a href="https://twitter.com/hashtag/tech?src=hash&amp;ref_src=twsrc%5Etfw">#tech</a> <a href="https://twitter.com/hashtag/event?src=hash&amp;ref_src=twsrc%5Etfw">#event</a> <a href="https://twitter.com/hashtag/jobs?src=hash&amp;ref_src=twsrc%5Etfw">#jobs</a> <a href="https://twitter.com/avanadeuki?ref_src=twsrc%5Etfw">@avanadeuki</a> <a href="https://t.co/NG42T2iUmF">https://t.co/NG42T2iUmF</a> <a href="https://t.co/ZVZjjDvxbR">pic.twitter.com/ZVZjjDvxbR</a>
— Software City (@SunSoftCity) </p><a href="https://twitter.com/SunSoftCity/status/1364485287355768832?ref_src=twsrc%5Etfw"><p>February 24, 2021</p></a></blockquote><script async="" src="https://platform.twitter.com/widgets.js" charset="utf-8"></script></figure>]]></content:encoded>
            <author>spencer@planetaria.tech (Spencer Sharp)</author>
        </item>
        <item>
            <title><![CDATA[Extracting transcripts and insights from videos in Python]]></title>
            <link>undefined/articles/extracting-transcripts-and-insights-from-videos-in-python</link>
            <guid>undefined/articles/extracting-transcripts-and-insights-from-videos-in-python</guid>
            <pubDate>Thu, 18 Feb 2021 20:46:51 GMT</pubDate>
            <description><![CDATA[No description provided]]></description>
            <content:encoded><![CDATA[<p>Compared to YouTube from Google, and Twitch from Amazon, Microsoft&#x27;s experiments with media have been... ill-feted in the past. From the shuttering of the Zune service in 2012, and the closure of the Mixer streaming service in July 2020, the track record doesn&#x27;t look great.</p>
<p><strong>But</strong> - Microsoft actually has a powerhouse of services for managing and handling video in the cloud. Enter  <a href="https://docs.microsoft.com/en-us/azure/media-services/video-indexer/">Azure Media Services Video Indexer</a>   - a service which brings together the whole gamut of Azure Cognitive Services, including translation, and Computer Vision.</p>
<p>In the UK, we&#x27;re still in lockdown due to the pandemic - so I&#x27;ve been trying to think of ways to help people stay connected, without burning out. This led me to work on a social video project to allow people to upload videos from their phone, automatically transcribing and posting them to teams.</p>
<p>In the course of this project ( <em>more detail of which will be in a forthcoming blog post series, around deploying Python Web Applications to Azure</em> ) - I realised that the Python SDK for Video Indexer is a bit lacking. I found a great package by BK Lim, but there isn&#x27;t an official SDK.</p>
<figure class="kg-card kg-gallery-card kg-width-wide kg-card-hascaption"><div class="kg-gallery-container"><div class="kg-gallery-row"><div class="kg-gallery-image"><img src="__GHOST_URL__/content/images/2021/02/Screenshot-2021-02-18-at-20.31.12.png" width="1280" height="1008" loading="lazy" srcset="__GHOST_URL__/content/images/size/w600/2021/02/Screenshot-2021-02-18-at-20.31.12.png 600w, __GHOST_URL__/content/images/size/w1000/2021/02/Screenshot-2021-02-18-at-20.31.12.png 1000w, __GHOST_URL__/content/images/2021/02/Screenshot-2021-02-18-at-20.31.12.png 1280w" sizes="(min-width: 720px) 720px"/></div><div class="kg-gallery-image"><img src="__GHOST_URL__/content/images/2021/02/Screenshot-2021-02-18-at-20.31.40.png" width="1628" height="1576" loading="lazy" srcset="__GHOST_URL__/content/images/size/w600/2021/02/Screenshot-2021-02-18-at-20.31.40.png 600w, __GHOST_URL__/content/images/size/w1000/2021/02/Screenshot-2021-02-18-at-20.31.40.png 1000w, __GHOST_URL__/content/images/size/w1600/2021/02/Screenshot-2021-02-18-at-20.31.40.png 1600w, __GHOST_URL__/content/images/2021/02/Screenshot-2021-02-18-at-20.31.40.png 1628w" sizes="(min-width: 720px) 720px"/></div></div></div><figcaption>A social video project I&#x27;ve been working on</figcaption></figure>
<p><p>For most purposes, BK Lim&#x27;s library would be great, but with the number of
queries and callbacks I expected, being able to run the library asynchronously
for me was a must.</p></p>
<h3 id="aio-videoindexer-allows-you-to-use-azure-media-services-in-python"><p>aio-videoindexer allows you to use Azure Media Services in Python</p></h3>
<p><p>I thought it might be useful for others, so I&#x27;ve spun the library out into 
<a href="https://pypi.org/project/aio-videoindexer/">a package on PyPy</a>.</p></p>
<figure class="kg-card kg-bookmark-card"><a class="kg-bookmark-container" href="https://pypi.org/project/aio-videoindexer/"><div class="kg-bookmark-content"><div class="kg-bookmark-title">aio-videoindexer</div><div class="kg-bookmark-description"><p>An async video indexer package for querying Microsoft Media Services
Video Indexer in Python.</p></div><div class="kg-bookmark-metadata"><img class="kg-bookmark-icon" src="https://pypi.org/static/images/favicon.6a76275d.ico"/><span class="kg-bookmark-author">PyPI</span></div></div><div class="kg-bookmark-thumbnail"><img src="https://pypi.org/static/images/twitter.90915068.jpg"/></div></a></figure>
<p>This doesn&#x27;t implement the full range of the <a href="https://api-portal.videoindexer.ai/docs/services/Operations/operations/Get-Video-Access-Token?">Video Indexer Operations API</a>
, but for uploading from blob storage, getting video display widgets, and listing
out video information - this should be a good start!</p>
<script src="https://gist.github.com/Sealjay-clj/0e1273cc038646a81c0aac482b9ca170.js"></script>
<p>I&#x27;ve added <a href="https://aio-videoindexer.readthedocs.io/en/latest/">basic documentation to
ReadTheDocs,</a> and you can
see this package in action in <a href="https://github.com/sealjay-clj/teams-vid">the Teams-Vid
repository</a> . In an upcoming blog
post, I&#x27;ll show how Video Indexing can be used to power a social video
application made with Python.</p>
<figure class="kg-card kg-image-card kg-card-hascaption"><img src="__GHOST_URL__/content/images/2021/02/image-24.png" class="kg-image" loading="lazy" width="1244" height="686" srcset="__GHOST_URL__/content/images/size/w600/2021/02/image-24.png 600w, __GHOST_URL__/content/images/size/w1000/2021/02/image-24.png 1000w, __GHOST_URL__/content/images/2021/02/image-24.png 1244w" sizes="(min-width: 720px) 720px"/><figcaption>A list of uploaded videos</figcaption></figure>
<figure class="kg-card kg-bookmark-card"><a class="kg-bookmark-container" href="https://github.com/sealjay-clj/teams-vid"><div class="kg-bookmark-content"><div class="kg-bookmark-title">Sealjay-clj/teams-vid</div><div class="kg-bookmark-description"><p>Web application for mobile and desktop to quickly post videos for your
team. Demonstrates Starlette, and Azure Media Services Video Indexer.
Lets people record themselves on the fly, to stay in syn...</p></div><div class="kg-bookmark-metadata"><img class="kg-bookmark-icon" src="https://github.githubassets.com/favicons/favicon.svg"/><span class="kg-bookmark-author">GitHub</span><span class="kg-bookmark-publisher">Sealjay-clj</span></div></div><div class="kg-bookmark-thumbnail"><img src="https://avatars.githubusercontent.com/u/19361656?s=400&amp;v=4"/></div></a></figure>]]></content:encoded>
            <author>spencer@planetaria.tech (Spencer Sharp)</author>
        </item>
        <item>
            <title><![CDATA[Unlocking content with summaries and insights!]]></title>
            <link>undefined/articles/unlocking-content-with-summaries-and-insight</link>
            <guid>undefined/articles/unlocking-content-with-summaries-and-insight</guid>
            <pubDate>Wed, 10 Feb 2021 16:09:57 GMT</pubDate>
            <description><![CDATA[No description provided]]></description>
            <content:encoded><![CDATA[<p>Cognitive Search is an awesome service that allows you to take the documents and information you have, wherever it may be, index it, and apply additional transforms to make the information searchable and usable - through the <a href="https://docs.microsoft.com/en-us/azure/search/cognitive-search-concept-intro">use of cognitive skills</a>.</p>
<p>I&#x27;ve been lucky enough to be working with Cognitive Search since 2018 - but although I run training sessions, and tinker with the service out of hours, a lot of this has been inextricably bound up with my day to day work. You know how it is - <em>am I allowed to talk about this</em>?</p>
<p>Well, I have permission to share (some) of what I&#x27;ve been working on! This will be less code heavy, but I&#x27;ll explain how a brand new solution would work in practice, and what the architecture would look like.</p>
<p>The impact of this approach can be phenomenal - I was part of a team working with a large financial services company to index their documents, and we saw new starters save <strong>53 seconds per search</strong> when finding new documents. Imagine how much that adds up!</p>
<p>Follow on to find out what we did, what we used, and how you can do this yourself!</p>
<h3>What did we do?</h3>
<p>We created an Azure Web Application which allows users to type in a free text search query, providing auto-suggest for common search terms, and displaying the results.</p>
<p>To go beyond normal search, we integrated:</p>
<ul>
<li>Agolo (<a href="https://www.agolo.com/">an automatic summarisation tool</a>) to summarise the text of the document</li>
<li><a href="https://docs.microsoft.com/en-gb/azure/cognitive-services/text-analytics/how-tos/text-analytics-how-to-entity-linking?tabs=version-3">The Azure Text Analytics API</a> to identify people, and locations mentioned</li>
<li><a href="https://docs.microsoft.com/en-us/azure/cognitive-services/computer-vision/overview#analyze-images-for-insight">The Azure Computer Vision API</a> to caption images</li>
</ul>
<p><img src="__GHOST_URL__/content/images/2021/02/cogsearchdesign.png" alt=""/></p>
<p><img src="__GHOST_URL__/content/images/2021/02/cogsearchmain.png" alt=""/></p>
<p><img src="__GHOST_URL__/content/images/2021/02/cogsearchoverview.png" alt=""/></p>
<p>This is an anonymised set of screenshots to demonstrate the application (used with permission from Avanade Inc)</p>
<h3>How does it work?</h3>
<p><img src="__GHOST_URL__/content/images/2021/02/cognitive_search_application.png" alt=""/></p>
<p>Generated with <a href="https://diagrams.mingrammer.com/">Diagrams for Python</a></p>
<h3>Getting the documents into Blob Storage</h3>
<p>All documents sit in SharePoint Online within Office 365. At the time of creating this solution, there was no SharePoint connector for Cognitive Search - so we copied the entirety of the library to be indexed to Blob Storage, and then created a Logic App to copy new and updated files to Blob Storage as it happened.</p>
<h3>Intelligence</h3>
<p>We created an Azure Function that accepted input from Cognitive Search at the Document Cracking phase, and then sent this to the Agolo <a href="https://dev.agolo.com/docs/services/570d7b4f88b6e5116cdf6a17/operations/570d7b5188b6e508dcfb1c90">Bullet Summarizer API</a> to be summarised. For example - taking a whole 60 page whitepaper on AI, and summarising it in three paragraphs. This Azure Function is registered as a <a href="https://docs.microsoft.com/en-us/azure/search/cognitive-search-custom-skill-web-api">Custom Web API</a>.</p>
<p>We then used the <a href="https://docs.microsoft.com/en-us/azure/search/cognitive-search-predefined-skills#built-in-skills">built-in skills</a> for Computer Vision and Text Analytics.</p>
<h3>Indexing the files</h3>
<p>We created an <a href="https://docs.microsoft.com/en-us/azure/search/search-get-started-portal">Index in Cognitive Search</a> which used the Blob Storage as a data source.</p>
<p>As part of the indexing process, the Cognitive Skills we added earlier, and the Custom Skill we created, are applied to the documents, to produce an index.</p>
<figure class="kg-card kg-image-card kg-card-hascaption"><img src="__GHOST_URL__/content/images/2021/02/image-21.png" class="kg-image" loading="lazy" width="1236" height="244" srcset="__GHOST_URL__/content/images/size/w600/2021/02/image-21.png 600w, __GHOST_URL__/content/images/size/w1000/2021/02/image-21.png 1000w, __GHOST_URL__/content/images/2021/02/image-21.png 1236w" sizes="(min-width: 720px) 720px"/><figcaption>The Document Cracking Pipeline for this Solution</figcaption></figure>
<script src="https://gist.github.com/Sealjay-clj/428a5b9451241b7247abc8a1a718af0f.js"></script>
<p><p>And there we have it! I hope this example showed you how easy it is to set up
and use Azure Cognitive Search to create intelligent applications, and extract
that is currently trapped in your documents.</p></p>
<figure class="kg-card kg-image-card kg-card-hascaption"><img src="__GHOST_URL__/content/images/2021/02/cogsearchoverview-1.png" class="kg-image" loading="lazy" width="543" height="447"/><figcaption>The search results for our knowledge finder example</figcaption></figure>
<p>I showed you how Cognitive Services and Agolo could be used to summarise documents</p>
<ul>
<li>and in a future post, I&#x27;ll explain <a href="https://docs.microsoft.com/en-us/azure/media-services/video-indexer/video-indexer-overview">how to use Azure Media Services Video Indexer</a>
to pull insight out of video and audio files.</li>
</ul>
<figure class="kg-card kg-image-card kg-card-hascaption"><img src="__GHOST_URL__/content/images/2021/02/image-23.png" class="kg-image" loading="lazy" width="419" height="267"/><figcaption>The information pyramid</figcaption></figure>
<p></p>]]></content:encoded>
            <author>spencer@planetaria.tech (Spencer Sharp)</author>
        </item>
        <item>
            <title><![CDATA[CLI wizardry - Bing News Search on the fly]]></title>
            <link>undefined/articles/bing-news-search-cli</link>
            <guid>undefined/articles/bing-news-search-cli</guid>
            <pubDate>Wed, 10 Feb 2021 01:47:31 GMT</pubDate>
            <description><![CDATA[No description provided]]></description>
            <content:encoded><![CDATA[<p>// TODO: Check against sealjay.com</p>

<p>You&#x27;ve probably heard of Bing, one of the largest search engines around, love it or loathe it. But did you know it has a nifty API? Bing Search APIs have moved recently out of Cognitive Services (<a href="https://docs.microsoft.com/en-us/azure/cognitive-services/bing-web-search/bing-api-comparison">as of October 30, 2020</a>).</p>
<p><p>These APIs include local business search, news, and image search. Wouldn&#x27;t it
be cool if we could use Bing News Search to quickly and easily find out what&#x27;s
going on in the world? Maybe you want to quickly check up on a coffee break,
remove the visuals from your pandemic doom-scrolling, or you need inspiration
for a tweet!</p></p>
<p><p>Today, I&#x27;m going to show you how to use Python to create a Command Line
Interface (CLI) to search for trending articles, phrases you&#x27;re particularly
interested in, or just see what&#x27;s happening in the world of business.</p></p>
<figure class="kg-card kg-image-card kg-card-hascaption"><img src="__GHOST_URL__/content/images/2021/02/image-3.png" class="kg-image" loading="lazy" width="924" height="451" srcset="__GHOST_URL__/content/images/size/w600/2021/02/image-3.png 600w, __GHOST_URL__/content/images/2021/02/image-3.png 924w" sizes="(min-width: 720px) 720px"/><figcaption><p>An example of a search for the &quot;future of computing&quot; with this handy tool!</p></figcaption></figure>

<hr/>
<h2 id="what-you-ll-need">What you&#x27;ll need</h2>
<ul><li><p>An Azure tenant (<a href="https://azure.microsoft.com/en/free/">create a free
account</a> if you don&#x27;t have one)</p></li><li>Basic Python Proficiency</li><li>A local installation of Git</li><li>A local installation of your preferred Python distribution</li><li>Visual Studio Code (or similar code editor)</li></ul>
<p><p>I&#x27;ll walk you through the process of setting up a Bing Search API including
the News feature, and then walk you through the application.</p></p>
<hr/>
<h2 id="getting-started">Getting Started</h2>
<h3 id="creating-your-bing-news-resource">Creating your Bing News Resource</h3>
<p><a href="https://portal.azure.com/#create/microsoft.bingsearch"><p>Use this link to jump directly to the Bing Search marketplace template</p></a><p>, or search for Bing Search v7 in the marketplace.</p></p>
<p><p>However you find this, creating the resource will need you to be familiar with
the pricing tier. Not all of the tiers include Bing News Search.</p></p>
<p><p>For the purposes of this exercise, I&#x27;ve used the &#x27;Free&#x27; instance, which allows
up to 1,000 free transactions per month at the time of writing - but if you
intend to use the tool often, you&#x27;ll want to look at 
<a href="https://www.microsoft.com/en-us/bing/apis/pricing">the paid tiers</a>
.</p></p>
<figure class="kg-card kg-image-card kg-card-hascaption"><img src="__GHOST_URL__/content/images/2021/02/image-8.png" class="kg-image" loading="lazy" width="701" height="355" srcset="__GHOST_URL__/content/images/size/w600/2021/02/image-8.png 600w, __GHOST_URL__/content/images/2021/02/image-8.png 701w"/><figcaption>Select the Free pricing tier</figcaption></figure>
<p><p>Once you&#x27;ve read the privacy statement, filled in the form, and hit create,
the resource will deploy. Time to get a coffee!</p></p>
<h3 id="getting-your-bing-news-endpoint-and-keys"><p>Getting your Bing News Endpoint and Keys</p></h3>
<p><p>When your resource is deployed, open it in the Azure Portal, and look at the
Overview screen.</p></p>
<figure class="kg-card kg-image-card kg-card-hascaption"><img src="__GHOST_URL__/content/images/2021/02/image-14.png" class="kg-image" loading="lazy" width="932" height="492" srcset="__GHOST_URL__/content/images/size/w600/2021/02/image-14.png 600w, __GHOST_URL__/content/images/2021/02/image-14.png 932w" sizes="(min-width: 720px) 720px"/><figcaption>Your deployment should look similar to this.</figcaption></figure>
<p><p>Take a note of the Endpoint, as you&#x27;ll need this URL for the application. My
endpoint isn&#x27;t part of a multi-service subscription, so it doesn&#x27;t have the
region in the URL, so it&#x27;s just <code><a href="https://api.bing.microsoft.com/">https://api.bing.microsoft.com/</a></code>.</p></p>
<p><p>Click on either &#x27;Keys and Endpoint&#x27; or the &#x27;Click here to manage keys&#x27; link to
open the &#x27;Keys and Endpoint&#x27; tab.</p></p>
<figure class="kg-card kg-image-card kg-card-hascaption"><img src="__GHOST_URL__/content/images/2021/02/image-10.png" class="kg-image" loading="lazy" width="760" height="462" srcset="__GHOST_URL__/content/images/size/w600/2021/02/image-10.png 600w, __GHOST_URL__/content/images/2021/02/image-10.png 760w" sizes="(min-width: 720px) 720px"/><figcaption>You&#x27;ll see your Endpoint listed here again</figcaption></figure>
<p><p>Keep hold of the endpoint from earlier, and click on the blue copy icon to
copy the API key, and keep this safe as well.</p></p>
<h3 id="configuring-the-application">Configuring the Application</h3>
<p><p>Fire up a terminal, or open up an integration terminal in your preferred code
editor - I&#x27;m a fan of 
<a href="https://code.visualstudio.com/">Visual Studio Code</a> -  and clone
the Git repository for the project. </p></p>
<p><p>Make sure you&#x27;ve changed your current working directory, to wherever you want
the code to go, and then run the clone command.</p></p>
<p><code>bash git clone https://github.com/Sealjay-clj/bingnews-cli.git </code></p>
<p><p>Rename the <code>.env.template</code> file in the <code>bingnews-cli/</code> 
directory to <code>.env</code>, replacing the content there with the Bing
Search Key, and the Bing Search Endpoint you noted down earlier.</p></p>
<script src="https://gist.github.com/Sealjay-clj/45a2522c586c88009f4c05271102c739.js"></script>
<h3 id="install-the-python-dependencies">Install the Python Dependencies</h3>
<p><p>Rather than installing all of the dependencies into the global environment,
we&#x27;ll create a separate environment.</p></p>
<p><p>To create a separate Python environment for your installation, and activate
it, there are two common options.</p></p>
<p><p>I prefer to use 
<a href="https://docs.conda.io/en/latest/miniconda.html">miniconda</a>, but
you can use a <code>venv</code> if you prefer.</p></p>
<p><p>a. <em>Using a Conda distribution</em></p></p>
<p><p>If you are using a distribution of conda, you may want to create a new conda
environment, rather than use venv:</p></p>
<code><p>$ conda create --name bingnews python=3.9 -y</p><p>$ conda activate bingnews</p><p>$ pip install -r requirements-dev.txt</p></code>
<p><p>b. <em>Using a Python virtual environment</em></p><br/><p>On Debian Linux distributions, you may need to run 
<code>sudo apt-get install python3-venv</code> before these instructions. On
other distributions, I don&#x27;t have a clue!</p></p>
<pre><code class="language-bash"><p>$ python3 -m venv env $ source env/bin/activate $ pip3 install -r
requirements-dev.txt</p></code></pre>
<p><p>On Windows, you may need to use <code>python</code> and <code>pip</code> 
commands where there are references to the <code>python3</code> and 
<code>pip3</code> commands.</p></p>
<p><p>At this point, you should have a configured Python environment, and we&#x27;re just
about ready to try this out! <code>cd bingnews-cli</code> into the same
directory as <code>bingnews.py</code>, and run 
<code>python3 bingnews.py</code>.</p></p>
<figure class="kg-card kg-image-card"><img src="__GHOST_URL__/content/images/2021/02/image-5.png" class="kg-image" loading="lazy" width="543" height="182"/></figure>
<p>Hopefully, you&#x27;re seeing a screen along these lines!</p>
<h3>How does it work?</h3>
<p>The application is surprisingly simple. Most of the intelligence takes place in Bing Search, and then Click is used to generate a CLI.  <a href="https://click.palletsprojects.com/en/7.x/">Click is a Python package</a>   focussed on creating command line interfaces.</p>
<p>The command line has three options:</p>
<ul>
<li>Search by Category. <em>Example:</em>  <code>python3 bingnews.py cat -c Business</code></li>
<li>Search by Phrase. <em>Example:</em>  <code>python3 bingnews.py phrase -p &quot;Future of Computing&quot;</code></li>
<li>Search for Trending articles. <em>Example:</em>  <code>python3 bingnews.py trend</code></li>
</ul>
<h4>The basic request</h4>
<p>The basic request is made up of the <code>search_and_output_bing</code>  function, which is called for all of the various API queries.</p>
<p>This queries the Bing News endpoint, and then requests that the output is printed with <code>print_bing_results</code>, which in turn formats the output for presentation in <code>clean_bing_article_list</code>, applying some tweaks for the varied result-set returned by trending articles, in  <code>clean_trending_article_dictionary</code>.</p>
 
<script src="https://gist.github.com/Sealjay-clj/e8a708866732ccd479a9cf069cfc84a3.js"></script>
 
<h4>Composing functions with Click</h4>
<p>In order to make functions available on the command-line, <code>click</code> allows us to use decorators to automatically generate help information for the command line, pass arguments to the function, and provide prompts if information is not provided by the user. Some defaults are also provided which can be overridden on the command-line, such as defaulting to the <code>en-GB</code> locale.</p>
<script src="https://gist.github.com/Sealjay-clj/a96bc2ddfd16fbbc3173f22f603c0e15.js"></script>
<h3>Other Components</h3>
<h5>Requests Caching</h5>
<p>Requests are cached for five minutes, in case the user runs the same search, or in case the shortener is provided similar news article URLs, to prevent requesting the same URL twice for shortening from an endpoint.</p>
<h5>Tabulate</h5>
<p>Tabulate is used to render the dictionary output from the API, and make it easily readable in the terminal.</p>
<h5>PyShorteners</h5>
<p>URLs provided by Bing News are shortened with the <code>pyshorteners</code> package,and the qpsru service, to ensure they don&#x27;t wrap off the terminal, and break the link.</p>
<h3>What packages does this use</h3>
<p>The key packages are as follows:</p>
<table><thead><tr><th>Package Name</th><th>Purpose</th></tr></thead><tbody><tr><td>click</td><td>Handles the CLI functionality</td></tr><tr><td>tabulate</td><td>Formats the results as a table</td></tr><tr><td>python-dotenv</td><td>Retrieves the configuration values from the .env file</td></tr><tr><td>requests</td><td>Handles the API request</td></tr><tr><td>requests-cache</td><td><p>Caches the requests if we make the same query, or shorten the same URL
(pyshorteners is <a href="https://github.com/ellisonleao/pyshorteners/blob/master/pyshorteners/base.py">based on the requests
package</a>
as well, and the qspru shortener uses GET requests)</p></td></tr><tr><td>pyshorteners</td><td><p>Shortens the URls - I use psru, as this shortener doesn&#x27;t require an API
key</p></td></tr></tbody></table>
<h3>What next?</h3>
<p>If you were to use this frequently in production, you&#x27;d want to add tests, and install this locally with a <code>setup.py</code> file. But for now, it&#x27;s a good start for a CLI that can be re-used - and I&#x27;ll be extending the functionality in a future post.</p>
<p>Thanks for reading, and I hope you found this interesting!</p>
<figure class="kg-card kg-image-card kg-card-hascaption"><img src="__GHOST_URL__/content/images/2021/02/image-13.png" class="kg-image" loading="lazy" width="913" height="289" srcset="__GHOST_URL__/content/images/size/w600/2021/02/image-13.png 600w, __GHOST_URL__/content/images/2021/02/image-13.png 913w" sizes="(min-width: 720px) 720px"/><figcaption>Time to go and catch up on Science and Technology!</figcaption></figure>
<figure class="kg-card kg-bookmark-card kg-card-hascaption"><a class="kg-bookmark-container" href="https://docs.microsoft.com/en-us/azure/cognitive-services/bing-web-search/"><div class="kg-bookmark-content"><div class="kg-bookmark-title"><p>Bing Search API documentation - Azure Cognitive Services</p></div><div class="kg-bookmark-description"><p>The Bing Search APIs let you build web-connected apps and services that
find webpages, images, news, locations, and more without advertisements.</p></div><div class="kg-bookmark-metadata"><span class="kg-bookmark-author">Microsoft Docs</span><span class="kg-bookmark-publisher">aahill</span></div></div><div class="kg-bookmark-thumbnail"><img src="https://docs.microsoft.com/en-us/media/logos/logo-ms-social.png"/></div></a><figcaption>Find out more about the Bing Search API</figcaption></figure>]]></content:encoded>
            <author>spencer@planetaria.tech (Spencer Sharp)</author>
        </item>
        <item>
            <title><![CDATA[Metrics Advisor]]></title>
            <link>undefined/articles/metrics-advisor</link>
            <guid>undefined/articles/metrics-advisor</guid>
            <pubDate>Tue, 09 Feb 2021 19:29:08 GMT</pubDate>
            <description><![CDATA[No description provided]]></description>
            <author>spencer@planetaria.tech (Spencer Sharp)</author>
        </item>
        <item>
            <title><![CDATA[Using Video Indexer and Microsoft Teams to stay in touch]]></title>
            <link>undefined/articles/using-video-indexer-and-microsoft-teams-to-stay-in-touch</link>
            <guid>undefined/articles/using-video-indexer-and-microsoft-teams-to-stay-in-touch</guid>
            <pubDate>Tue, 09 Feb 2021 13:59:07 GMT</pubDate>
            <description><![CDATA[No description provided]]></description>
            <content:encoded><![CDATA[<figure class="kg-card kg-bookmark-card"><a class="kg-bookmark-container" href="https://docs.microsoft.com/en-us/azure/media-services/video-indexer/video-indexer-use-apis"><div class="kg-bookmark-content"><div class="kg-bookmark-title"><p>Use the Video Indexer API - Azure Media Services</p></div><div class="kg-bookmark-description"><p>This article describes how to get started with Azure Media Services
Video Indexer API.</p></div><div class="kg-bookmark-metadata"><span class="kg-bookmark-author">Microsoft Docs</span><span class="kg-bookmark-publisher">Juliako</span></div></div><div class="kg-bookmark-thumbnail"><img src="https://docs.microsoft.com/en-us/media/logos/logo-ms-social.png"/></div></a></figure>]]></content:encoded>
            <author>spencer@planetaria.tech (Spencer Sharp)</author>
        </item>
        <item>
            <title><![CDATA[Enabling https on a Uvicorn Python Application deployed to Azure]]></title>
            <link>undefined/articles/enabling-https-on-a-uvicorn-python-application-deployed-to-azure</link>
            <guid>undefined/articles/enabling-https-on-a-uvicorn-python-application-deployed-to-azure</guid>
            <pubDate>Tue, 09 Feb 2021 10:10:00 GMT</pubDate>
            <description><![CDATA[No description provided]]></description>
            <content:encoded><![CDATA[<p><p>Like many services, </p><a href="https://docs.microsoft.com/en-us/azure/app-service/configure-language-python#detect-https-session"><p>Azure terminates SSL at the network load balancer</p></a><p>. In plain English, your application needs to check the headers provided to
it, to figure out if your user has connected via https.</p></p>
<p><p>If you&#x27;re using Uvicorn or another ASGI provider, you&#x27;ll need to include
middleware, to check the <code>X-Forwarded-Proto</code> and 
<code>X-Forwarded-For</code> headers.</p></p>
<p><p>Thankfully, Uvicorn already provides a package you can import for this: 
<code>uvicorn.middleware.proxy_headers.ProxyHeadersMiddleware</code>.</p></p>
<p><p>Import the full 
<code>uvicorn.middleware.proxy_headers.ProxyHeadersMiddleware</code> package,
specifying a specific trusted host to check for headers, or use a wildcard for
all hosts.</p></p>
<p><p>For example, in a 
<a href="https://www.starlette.io/middleware/">Starlette deployment</a> you
could include the library like so:</p></p>
<pre><code class="language-python"><p>import uvicorn # ... Middleware(
uvicorn.middleware.proxy_headers.ProxyHeadersMiddleware,
trusted_hosts=&quot;*&quot; )# Add the uvicorn middleware to the Starlette
middleware classes # ...</p></code></pre>]]></content:encoded>
            <author>spencer@planetaria.tech (Spencer Sharp)</author>
        </item>
        <item>
            <title><![CDATA[Running an ASGI Python Web Application in Azure with Gunicorn and Uvicorn]]></title>
            <link>undefined/articles/asgi-python-web-app-azure-gunicorn-python</link>
            <guid>undefined/articles/asgi-python-web-app-azure-gunicorn-python</guid>
            <pubDate>Tue, 09 Feb 2021 09:20:00 GMT</pubDate>
            <description><![CDATA[No description provided]]></description>
            <content:encoded><![CDATA[<p><p>Assuming you&#x27;re using a Linux web application plan, and running a Python
application that requires the use of Uvicorn, here are some tips.</p></p>
<p><p>You&#x27;ll need to </p><a href="https://docs.microsoft.com/en-gb/azure/app-service/configure-language-python#customize-startup-command"><p>have a startup command set in Azure</p></a><p>, which either calls a Uvicorn worker directly, or calls a configuration file specifying
one.</p></p>
<figure class="kg-card kg-image-card kg-card-hascaption"><img src="__GHOST_URL__/content/images/2021/02/image-2.png" class="kg-image" loading="lazy" width="296" height="63"/><figcaption><p>On the Azure Portal, open your Web App, scroll to &#x27;Configuration&#x27; under
&#x27;Settings&#x27;, click on the &#x27;General Settings&#x27; tab, and enter the appropriate
startup command.</p></figcaption></figure>
<p><code>gunicorn -c gunicorn_config.py app:app</code></p>
<p><p>Once your startup command is set, you&#x27;ll also need to have a
gunicorn_config.py file in your web app deployment.</p></p>
<pre><code class="language-python"><h1>Configuration for Gunicorn on Azure # Azure Startup Command should be:</h1><p>gunicorn -c gunicorn_config.py app:app # See:
<a href="https://docs.gunicorn.org/en/stable/settings.html#config">https://docs.gunicorn.org/en/stable/settings.html#config</a> workers = 4
worker_class = &quot;uvicorn.workers.UvicornWorker&quot;</p></code></pre>
<p><p>Finally, in your requirements.txt file, you&#x27;ll need to specify additional
dependencies:</p></p>
<pre><code># Required for deploying to Azure uvicorn uvloop httptools</code></pre>]]></content:encoded>
            <author>spencer@planetaria.tech (Spencer Sharp)</author>
        </item>
        <item>
            <title><![CDATA[Microsoft Build 2020 Part 2: And there’s more!]]></title>
            <link>undefined/articles/microsoft-build-2020-part-2-and-theres-more</link>
            <guid>undefined/articles/microsoft-build-2020-part-2-and-theres-more</guid>
            <pubDate>Thu, 04 Jun 2020 05:57:00 GMT</pubDate>
            <description><![CDATA[No description provided]]></description>
            <content:encoded><![CDATA[<p>We had so much to say in part 1, we worked with people across Avanade to published a second blog post:</p>
<p><a href="https://www.avanade.com/en/blogs/avanade-insights/innovation/microsoft-build-2020-part-2"><a href="https://www.avanade.com/en/blogs/avanade-insights/innovation/microsoft-build-2020-part-2">https://www.avanade.com/en/blogs/avanade-insights/innovation/microsoft-build-2020-part-2</a></a></p>]]></content:encoded>
            <author>spencer@planetaria.tech (Spencer Sharp)</author>
        </item>
        <item>
            <title><![CDATA[Microsoft Build 2020 - Part 1: We’ve combed through all the revelations]]></title>
            <link>undefined/articles/microsoft-build-2020-part-1-weve-combed-through-all-the-revelations</link>
            <guid>undefined/articles/microsoft-build-2020-part-1-weve-combed-through-all-the-revelations</guid>
            <pubDate>Fri, 29 May 2020 05:56:00 GMT</pubDate>
            <description><![CDATA[No description provided]]></description>
            <content:encoded><![CDATA[<p>My team pulled this blog post together from people all across Avanade:</p>
<p><a href="https://www.avanade.com/en/blogs/avanade-insights/innovation/microsoft-build-2020-combed-through-revelations/"><a href="https://www.avanade.com/en/blogs/avanade-insights/innovation/microsoft-build-2020-combed-through-revelations/">https://www.avanade.com/en/blogs/avanade-insights/innovation/microsoft-build-2020-combed-through-revelations/</a></a></p>]]></content:encoded>
            <author>spencer@planetaria.tech (Spencer Sharp)</author>
        </item>
        <item>
            <title><![CDATA[Annual Manufacturing Report 2020]]></title>
            <link>undefined/articles/annual-manufacturing-report-2020</link>
            <guid>undefined/articles/annual-manufacturing-report-2020</guid>
            <pubDate>Mon, 30 Mar 2020 00:00:00 GMT</pubDate>
            <description><![CDATA[No description provided]]></description>
            <content:encoded><![CDATA[<p>My thoughts on the state of Manufacturing in 2020.</p>
<figure class="kg-card kg-embed-card"><iframe width="200" height="113" src="https://www.youtube.com/embed/AfGs94vNXtg?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"></iframe></figure>
<p>Source: <a href="https://www.themanufacturer.com/articles/annual-manufacturing-report-2020-what-are-manufacturers-saying-about-their-future/"> Annual Manufacturing Report 2020 - What are manufacturers saying about
their future? - The
Manufacturer</a></p>
<blockquote>
<p><strong>Chris Lloyd Jones,</strong> Global Emerging Technology and Engineering Leader, at digital and cloud services company <strong>  <a href="https://www.avanade.com/en-gb/about-avanade">Avanade</a></strong> , which sponsored the chapter, said, “Industry 4.0 is not the end game for industrial digitalisation. In today’s world of perpetual change, the solution is not another industrial revolution, but a transformation of products and how we make them.</p>
</blockquote>
<blockquote>
<p>“We call this Industry X.0. Using new technologies like IoT, analytics, AI and digital twin, manufacturers can unlock new revenue and work with customers, employees and partners on a whole new level.”</p>
</blockquote>]]></content:encoded>
            <author>spencer@planetaria.tech (Spencer Sharp)</author>
        </item>
        <item>
            <title><![CDATA[5 Trends every CIO should be aware of in 2020]]></title>
            <link>undefined/articles/5-trends-every-cio-should-be-aware-of-in-2020</link>
            <guid>undefined/articles/5-trends-every-cio-should-be-aware-of-in-2020</guid>
            <pubDate>Mon, 20 Jan 2020 00:00:00 GMT</pubDate>
            <description><![CDATA[No description provided]]></description>
            <content:encoded><![CDATA[<p><p>Top Business Tech published the five trends I predicted should be on the CIO
radar.</p></p>
<figure class="kg-card kg-bookmark-card"><a class="kg-bookmark-container" href="https://tbtech.co/5-trends-every-cio-should-be-aware-of-in-2020/"><div class="kg-bookmark-content"><div class="kg-bookmark-title"><p>5 Trends Every CIO Should Be Aware Of In 2020 | TBTech</p></div><div class="kg-bookmark-description"><p>Chris Lloyd-Jones, product &amp; engineering lead for emerging
technology at Avanade, predicts 5 trends that should be on every CIO’s
radar in 2020</p></div><div class="kg-bookmark-metadata"><img class="kg-bookmark-icon" src="https://tbtech.co/wp-content/uploads/2019/06/cropped-03_PNG_TBT_Logo_Ico_Col_G_220519-192x192.png"/><span class="kg-bookmark-author">Top Business Tech</span><span class="kg-bookmark-publisher">Chris Lloyd-Jones</span></div></div><div class="kg-bookmark-thumbnail"><img src="https://tbtech.co/wp-content/uploads/2020/01/TrendFeat.png"/></div></a></figure>
<p>These were:</p>
<ul><li>The perceptive spaces trend</li><li>Virtual collaboration across borders</li><li>Practical uses for blockchain</li><li>More ethical security solutions</li><li>The gig economy trend continues</li></ul>
<p><a href="https://tbtech.co/5-trends-every-cio-should-be-aware-of-in-2020/"><p>Read the article for more</p></a><p>.</p></p>]]></content:encoded>
            <author>spencer@planetaria.tech (Spencer Sharp)</author>
        </item>
        <item>
            <title><![CDATA[Gartner: 5 emerging technology trends with transformational impact]]></title>
            <link>undefined/articles/gartner-5-emerging-technology-trends-with-transformational-impact</link>
            <guid>undefined/articles/gartner-5-emerging-technology-trends-with-transformational-impact</guid>
            <pubDate>Thu, 29 Aug 2019 00:00:00 GMT</pubDate>
            <description><![CDATA[No description provided]]></description>
            <content:encoded><![CDATA[<p>I was mentioned in Information Age.</p>
<blockquote><p>Sensing &amp; motion, augmented human, postclassical compute and comms,
digital ecosystems, and advanced AI &amp; Analytics are key emerging
technology trends, according to Gartner.</p></blockquote>
<figure class="kg-card kg-bookmark-card"><a class="kg-bookmark-container" href="https://www.information-age.com/5-emerging-technology-trends-gartner-123484932/"><div class="kg-bookmark-content"><div class="kg-bookmark-title"><p>5 emerging technology trends with transformational impact -- Gartner</p></div><div class="kg-bookmark-description"><p>Sensing &amp; motion, augmented human, postclassical compute, digital
ecosystems, and advanced AI &amp; Analytics are key emerging technology
trends</p></div><div class="kg-bookmark-metadata"><img class="kg-bookmark-icon" src="https://s27389.pcdn.co/wp-content/uploads/2018/06/cropped-IA_FAVICON_2018-1-192x192.png"/><span class="kg-bookmark-author">Information Age</span><span class="kg-bookmark-publisher">Andrew Ross</span></div></div><div class="kg-bookmark-thumbnail"><img src="https://s27389.pcdn.co/wp-content/uploads/2019/08/emerging-technology-trends.jpg"/></div></a></figure>]]></content:encoded>
            <author>spencer@planetaria.tech (Spencer Sharp)</author>
        </item>
        <item>
            <title><![CDATA[Why CIOs should focus on trimming their internal email footprint]]></title>
            <link>undefined/articles/why-cios-should-focus-on-trimming-their-internal-email-footprint</link>
            <guid>undefined/articles/why-cios-should-focus-on-trimming-their-internal-email-footprint</guid>
            <pubDate>Tue, 30 Jul 2019 00:00:00 GMT</pubDate>
            <description><![CDATA[No description provided]]></description>
            <content:encoded><![CDATA[<p><p>I was mentioned in Computer Weekly by 
<a href="https://twitter.com/cliffsaran">Cliff Saran</a>.</p></p>
<blockquote><p>Better internal collaboration should be part of a CIO’s digitisation arsenal.
But there is resistance to change, especially as email is so dominant.</p></blockquote>
<figure class="kg-card kg-bookmark-card"><a class="kg-bookmark-container" href="https://www.computerweekly.com/news/252467564/Why-CIOs-should-focus-on-trimming-their-internal-email-footprint"><div class="kg-bookmark-content"><div class="kg-bookmark-title"><p>Why CIOs should focus on trimming their internal email footprint</p></div><div class="kg-bookmark-description"><p>Better internal collaboration should be part of a CIO’s digitisation
arsenal. But there is resistance to change, especially as email is so
dominant</p></div><div class="kg-bookmark-metadata"><img class="kg-bookmark-icon" src="https://www.computerweekly.com/apple-touch-icon-precomposed.png"/><span class="kg-bookmark-author">ComputerWeekly.com</span><span class="kg-bookmark-publisher">Cliff Saran,</span></div></div><div class="kg-bookmark-thumbnail"><img src="https://cdn.ttgtmedia.com/visuals/searchSalesForce/customer_experience/salesforce_article_017.jpg"/></div></a></figure>]]></content:encoded>
            <author>spencer@planetaria.tech (Spencer Sharp)</author>
        </item>
        <item>
            <title><![CDATA[How facial recognition technology threatens basic privacy rights]]></title>
            <link>undefined/articles/how-facial-recognition-technology-threatens-basic-privacy-rights</link>
            <guid>undefined/articles/how-facial-recognition-technology-threatens-basic-privacy-rights</guid>
            <pubDate>Thu, 27 Jun 2019 00:00:00 GMT</pubDate>
            <description><![CDATA[No description provided]]></description>
            <content:encoded><![CDATA[<p>I was mentioned in Computer Weekly.</p>
<figure class="kg-card kg-bookmark-card"><a class="kg-bookmark-container" href="https://www.computerweekly.com/feature/How-facial-recognition-technology-threatens-basic-privacy-rights"><div class="kg-bookmark-content"><div class="kg-bookmark-title"><p>How facial recognition technology threatens basic privacy rights</p></div><div class="kg-bookmark-description"><p>As adoption of facial recognition systems continues to grow worldwide,
there is increasing concern that this technology could undermine
fundamental privacy rights and how it can be kept in check</p></div><div class="kg-bookmark-metadata"><img class="kg-bookmark-icon" src="https://www.computerweekly.com/apple-touch-icon-precomposed.png"/><span class="kg-bookmark-author">ComputerWeekly.com</span><span class="kg-bookmark-publisher">Nicholas Fearn</span></div></div><div class="kg-bookmark-thumbnail"><img src="https://cdn.ttgtmedia.com/visuals/German/article/CCTV-surveillance-3-fotolia.jpg"/></div></a></figure>]]></content:encoded>
            <author>spencer@planetaria.tech (Spencer Sharp)</author>
        </item>
        <item>
            <title><![CDATA[Ready by Design: Help to design a better digital future]]></title>
            <link>undefined/articles/ready-by-design-help-to-design-a-better-digital-future</link>
            <guid>undefined/articles/ready-by-design-help-to-design-a-better-digital-future</guid>
            <pubDate>Wed, 26 Jun 2019 00:00:00 GMT</pubDate>
            <description><![CDATA[No description provided]]></description>
            <content:encoded><![CDATA[<p>I was one of the presenters at Women of Silicon Roundabout.</p>
<blockquote><p>Emerging technology has given us unprecedented opportunities and challenges
for business, society and the world.</p></blockquote>
<blockquote><p>Innovation is changing our world at such a pace that humans and society are
struggling to keep up.</p></blockquote>
<blockquote><p>If we designed the world today, harnessing technology and our knowledge of its
impact, how would we do it differently?</p></blockquote>
<blockquote><p>How do we best harness it for better experiences, positive human impact and
social good?</p></blockquote>
<blockquote><p>Learn about the latest in tech innovation and digital potential in this
interactive design-led thinking workshop, where attendees will contribute to
designing a better future!</p></blockquote>
<blockquote>Key takeaways include:</blockquote>
<blockquote><p>How emerging technology and innovation insights will impact our work and
personal lives</p></blockquote>
<blockquote><p>How we adapt to the challenges and opportunities created</p></blockquote>
<blockquote><p>How techniques such as design-led thinking and agile help us to design and
deliver change</p></blockquote>
<blockquote><p>The role of ethics, diversity and inclusion in our advancement</p></blockquote>
<blockquote><p>How we can use technology and innovation to make a positive impact on society
and the world</p></blockquote>
<figure class="kg-card kg-bookmark-card"><a class="kg-bookmark-container" href="https://www.women-in-technology.com/agenda"><div class="kg-bookmark-content"><div class="kg-bookmark-title"><p>Women of Silicon Roundabout Conference 2020 | Agenda</p></div><div class="kg-bookmark-description"><p>Women of Silicon Roundabout was created to inspire, celebrate and
connect women working in technology - 16-17 June 2020: ExCel London.</p></div><div class="kg-bookmark-metadata"><img class="kg-bookmark-icon" src="https://www.women-in-technology.com/hubfs/WoSR%20-%20Women%20of%20Silicon%20Roundabout/images/HOME%20PAGE/logo-home.png"/><span class="kg-bookmark-author"><p>Women of Silicon Roundabout Conference 2021</p></span><span class="kg-bookmark-publisher">Ascend Global Media Limited</span></div></div><div class="kg-bookmark-thumbnail"><img src="https://www.women-in-technology.com/hubfs/WOSR19_TomLeishman-5766-6.jpg#keepProtocol"/></div></a></figure>]]></content:encoded>
            <author>spencer@planetaria.tech (Spencer Sharp)</author>
        </item>
        <item>
            <title><![CDATA[Enabling a future-ready business with AI and IA]]></title>
            <link>undefined/articles/enabling-a-future-ready-business-with-ai-and-ia</link>
            <guid>undefined/articles/enabling-a-future-ready-business-with-ai-and-ia</guid>
            <pubDate>Mon, 24 Jun 2019 00:00:00 GMT</pubDate>
            <description><![CDATA[No description provided]]></description>
            <content:encoded><![CDATA[<p>I was referenced by the Telegraph.</p>
<blockquote>
<p>While digital transformation by harnessing artificial intelligence and intelligent automation is a clear priority, there is no single path to success because companies are not starting from the same point.</p>
</blockquote>
<figure class="kg-card kg-bookmark-card"><a class="kg-bookmark-container" href="https://www.telegraph.co.uk/business/business-reporter/enabling-business-with-ai-and-ia/"><div class="kg-bookmark-content"><div class="kg-bookmark-title"><p>Enabling a future-ready business with AI and IA</p></div><div class="kg-bookmark-description"><p>If organisations are to be future-ready, data and intelligence must
permeate their core.</p></div><div class="kg-bookmark-metadata"><img class="kg-bookmark-icon" src="https://www.telegraph.co.uk/etc/designs/telegraph/core/clientlibs/core/icons/favicon-152x152.png"/><span class="kg-bookmark-author">The Telegraph</span><span class="kg-bookmark-publisher">24 June 2019 • 9:00am Follow</span></div></div><div class="kg-bookmark-thumbnail"><img src="https://www.telegraph.co.uk/content/dam/business/spark/business-reporter/business-reporter-2019/Lyonsdown-avanade-xlarge.jpg?imwidth=1200"/></div></a></figure>]]></content:encoded>
            <author>spencer@planetaria.tech (Spencer Sharp)</author>
        </item>
        <item>
            <title><![CDATA[BBC World Service, Chris Lloyd-Jones, Al Specialist, Avanade]]></title>
            <link>undefined/articles/bbc-world-service-chris-lloyd-jones-al-specialist-avanade</link>
            <guid>undefined/articles/bbc-world-service-chris-lloyd-jones-al-specialist-avanade</guid>
            <pubDate>Thu, 13 Jun 2019 00:00:00 GMT</pubDate>
            <description><![CDATA[No description provided]]></description>
            <content:encoded><![CDATA[<p><p>I joined the BBC World Business Report to discuss what needs to be done to
combat </p><a href="https://www.avanade.com/en/blogs/avanade-insights/artificial-intelligence/how-to-spot-deepfake-videos"><p>the emergence of deepfake videos</p></a><p>.</p></p>
<figure class="kg-card kg-bookmark-card"><a class="kg-bookmark-container" href="https://www.eiols.tv/olspreview.aspx?Int=627892-C2"><div class="kg-bookmark-content"><div class="kg-bookmark-title"><p>Executive Interviews - Bringing Your News to Life</p></div><div class="kg-bookmark-description"><p>Showcase TV interviews easily and legally on websites, social media, at
events and internally via our broadcaster endorsed services.</p></div><div class="kg-bookmark-metadata"><img class="kg-bookmark-icon" src="https://www.eiols.tv/icon/favicon.ico"/><span class="kg-bookmark-author">Executive Interviews</span></div></div><div class="kg-bookmark-thumbnail"><img src="https://www.eiols.tv/App_Themes/images/Broadcasters/TransLogo/BBC_World.png"/></div></a></figure>]]></content:encoded>
            <author>spencer@planetaria.tech (Spencer Sharp)</author>
        </item>
        <item>
            <title><![CDATA[Quantum computing — coming soon to an enterprise near you?]]></title>
            <link>undefined/articles/quantum-computing-coming-soon-to-an-enterprise-near-you</link>
            <guid>undefined/articles/quantum-computing-coming-soon-to-an-enterprise-near-you</guid>
            <pubDate>Mon, 25 Feb 2019 00:00:00 GMT</pubDate>
            <description><![CDATA[No description provided]]></description>
            <content:encoded><![CDATA[<p>I was referenced in Information Age.</p>
<figure class="kg-card kg-bookmark-card"><a class="kg-bookmark-container" href="https://www.information-age.com/quantum-computing-enterprise-123479402/"><div class="kg-bookmark-content"><div class="kg-bookmark-title"><p>Quantum computing -- coming soon to an enterprise near you?</p></div><div class="kg-bookmark-description"><p>Quantum computing will be one of the defining technologies that will
emerge over the next five to ten years</p></div><div class="kg-bookmark-metadata"><img class="kg-bookmark-icon" src="https://s27389.pcdn.co/wp-content/uploads/2018/06/cropped-IA_FAVICON_2018-1-192x192.png"/><span class="kg-bookmark-author">Information Age</span><span class="kg-bookmark-publisher">Nick Ismail</span></div></div><div class="kg-bookmark-thumbnail"><img src="https://s27389.pcdn.co/wp-content/uploads/2019/02/quantum-computing-enterprise.jpeg"/></div></a></figure>]]></content:encoded>
            <author>spencer@planetaria.tech (Spencer Sharp)</author>
        </item>
        <item>
            <title><![CDATA[Chatbot implementation: Best practice tips from Avanade]]></title>
            <link>undefined/articles/chatbot-implementation-best-practice-tips-from-avanade</link>
            <guid>undefined/articles/chatbot-implementation-best-practice-tips-from-avanade</guid>
            <pubDate>Thu, 21 Feb 2019 00:00:00 GMT</pubDate>
            <description><![CDATA[No description provided]]></description>
            <content:encoded><![CDATA[<p>I was referenced in Information Age.</p>
<figure class="kg-card kg-bookmark-card"><a class="kg-bookmark-container" href="https://www.information-age.com/chatbot-implementation-best-practice-123479328/"><div class="kg-bookmark-content"><div class="kg-bookmark-title"><p>Chatbot implementation: Best practice tips from Avanade</p></div><div class="kg-bookmark-description"><p>This article will explore Avanade’s deployment of Carrie, a security
chatbot for Carlsberg. And some implementation best practice tips</p></div><div class="kg-bookmark-metadata"><img class="kg-bookmark-icon" src="https://s27389.pcdn.co/wp-content/uploads/2018/06/cropped-IA_FAVICON_2018-1-192x192.png"/><span class="kg-bookmark-author">Information Age</span><span class="kg-bookmark-publisher">Nick Ismail</span></div></div><div class="kg-bookmark-thumbnail"><img src="https://s27389.pcdn.co/wp-content/uploads/2019/02/chatbot-implementation-best-practice-e1550759421826.jpeg"/></div></a></figure>]]></content:encoded>
            <author>spencer@planetaria.tech (Spencer Sharp)</author>
        </item>
        <item>
            <title><![CDATA[IOT Now: Focus on your business goals]]></title>
            <link>undefined/articles/iot-now-focus-on-your-business-goals</link>
            <guid>undefined/articles/iot-now-focus-on-your-business-goals</guid>
            <pubDate>Tue, 12 Feb 2019 00:00:00 GMT</pubDate>
            <description><![CDATA[No description provided]]></description>
            <content:encoded><![CDATA[<p>How can IoT empower new digital business models?</p>
<p><p>How can innovative companies prioritise design and data to improve the
employee and customer experience?</p></p>
<p><p>Is IoT a panacea to create new competitive differentiation in your industry</p></p>
<p><p>How is IoT bridging the gap between the digital and real, to mediate the
continual exchange of data and services</p></p>
<p>A discussion of real examples.</p>
<figure class="kg-card kg-image-card kg-card-hascaption"><img src="__GHOST_URL__/content/images/2021/02/image-1.png" class="kg-image" loading="lazy" width="360" height="360"/><figcaption><a href="https://www.globalexecutiveevents.com/news-avanade"><p>Avanade - News - Global Executive Events</p></a></figcaption></figure>]]></content:encoded>
            <author>spencer@planetaria.tech (Spencer Sharp)</author>
        </item>
        <item>
            <title><![CDATA[IDG Connect: How AI is impacting the creative industries]]></title>
            <link>undefined/articles/idg-connect-ai-creative</link>
            <guid>undefined/articles/idg-connect-ai-creative</guid>
            <pubDate>Sun, 18 Nov 2018 00:00:00 GMT</pubDate>
            <description><![CDATA[No description provided]]></description>
            <content:encoded><![CDATA[<h3 id="how-is-ai-currently-used-in-the-creative-industries-what-are-the-challenges-and-how-can-creatives-work-with-ai-to-create-interesting-experiences"><p>How is AI currently used in the creative industries, what are the challenges
and how can creatives work with AI to create interesting experiences?</p></h3>
<p><p>I was mentioned in IDG Connect&#x27;s analysis on &#x27;how AI is impacting the creative
industries.&#x27;</p></p>
<figure class="kg-card kg-bookmark-card"><a class="kg-bookmark-container" href="https://www.idgconnect.com/idgconnect/analysis-review/1500175/ai-impacting-creative-industries"><div class="kg-bookmark-content"><div class="kg-bookmark-title"><p>How AI is impacting the creative industries</p></div><div class="kg-bookmark-description"><p>How is AI currently used in the creative industries, what are the
challenges and how can creatives work with AI to create interesting
experiences?</p></div><div class="kg-bookmark-metadata"><img class="kg-bookmark-icon" src="https://alt.idgesg.net/images/furniture/idgconnect/favicon.ico"/><span class="kg-bookmark-author">IDG Connect</span><span class="kg-bookmark-publisher">Bianca Wright</span></div></div><div class="kg-bookmark-thumbnail"><img src="https://idge.staticworld.net/tnw/images/computerworld-logo300x300.png"/></div></a></figure>]]></content:encoded>
            <author>spencer@planetaria.tech (Spencer Sharp)</author>
        </item>
        <item>
            <title><![CDATA[D365 Saturday Dublin 2018 - AI and D365]]></title>
            <link>undefined/articles/d365-saturday-dublin-2018-ai-and-d365</link>
            <guid>undefined/articles/d365-saturday-dublin-2018-ai-and-d365</guid>
            <pubDate>Sat, 15 Sep 2018 00:00:00 GMT</pubDate>
            <description><![CDATA[No description provided]]></description>
            <content:encoded><![CDATA[<p>A step by step introduction to integrating Machine Learning models into Dynamics 365. Covering a scenario around banking risk, and automating credit scoring. Also including OCR and Computer Vision.</p>]]></content:encoded>
            <author>spencer@planetaria.tech (Spencer Sharp)</author>
        </item>
        <item>
            <title><![CDATA[RPA and AI World Berlin 2018]]></title>
            <link>undefined/articles/rpa-and-ai-world-berlin-2018</link>
            <guid>undefined/articles/rpa-and-ai-world-berlin-2018</guid>
            <pubDate>Wed, 11 Jul 2018 00:00:00 GMT</pubDate>
            <description><![CDATA[No description provided]]></description>
            <author>spencer@planetaria.tech (Spencer Sharp)</author>
        </item>
        <item>
            <title><![CDATA[Blue Prism World London 2018]]></title>
            <link>undefined/articles/blue-prism-world-london-2018</link>
            <guid>undefined/articles/blue-prism-world-london-2018</guid>
            <pubDate>Fri, 22 Jun 2018 00:00:00 GMT</pubDate>
            <description><![CDATA[No description provided]]></description>
            <content:encoded><![CDATA[<p>I presented on the work my team had completed to:</p>
<ul><li><p>Build </p><a href="https://www.avanade.com/404?item=web%3a%7bAA4D08D2-9DEE-4772-9270-80E747CFBADC%7d%40en"><p>the first Microsoft cognitive service integration for Blue Prism</p></a><br/></li><li><p>Create continuous integration from Blue Prism to Git (</p><a href="https://news.microsoft.com/2018/06/04/microsoft-to-acquire-github-for-7-5-billion/" rel="nofollow"><p>even more timely as Github joins the Microsoft fold</p></a><p>)<br/></p></li><li><a href="https://www.prnewswire.com/news-releases/avanade-first-global-systems-integrator-si-to-become-authorized-training-partner-for-blue-prism-300664404.html" rel="nofollow"><p>Become the first Global Systems Integrator Authorized Training partner for
Blue Prism</p></a><br/></li><li><p>Adding Virtual Agents to Robotic Process Automation for a conversational
interface</p></li></ul>
<p><p>Full post available at </p><a href="https://www.avanade.com/en/blogs/avanade-insights/artificial-intelligence/intelligent-automation-blue-prism"><p>Intelligent Automation: Big Progress for Big Processes | Avanade</p></a><p>.</p></p>
<figure class="kg-card kg-bookmark-card"><a class="kg-bookmark-container" href="https://www.blueprism.com/resources/blog/congratulations-to-our-partner-awards-2020-winners/"><div class="kg-bookmark-content"><div class="kg-bookmark-title"><p>Congratulations to our Partner Awards 2020 Winners</p></div><div class="kg-bookmark-description"><p>Congratulations to all of our Partner Awards 2020 Winners!</p></div><div class="kg-bookmark-metadata"><img class="kg-bookmark-icon" src="https://www.blueprism.com/assets/favicons/apple-touch-icon.png?v=2.1"/><span class="kg-bookmark-author">Blue Prism</span></div></div><div class="kg-bookmark-thumbnail"><img src="https://www.blueprism.com/uploads/resources/thumbnails/blog/_1200x630_crop_center-center_82_none/BP-Partner-Awards-2020-W-Thumb-440x303px.jpg?mtime=1592924721"/></div></a></figure>]]></content:encoded>
            <author>spencer@planetaria.tech (Spencer Sharp)</author>
        </item>
        <item>
            <title><![CDATA[Nintex Xchange 2018]]></title>
            <link>undefined/articles/nintex-xchange-2018</link>
            <guid>undefined/articles/nintex-xchange-2018</guid>
            <pubDate>Mon, 26 Feb 2018 00:00:00 GMT</pubDate>
            <description><![CDATA[No description provided]]></description>
            <author>spencer@planetaria.tech (Spencer Sharp)</author>
        </item>
        <item>
            <title><![CDATA[D365 Saturday London 2018 - AI and D365]]></title>
            <link>undefined/articles/d365-saturday-london-2018-ai-and-d365</link>
            <guid>undefined/articles/d365-saturday-london-2018-ai-and-d365</guid>
            <pubDate>Sat, 27 Jan 2018 05:11:00 GMT</pubDate>
            <description><![CDATA[No description provided]]></description>
            <content:encoded><![CDATA[<p>Integrating Virtual Agents and Machine Learning models into D365 for Sales and Service. A visual demonstration (prior to the Fall 2018 AI update) of integrated AI.</p>]]></content:encoded>
            <author>spencer@planetaria.tech (Spencer Sharp)</author>
        </item>
        <item>
            <title><![CDATA[Big Data in Payments - Cass Business School]]></title>
            <link>undefined/articles/big-data-in-payments-cass-business-school</link>
            <guid>undefined/articles/big-data-in-payments-cass-business-school</guid>
            <pubDate>Tue, 18 Jul 2017 00:00:00 GMT</pubDate>
            <description><![CDATA[No description provided]]></description>
            <content:encoded><![CDATA[<p>I hosted a talk on analytics and big data in finance at Cass Business School.</p>]]></content:encoded>
            <author>spencer@planetaria.tech (Spencer Sharp)</author>
        </item>
        <item>
            <title><![CDATA[Intelligent Workforce of the Future]]></title>
            <link>undefined/articles/intelligent-workforce-of-the-future</link>
            <guid>undefined/articles/intelligent-workforce-of-the-future</guid>
            <pubDate>Mon, 12 Jun 2017 03:53:00 GMT</pubDate>
            <description><![CDATA[No description provided]]></description>
            <content:encoded><![CDATA[<p><p>Intelligent Automation is the essential new co-worker in the digital world,
and companies will need to apply the human touch to those activities that need
it most. We’ll show you some real examples of the Intelligent Workforce, and
the value proposition involved with leveraging smart technology effectively
and efficiently.</p></p>
<figure class="kg-card kg-bookmark-card"><a class="kg-bookmark-container" href="https://goo.gl/maps/NoVPhSLDwRueVeCAA"><div class="kg-bookmark-content"><div class="kg-bookmark-title">Microsoft Executive Briefing Center</div><div class="kg-bookmark-description"><p>★★★★★ · Corporate office · 16070 NE 36th Way</p></div><div class="kg-bookmark-metadata"><img class="kg-bookmark-icon" src="https://www.google.com/images/branding/product/ico/maps15_bnuw3a_32dp.ico"/><span class="kg-bookmark-author"><p>Microsoft Executive Briefing Center</p></span></div></div><div class="kg-bookmark-thumbnail"><img src="https://lh5.googleusercontent.com/p/AF1QipMgqoE2yalDuizbuEDl8a7bCRcjnSiUf9PfJMba=w256-h256-k-no-p"/></div></a></figure>
<figure class="kg-card kg-embed-card"><iframe width="200" height="113" src="https://www.youtube.com/embed/6V7xETImnMY?start=580&amp;feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"></iframe></figure>]]></content:encoded>
            <author>spencer@planetaria.tech (Spencer Sharp)</author>
        </item>
        <item>
            <title><![CDATA[Blue Prism World New York 2017]]></title>
            <link>undefined/articles/blue-prism-world-new-york-2017</link>
            <guid>undefined/articles/blue-prism-world-new-york-2017</guid>
            <pubDate>Wed, 07 Jun 2017 00:00:00 GMT</pubDate>
            <description><![CDATA[No description provided]]></description>
            <content:encoded><![CDATA[<p>I presented an overview of RPA and how that can be integrated with Microsoft Cognitive Services.</p>]]></content:encoded>
            <author>spencer@planetaria.tech (Spencer Sharp)</author>
        </item>
        <item>
            <title><![CDATA[Blue Prism World London 2017]]></title>
            <link>undefined/articles/blue-prism-world-london-2017</link>
            <guid>undefined/articles/blue-prism-world-london-2017</guid>
            <pubDate>Thu, 01 Jun 2017 00:00:00 GMT</pubDate>
            <description><![CDATA[No description provided]]></description>
            <content:encoded><![CDATA[<p><p>I looked after the Avanade relationship with Blue Prism throughout 2017, and
accepted an award onstage for &#x27;creating client value.&#x27;</p></p>
<figure class="kg-card kg-bookmark-card"><a class="kg-bookmark-container" href="https://www.businesswire.com/news/home/20170628005840/en/Blue-Prism-World-Events-in-New-York-and-London-Bring-Together-More-Than-1200-Robotic-Process-Automation-RPA-Users-Partners-Experts-and-Industry-Leaders"><div class="kg-bookmark-content"><div class="kg-bookmark-title"><p>Blue Prism World Events in New York and London Bring Together More Than
1,200 Robotic Process Automation (RPA) Users, Partners, Experts and
Industry Leaders</p></div><div class="kg-bookmark-description"><p>Blue Prism attracted more than 1,200 attendees to its Blue Prism World
events, making it the largest RPA event of the year.</p></div><div class="kg-bookmark-metadata"><span class="kg-bookmark-author">Business Wire</span></div></div><div class="kg-bookmark-thumbnail"><img src="https://mms.businesswire.com/media/20170628005840/en/557080/21/blueprism_logo_2008.jpg"/></div></a></figure>]]></content:encoded>
            <author>spencer@planetaria.tech (Spencer Sharp)</author>
        </item>
    </channel>
</rss>